{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PeirongMa/chatgpt-sms/blob/main/bank_deposit_change_prediction_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mt9OSnsNQgFw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "from google.colab import files\n",
        "import os\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "import statsmodels.api as sm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Process the raw data into suitable format"
      ],
      "metadata": {
        "id": "VgffewZensj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# specify the folder path where CSV files are stored\n",
        "folder_path = \"/content/2022\"\n",
        "\n",
        "# get a list of all CSV files in the folder\n",
        "file_list = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
        "\n",
        "# create an empty list to store the dataframes\n",
        "dfs = []\n",
        "\n",
        "# read in each CSV file as a dataframe and append to the dfs list\n",
        "for file in file_list:\n",
        "    file_path = os.path.join(folder_path, file)\n",
        "    df = pd.read_csv(file_path)\n",
        "    if len(dfs) == 0:\n",
        "        # for the first dataframe, store the column names\n",
        "        cols = list(df.columns)\n",
        "        dfs.append(df)\n",
        "    else:\n",
        "        # for subsequent dataframes, only read in columns that are not already present\n",
        "        new_cols = [col for col in df.columns if col not in cols]\n",
        "        if len(new_cols) > 0:\n",
        "            df = pd.read_csv(file_path, usecols=new_cols)\n",
        "            dfs.append(df)\n",
        "\n",
        "# concatenate all dataframes in the dfs list into a single dataframe\n",
        "final_df = pd.concat(dfs, axis=1)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u-mOks-GgN8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "C7BaMLEjhLNq",
        "outputId": "031f0977-23c8-40bf-b162-cf16b006c9c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ABCUBK  ABCUOTH  ABCXBK  ABCXOTH  ADDNONII  ADDNONINTEXP  ASCEOTH  \\\n",
              "0        NaN      NaN     NaN      NaN       558          1373      NaN   \n",
              "1        NaN      NaN     NaN      NaN      1634          2435      NaN   \n",
              "2        NaN      NaN     NaN      NaN       311          1288      NaN   \n",
              "3        NaN      NaN     NaN      NaN       586          1580      NaN   \n",
              "4        NaN      NaN     NaN      NaN      8862         14509      NaN   \n",
              "...      ...      ...     ...      ...       ...           ...      ...   \n",
              "4768     NaN      NaN     NaN      NaN        10           610      NaN   \n",
              "4769     NaN      NaN     NaN      NaN      1677          3627      NaN   \n",
              "4770     NaN      NaN     NaN      NaN       890          2390      NaN   \n",
              "4771     NaN      NaN     NaN      NaN       562           929      NaN   \n",
              "4772     NaN      NaN     NaN      NaN       426           818      NaN   \n",
              "\n",
              "      ASCERES  ASDROTH  ASDRRES  ...  TTNMNUM      UC   UCCOMRE  UCCOMRES  \\\n",
              "0         NaN      NaN      NaN  ...        0   11604     941.0     861.0   \n",
              "1         NaN      NaN      NaN  ...        0   47671   13824.0   13824.0   \n",
              "2         NaN      NaN      NaN  ...        0   23164     822.0     822.0   \n",
              "3         NaN      NaN      NaN  ...        0   24562    2785.0    2785.0   \n",
              "4         NaN      NaN      NaN  ...       14  656536  194266.0  194266.0   \n",
              "...       ...      ...      ...  ...      ...     ...       ...       ...   \n",
              "4768      NaN      NaN      NaN  ...        0    3410    2928.0    2928.0   \n",
              "4769      NaN      NaN      NaN  ...        0   82433   30700.0   30700.0   \n",
              "4770      NaN      NaN      NaN  ...        0   21729    8847.0    8847.0   \n",
              "4771      NaN      NaN      NaN  ...        0    3539    1359.0    1183.0   \n",
              "4772      NaN      NaN      NaN  ...        0   14308    2733.0    2733.0   \n",
              "\n",
              "      UCCOMREU   UCCRCD    UCLOC   UCOTHER   UCOVER1  UCSC  \n",
              "0         80.0      0.0    785.0    9878.0       0.0   NaN  \n",
              "1          0.0     26.0   9699.0   24122.0   25721.0   NaN  \n",
              "2          0.0    935.0   2045.0   19362.0       0.0   NaN  \n",
              "3          0.0    428.0   4819.0   16530.0       0.0   NaN  \n",
              "4          0.0  12241.0  86918.0  363111.0  459561.0   NaN  \n",
              "...        ...      ...      ...       ...       ...   ...  \n",
              "4768       0.0      0.0      0.0     482.0       0.0   NaN  \n",
              "4769       0.0   1695.0  28339.0   21699.0   47265.0   NaN  \n",
              "4770       0.0      0.0   7547.0    5335.0       0.0   NaN  \n",
              "4771     176.0      0.0   1719.0     461.0    1137.0   NaN  \n",
              "4772       0.0      0.0     53.0   11522.0       0.0   NaN  \n",
              "\n",
              "[4773 rows x 933 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-238728e7-6552-433f-9a85-60a1784e3307\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ABCUBK</th>\n",
              "      <th>ABCUOTH</th>\n",
              "      <th>ABCXBK</th>\n",
              "      <th>ABCXOTH</th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASCEOTH</th>\n",
              "      <th>ASCERES</th>\n",
              "      <th>ASDROTH</th>\n",
              "      <th>ASDRRES</th>\n",
              "      <th>...</th>\n",
              "      <th>TTNMNUM</th>\n",
              "      <th>UC</th>\n",
              "      <th>UCCOMRE</th>\n",
              "      <th>UCCOMRES</th>\n",
              "      <th>UCCOMREU</th>\n",
              "      <th>UCCRCD</th>\n",
              "      <th>UCLOC</th>\n",
              "      <th>UCOTHER</th>\n",
              "      <th>UCOVER1</th>\n",
              "      <th>UCSC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>558</td>\n",
              "      <td>1373</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>11604</td>\n",
              "      <td>941.0</td>\n",
              "      <td>861.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>785.0</td>\n",
              "      <td>9878.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1634</td>\n",
              "      <td>2435</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>47671</td>\n",
              "      <td>13824.0</td>\n",
              "      <td>13824.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>9699.0</td>\n",
              "      <td>24122.0</td>\n",
              "      <td>25721.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>311</td>\n",
              "      <td>1288</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>23164</td>\n",
              "      <td>822.0</td>\n",
              "      <td>822.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>935.0</td>\n",
              "      <td>2045.0</td>\n",
              "      <td>19362.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>586</td>\n",
              "      <td>1580</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>24562</td>\n",
              "      <td>2785.0</td>\n",
              "      <td>2785.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>4819.0</td>\n",
              "      <td>16530.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8862</td>\n",
              "      <td>14509</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>14</td>\n",
              "      <td>656536</td>\n",
              "      <td>194266.0</td>\n",
              "      <td>194266.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>12241.0</td>\n",
              "      <td>86918.0</td>\n",
              "      <td>363111.0</td>\n",
              "      <td>459561.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4768</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>610</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3410</td>\n",
              "      <td>2928.0</td>\n",
              "      <td>2928.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>482.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4769</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1677</td>\n",
              "      <td>3627</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>82433</td>\n",
              "      <td>30700.0</td>\n",
              "      <td>30700.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1695.0</td>\n",
              "      <td>28339.0</td>\n",
              "      <td>21699.0</td>\n",
              "      <td>47265.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4770</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>890</td>\n",
              "      <td>2390</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>21729</td>\n",
              "      <td>8847.0</td>\n",
              "      <td>8847.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7547.0</td>\n",
              "      <td>5335.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4771</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>562</td>\n",
              "      <td>929</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>3539</td>\n",
              "      <td>1359.0</td>\n",
              "      <td>1183.0</td>\n",
              "      <td>176.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1719.0</td>\n",
              "      <td>461.0</td>\n",
              "      <td>1137.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4772</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>426</td>\n",
              "      <td>818</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>14308</td>\n",
              "      <td>2733.0</td>\n",
              "      <td>2733.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>53.0</td>\n",
              "      <td>11522.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4773 rows × 933 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-238728e7-6552-433f-9a85-60a1784e3307')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-238728e7-6552-433f-9a85-60a1784e3307 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-238728e7-6552-433f-9a85-60a1784e3307');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 292
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t2020.to_csv('2022t_file.csv', index=False)\n",
        "files.download('2022t_file.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Q75GN4NwmC_5",
        "outputId": "e220ab86-f549-410b-dcd0-61ea53b7123c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4778834f-c9de-4d82-bc76-8a3be92af583\", \"2022t_file.csv\", 945895)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def process_data_files(file_names):\n",
        "    # loop over each pair of file names\n",
        "    for i in range(0, len(file_names), 2):\n",
        "        # read in the two data files for this pair\n",
        "        data1 = pd.read_csv(file_names[i])\n",
        "        data2 = pd.read_csv(file_names[i+1])\n",
        "\n",
        "        # merge the two dataframes and perform data cleaning\n",
        "        merged_df = pd.merge(data1, data2[['NAME', 'DEP']], on='NAME', how='left')\n",
        "        merged_df.drop_duplicates(subset=[ 'NAME'], inplace=True)\n",
        "        merged_df['change_depot'] = merged_df['DEP_x']-merged_df['DEP_y']\n",
        "        nan_pct = merged_df.isna().sum() / len(merged_df) * 100\n",
        "        zero_pct = (merged_df == 0).sum() / len(merged_df) * 100\n",
        "        same_value_pct = (merged_df.apply(lambda col: col.value_counts(normalize=True).max()) * 100)\n",
        "        mask = ((nan_pct >= 20) | (zero_pct >= 20) | (same_value_pct >= 20))\n",
        "        merged_df.drop(merged_df.columns[mask], axis=1, inplace=True)\n",
        "        merged_df = merged_df.dropna(axis=0)\n",
        "        merged_df = merged_df.set_index('NAME')\n",
        "    return merged_df\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DuW3-x9bkGnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = [\"2001q3_file .csv\", \"2001q4_file.csv\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "XA-5dklXlB9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2001 = process_data_files(file_names)"
      ],
      "metadata": {
        "id": "fRVEEexbkpo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        },
        "id": "gpAkoyKkkARI",
        "outputId": "ca9e9042-1c5e-440a-b05f-388c6531a0c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         ADDNONII  ADDNONINTEXP   ASSET   DEP_x  EDEPDOM  \\\n",
              "NAME                                                                       \n",
              "PROGRESSIVE BANK NA           286          1041  183166  158131   3853.0   \n",
              "FARMERS STATE BANK            175           405   80756   62379   1736.0   \n",
              "FIRST BANK                    445           507   61227   53416   1518.0   \n",
              "WOODFORD STATE BANK           122           274   77724   70622   2189.0   \n",
              "PORTAGE COUNTY BANK           193           270   43399   38108   1089.0   \n",
              "...                           ...           ...     ...     ...      ...   \n",
              "JEFFERSON SECURITY BANK       326          1296  167966  154970   4098.0   \n",
              "CAPON VALLEY BANK             201           734  112342   99922   3163.0   \n",
              "G W JONES EXCHANGE BANK       104           406   52286   47311   1245.0   \n",
              "BANK OF DELIGHT                20           214   70816   58871   1969.0   \n",
              "UNION TRUST CO               1736          2967  349343  268903   5915.0   \n",
              "\n",
              "                         EINTEXP  ELNATR  EOTHNINT  EPREMAGG    ESAL  ...  \\\n",
              "NAME                                                                  ...   \n",
              "PROGRESSIVE BANK NA       4109.0   360.0     989.0     507.0  1685.0  ...   \n",
              "FARMERS STATE BANK        1935.0    60.0     405.0     175.0   975.0  ...   \n",
              "FIRST BANK                1645.0    27.0     500.0     288.0   950.0  ...   \n",
              "WOODFORD STATE BANK       2241.0    90.0     274.0     206.0   933.0  ...   \n",
              "PORTAGE COUNTY BANK       1100.0    36.0     270.0     103.0   586.0  ...   \n",
              "...                          ...     ...       ...       ...     ...  ...   \n",
              "JEFFERSON SECURITY BANK   4142.0    90.0    1296.0     674.0  2206.0  ...   \n",
              "CAPON VALLEY BANK         3237.0   165.0     734.0     360.0  1106.0  ...   \n",
              "G W JONES EXCHANGE BANK   1311.0    19.0     406.0     253.0   877.0  ...   \n",
              "BANK OF DELIGHT           1969.0     0.0     191.0      57.0   428.0  ...   \n",
              "UNION TRUST CO            8260.0   225.0    2967.0    1609.0  4740.0  ...   \n",
              "\n",
              "                         SCRDEBT   SCUS  SCUSO      TRN  TRNIPCOC  TRNMUNI  \\\n",
              "NAME                                                                         \n",
              "PROGRESSIVE BANK NA      63801.0  40769  39028  39899.0   34246.0   5546.0   \n",
              "FARMERS STATE BANK       26164.0  16287  16287  14789.0   13116.0   1673.0   \n",
              "FIRST BANK                6510.0   4391   4134  12889.0   11398.0   1057.0   \n",
              "WOODFORD STATE BANK       4625.0   3402   3402  12530.0   11298.0   1232.0   \n",
              "PORTAGE COUNTY BANK       7410.0   5210   4209   7628.0    7324.0    304.0   \n",
              "...                          ...    ...    ...      ...       ...      ...   \n",
              "JEFFERSON SECURITY BANK  25692.0  22352  21826  56235.0   37530.0  18683.0   \n",
              "CAPON VALLEY BANK         9335.0   4790   4790  17341.0   16503.0    838.0   \n",
              "G W JONES EXCHANGE BANK   1510.0   1510      0  11878.0   11136.0    742.0   \n",
              "BANK OF DELIGHT          16738.0   9218   9008  12550.0   10227.0   2323.0   \n",
              "UNION TRUST CO           84417.0  61832  61832  26235.0    3949.0  22286.0   \n",
              "\n",
              "                            UC  UCOTHER     DEP_y  change_depot  \n",
              "NAME                                                             \n",
              "PROGRESSIVE BANK NA      17745   5555.0  170947.0      -12816.0  \n",
              "FARMERS STATE BANK        5737   2731.0   63667.0       -1288.0  \n",
              "FIRST BANK                3796   1137.0   57466.0       -4050.0  \n",
              "WOODFORD STATE BANK       4395    828.0   73658.0       -3036.0  \n",
              "PORTAGE COUNTY BANK       4525   1297.0   40355.0       -2247.0  \n",
              "...                        ...      ...       ...           ...  \n",
              "JEFFERSON SECURITY BANK  29188  18239.0  163754.0       -8784.0  \n",
              "CAPON VALLEY BANK         4785   4785.0  101555.0       -1633.0  \n",
              "G W JONES EXCHANGE BANK   5184    293.0   51040.0       -3729.0  \n",
              "BANK OF DELIGHT           1648    808.0   61735.0       -2864.0  \n",
              "UNION TRUST CO           40742  15626.0  268424.0         479.0  \n",
              "\n",
              "[7038 rows x 171 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d8660dac-a1cc-409a-b33d-33111f1753c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASSET</th>\n",
              "      <th>DEP_x</th>\n",
              "      <th>EDEPDOM</th>\n",
              "      <th>EINTEXP</th>\n",
              "      <th>ELNATR</th>\n",
              "      <th>EOTHNINT</th>\n",
              "      <th>EPREMAGG</th>\n",
              "      <th>ESAL</th>\n",
              "      <th>...</th>\n",
              "      <th>SCRDEBT</th>\n",
              "      <th>SCUS</th>\n",
              "      <th>SCUSO</th>\n",
              "      <th>TRN</th>\n",
              "      <th>TRNIPCOC</th>\n",
              "      <th>TRNMUNI</th>\n",
              "      <th>UC</th>\n",
              "      <th>UCOTHER</th>\n",
              "      <th>DEP_y</th>\n",
              "      <th>change_depot</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NAME</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PROGRESSIVE BANK NA</th>\n",
              "      <td>286</td>\n",
              "      <td>1041</td>\n",
              "      <td>183166</td>\n",
              "      <td>158131</td>\n",
              "      <td>3853.0</td>\n",
              "      <td>4109.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>989.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1685.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63801.0</td>\n",
              "      <td>40769</td>\n",
              "      <td>39028</td>\n",
              "      <td>39899.0</td>\n",
              "      <td>34246.0</td>\n",
              "      <td>5546.0</td>\n",
              "      <td>17745</td>\n",
              "      <td>5555.0</td>\n",
              "      <td>170947.0</td>\n",
              "      <td>-12816.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FARMERS STATE BANK</th>\n",
              "      <td>175</td>\n",
              "      <td>405</td>\n",
              "      <td>80756</td>\n",
              "      <td>62379</td>\n",
              "      <td>1736.0</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>975.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26164.0</td>\n",
              "      <td>16287</td>\n",
              "      <td>16287</td>\n",
              "      <td>14789.0</td>\n",
              "      <td>13116.0</td>\n",
              "      <td>1673.0</td>\n",
              "      <td>5737</td>\n",
              "      <td>2731.0</td>\n",
              "      <td>63667.0</td>\n",
              "      <td>-1288.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>FIRST BANK</th>\n",
              "      <td>445</td>\n",
              "      <td>507</td>\n",
              "      <td>61227</td>\n",
              "      <td>53416</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6510.0</td>\n",
              "      <td>4391</td>\n",
              "      <td>4134</td>\n",
              "      <td>12889.0</td>\n",
              "      <td>11398.0</td>\n",
              "      <td>1057.0</td>\n",
              "      <td>3796</td>\n",
              "      <td>1137.0</td>\n",
              "      <td>57466.0</td>\n",
              "      <td>-4050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>WOODFORD STATE BANK</th>\n",
              "      <td>122</td>\n",
              "      <td>274</td>\n",
              "      <td>77724</td>\n",
              "      <td>70622</td>\n",
              "      <td>2189.0</td>\n",
              "      <td>2241.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4625.0</td>\n",
              "      <td>3402</td>\n",
              "      <td>3402</td>\n",
              "      <td>12530.0</td>\n",
              "      <td>11298.0</td>\n",
              "      <td>1232.0</td>\n",
              "      <td>4395</td>\n",
              "      <td>828.0</td>\n",
              "      <td>73658.0</td>\n",
              "      <td>-3036.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PORTAGE COUNTY BANK</th>\n",
              "      <td>193</td>\n",
              "      <td>270</td>\n",
              "      <td>43399</td>\n",
              "      <td>38108</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7410.0</td>\n",
              "      <td>5210</td>\n",
              "      <td>4209</td>\n",
              "      <td>7628.0</td>\n",
              "      <td>7324.0</td>\n",
              "      <td>304.0</td>\n",
              "      <td>4525</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>40355.0</td>\n",
              "      <td>-2247.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JEFFERSON SECURITY BANK</th>\n",
              "      <td>326</td>\n",
              "      <td>1296</td>\n",
              "      <td>167966</td>\n",
              "      <td>154970</td>\n",
              "      <td>4098.0</td>\n",
              "      <td>4142.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>1296.0</td>\n",
              "      <td>674.0</td>\n",
              "      <td>2206.0</td>\n",
              "      <td>...</td>\n",
              "      <td>25692.0</td>\n",
              "      <td>22352</td>\n",
              "      <td>21826</td>\n",
              "      <td>56235.0</td>\n",
              "      <td>37530.0</td>\n",
              "      <td>18683.0</td>\n",
              "      <td>29188</td>\n",
              "      <td>18239.0</td>\n",
              "      <td>163754.0</td>\n",
              "      <td>-8784.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CAPON VALLEY BANK</th>\n",
              "      <td>201</td>\n",
              "      <td>734</td>\n",
              "      <td>112342</td>\n",
              "      <td>99922</td>\n",
              "      <td>3163.0</td>\n",
              "      <td>3237.0</td>\n",
              "      <td>165.0</td>\n",
              "      <td>734.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>1106.0</td>\n",
              "      <td>...</td>\n",
              "      <td>9335.0</td>\n",
              "      <td>4790</td>\n",
              "      <td>4790</td>\n",
              "      <td>17341.0</td>\n",
              "      <td>16503.0</td>\n",
              "      <td>838.0</td>\n",
              "      <td>4785</td>\n",
              "      <td>4785.0</td>\n",
              "      <td>101555.0</td>\n",
              "      <td>-1633.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>G W JONES EXCHANGE BANK</th>\n",
              "      <td>104</td>\n",
              "      <td>406</td>\n",
              "      <td>52286</td>\n",
              "      <td>47311</td>\n",
              "      <td>1245.0</td>\n",
              "      <td>1311.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>406.0</td>\n",
              "      <td>253.0</td>\n",
              "      <td>877.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1510.0</td>\n",
              "      <td>1510</td>\n",
              "      <td>0</td>\n",
              "      <td>11878.0</td>\n",
              "      <td>11136.0</td>\n",
              "      <td>742.0</td>\n",
              "      <td>5184</td>\n",
              "      <td>293.0</td>\n",
              "      <td>51040.0</td>\n",
              "      <td>-3729.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BANK OF DELIGHT</th>\n",
              "      <td>20</td>\n",
              "      <td>214</td>\n",
              "      <td>70816</td>\n",
              "      <td>58871</td>\n",
              "      <td>1969.0</td>\n",
              "      <td>1969.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>428.0</td>\n",
              "      <td>...</td>\n",
              "      <td>16738.0</td>\n",
              "      <td>9218</td>\n",
              "      <td>9008</td>\n",
              "      <td>12550.0</td>\n",
              "      <td>10227.0</td>\n",
              "      <td>2323.0</td>\n",
              "      <td>1648</td>\n",
              "      <td>808.0</td>\n",
              "      <td>61735.0</td>\n",
              "      <td>-2864.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>UNION TRUST CO</th>\n",
              "      <td>1736</td>\n",
              "      <td>2967</td>\n",
              "      <td>349343</td>\n",
              "      <td>268903</td>\n",
              "      <td>5915.0</td>\n",
              "      <td>8260.0</td>\n",
              "      <td>225.0</td>\n",
              "      <td>2967.0</td>\n",
              "      <td>1609.0</td>\n",
              "      <td>4740.0</td>\n",
              "      <td>...</td>\n",
              "      <td>84417.0</td>\n",
              "      <td>61832</td>\n",
              "      <td>61832</td>\n",
              "      <td>26235.0</td>\n",
              "      <td>3949.0</td>\n",
              "      <td>22286.0</td>\n",
              "      <td>40742</td>\n",
              "      <td>15626.0</td>\n",
              "      <td>268424.0</td>\n",
              "      <td>479.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7038 rows × 171 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d8660dac-a1cc-409a-b33d-33111f1753c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d8660dac-a1cc-409a-b33d-33111f1753c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d8660dac-a1cc-409a-b33d-33111f1753c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ddmb_JMmTDQn"
      },
      "outputs": [],
      "source": [
        "file_names = [\"2008q3_file .csv\", \"2008q4_file.csv\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4W2PXzjaUHvs"
      },
      "outputs": [],
      "source": [
        "data2008 = process_data_files(file_names)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_names = [\"2022q3_file.csv\", \"2022q4_file.csv\"]"
      ],
      "metadata": {
        "id": "42zXmxpFmTym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2022 = process_data_files(file_names)"
      ],
      "metadata": {
        "id": "WDcPylcumriT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([data2001,data2008,data2022], axis=0, ignore_index=True)\n"
      ],
      "metadata": {
        "id": "ETwT-rPImvIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "lXFaAPflkHLU",
        "outputId": "7fe6cee3-b954-468f-c53b-77cd98f9ec9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADDNONII  ADDNONINTEXP    ASSET    DEP_x  EDEPDOM  EINTEXP  ELNATR  \\\n",
              "0           286          1041   183166   158131   3853.0   4109.0   360.0   \n",
              "1           175           405    80756    62379   1736.0   1935.0    60.0   \n",
              "2           445           507    61227    53416   1518.0   1645.0    27.0   \n",
              "3           122           274    77724    70622   2189.0   2241.0    90.0   \n",
              "4           193           270    43399    38108   1089.0   1100.0    36.0   \n",
              "...         ...           ...      ...      ...      ...      ...     ...   \n",
              "16501       226          1165   262061   227154    561.0    800.0     NaN   \n",
              "16502       379           299    75196    67570     92.0     92.0     NaN   \n",
              "16503      2236          5747  1866957  1769119   3507.0   3507.0     NaN   \n",
              "16504       701          1780   200966   181387    396.0    432.0     NaN   \n",
              "16505       430           757   111886   103662     71.0    104.0     NaN   \n",
              "\n",
              "       EOTHNINT  EPREMAGG    ESAL  ...  SCNM5T15    ASSET.1      DEP.1  \\\n",
              "0         989.0     507.0  1685.0  ...       NaN        NaN        NaN   \n",
              "1         405.0     175.0   975.0  ...       NaN        NaN        NaN   \n",
              "2         500.0     288.0   950.0  ...       NaN        NaN        NaN   \n",
              "3         274.0     206.0   933.0  ...       NaN        NaN        NaN   \n",
              "4         270.0     103.0   586.0  ...       NaN        NaN        NaN   \n",
              "...         ...       ...     ...  ...       ...        ...        ...   \n",
              "16501    1165.0     376.0  2737.0  ...    6802.0   262061.0   227154.0   \n",
              "16502     299.0     114.0   574.0  ...       0.0    75196.0    67570.0   \n",
              "16503    5747.0     932.0  7411.0  ...   56053.0  1866957.0  1769119.0   \n",
              "16504    1780.0     659.0  2470.0  ...    2429.0   200966.0   181387.0   \n",
              "16505     757.0     292.0  1024.0  ...    1803.0   111886.0   103662.0   \n",
              "\n",
              "       ICHBAL  IOTHII  NETINBM   DEPSMB  DEPSMRN  NETINC.1  NTRTMMED  \n",
              "0         NaN     NaN      NaN      NaN      NaN       NaN       NaN  \n",
              "1         NaN     NaN      NaN      NaN      NaN       NaN       NaN  \n",
              "2         NaN     NaN      NaN      NaN      NaN       NaN       NaN  \n",
              "3         NaN     NaN      NaN      NaN      NaN       NaN       NaN  \n",
              "4         NaN     NaN      NaN      NaN      NaN       NaN       NaN  \n",
              "...       ...     ...      ...      ...      ...       ...       ...  \n",
              "16501   109.0    40.0   1652.0   8615.0    252.0    1652.0    5777.0  \n",
              "16502   109.0     2.0    122.0   2344.0    124.0     122.0    1791.0  \n",
              "16503  2384.0    79.0  17649.0  21380.0    396.0   17649.0   35755.0  \n",
              "16504   111.0    43.0   1434.0  11298.0    413.0    1434.0   19997.0  \n",
              "16505   208.0     0.0   1006.0   4215.0     59.0    1006.0    2005.0  \n",
              "\n",
              "[16506 rows x 201 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bc12926e-dc75-4ee1-86d6-9110b1fabc20\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASSET</th>\n",
              "      <th>DEP_x</th>\n",
              "      <th>EDEPDOM</th>\n",
              "      <th>EINTEXP</th>\n",
              "      <th>ELNATR</th>\n",
              "      <th>EOTHNINT</th>\n",
              "      <th>EPREMAGG</th>\n",
              "      <th>ESAL</th>\n",
              "      <th>...</th>\n",
              "      <th>SCNM5T15</th>\n",
              "      <th>ASSET.1</th>\n",
              "      <th>DEP.1</th>\n",
              "      <th>ICHBAL</th>\n",
              "      <th>IOTHII</th>\n",
              "      <th>NETINBM</th>\n",
              "      <th>DEPSMB</th>\n",
              "      <th>DEPSMRN</th>\n",
              "      <th>NETINC.1</th>\n",
              "      <th>NTRTMMED</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>286</td>\n",
              "      <td>1041</td>\n",
              "      <td>183166</td>\n",
              "      <td>158131</td>\n",
              "      <td>3853.0</td>\n",
              "      <td>4109.0</td>\n",
              "      <td>360.0</td>\n",
              "      <td>989.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1685.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>405</td>\n",
              "      <td>80756</td>\n",
              "      <td>62379</td>\n",
              "      <td>1736.0</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>975.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>445</td>\n",
              "      <td>507</td>\n",
              "      <td>61227</td>\n",
              "      <td>53416</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>122</td>\n",
              "      <td>274</td>\n",
              "      <td>77724</td>\n",
              "      <td>70622</td>\n",
              "      <td>2189.0</td>\n",
              "      <td>2241.0</td>\n",
              "      <td>90.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>193</td>\n",
              "      <td>270</td>\n",
              "      <td>43399</td>\n",
              "      <td>38108</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>36.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16501</th>\n",
              "      <td>226</td>\n",
              "      <td>1165</td>\n",
              "      <td>262061</td>\n",
              "      <td>227154</td>\n",
              "      <td>561.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>2737.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6802.0</td>\n",
              "      <td>262061.0</td>\n",
              "      <td>227154.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>8615.0</td>\n",
              "      <td>252.0</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>5777.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16502</th>\n",
              "      <td>379</td>\n",
              "      <td>299</td>\n",
              "      <td>75196</td>\n",
              "      <td>67570</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>299.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75196.0</td>\n",
              "      <td>67570.0</td>\n",
              "      <td>109.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>2344.0</td>\n",
              "      <td>124.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>1791.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16503</th>\n",
              "      <td>2236</td>\n",
              "      <td>5747</td>\n",
              "      <td>1866957</td>\n",
              "      <td>1769119</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5747.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>7411.0</td>\n",
              "      <td>...</td>\n",
              "      <td>56053.0</td>\n",
              "      <td>1866957.0</td>\n",
              "      <td>1769119.0</td>\n",
              "      <td>2384.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17649.0</td>\n",
              "      <td>21380.0</td>\n",
              "      <td>396.0</td>\n",
              "      <td>17649.0</td>\n",
              "      <td>35755.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16504</th>\n",
              "      <td>701</td>\n",
              "      <td>1780</td>\n",
              "      <td>200966</td>\n",
              "      <td>181387</td>\n",
              "      <td>396.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1780.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>2470.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2429.0</td>\n",
              "      <td>200966.0</td>\n",
              "      <td>181387.0</td>\n",
              "      <td>111.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>1434.0</td>\n",
              "      <td>11298.0</td>\n",
              "      <td>413.0</td>\n",
              "      <td>1434.0</td>\n",
              "      <td>19997.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>430</td>\n",
              "      <td>757</td>\n",
              "      <td>111886</td>\n",
              "      <td>103662</td>\n",
              "      <td>71.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>757.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1803.0</td>\n",
              "      <td>111886.0</td>\n",
              "      <td>103662.0</td>\n",
              "      <td>208.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>4215.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>2005.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16506 rows × 201 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc12926e-dc75-4ee1-86d6-9110b1fabc20')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bc12926e-dc75-4ee1-86d6-9110b1fabc20 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bc12926e-dc75-4ee1-86d6-9110b1fabc20');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = merged_df.dropna(axis=1)"
      ],
      "metadata": {
        "id": "ogbY_6gg6sEV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_numeric(value):\n",
        "    if pd.isna(value):\n",
        "        return False\n",
        "    try:\n",
        "        float(value)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ],
      "metadata": {
        "id": "1QP2FLYLoOKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_df = merged_df.applymap(is_numeric)\n",
        "\n",
        "# drop columns that contain only non-numeric values (i.e. all cells are letters)\n",
        "non_numeric_cols = (numeric_df == False).all()\n",
        "merged_df = merged_df.loc[:, ~non_numeric_cols]"
      ],
      "metadata": {
        "id": "EF8kd3QZoSYU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df['change%'] = merged_df['change_depot']/merged_df['DEP_x']"
      ],
      "metadata": {
        "id": "S9RUd0i8wKET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e-vZeyVDnA8L"
      },
      "outputs": [],
      "source": [
        "exclude_cols = ['ID', 'NAME', 'DEP_x','change_depot','DEP_y','RISDATE','change%']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "705YnK_ntUou"
      },
      "outputs": [],
      "source": [
        "included_cols = [col for col in merged_df.columns if col not in exclude_cols]\n",
        "data = merged_df[included_cols]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "NM--FLa2uAnP",
        "outputId": "77cc2f0c-0149-4e6d-dcb7-c8246c420570"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADDNONII  ADDNONINTEXP    ASSET  EDEPDOM  EINTEXP  EOTHNINT  EPREMAGG  \\\n",
              "0           286          1041   183166   3853.0   4109.0     989.0     507.0   \n",
              "1           175           405    80756   1736.0   1935.0     405.0     175.0   \n",
              "2           445           507    61227   1518.0   1645.0     500.0     288.0   \n",
              "3           122           274    77724   2189.0   2241.0     274.0     206.0   \n",
              "4           193           270    43399   1089.0   1100.0     270.0     103.0   \n",
              "...         ...           ...      ...      ...      ...       ...       ...   \n",
              "16501       226          1165   262061    561.0    800.0    1165.0     376.0   \n",
              "16502       379           299    75196     92.0     92.0     299.0     114.0   \n",
              "16503      2236          5747  1866957   3507.0   3507.0    5747.0     932.0   \n",
              "16504       701          1780   200966    396.0    432.0    1780.0     659.0   \n",
              "16505       430           757   111886     71.0    104.0     757.0     292.0   \n",
              "\n",
              "         ESAL  IBEFXTR   ILNDOM  ...      SC    SCAF  SCPLEDGE   SCRDEBT  \\\n",
              "0      1685.0   1645.0   6161.0  ...   63801   54469   28595.0   63801.0   \n",
              "1       975.0    632.0   3195.0  ...   26214   26214    3898.0   26164.0   \n",
              "2       950.0    276.0   2678.0  ...    6510    6510    1808.0    6510.0   \n",
              "3       933.0    518.0   3817.0  ...    4624       0     200.0    4625.0   \n",
              "4       586.0    566.0   2068.0  ...    7412       0       0.0    7410.0   \n",
              "...       ...      ...      ...  ...     ...     ...       ...       ...   \n",
              "16501  2737.0   1652.0   5698.0  ...   68548   66110   41122.0   68548.0   \n",
              "16502   574.0    122.0    493.0  ...   26910       0    5025.0   26869.0   \n",
              "16503  7411.0  17649.0  18311.0  ...  925496  925391  362792.0  925392.0   \n",
              "16504  2470.0   1434.0   5544.0  ...   42761   42761    6666.0   42761.0   \n",
              "16505  1024.0   1006.0   1029.0  ...   42195    8491     500.0   42195.0   \n",
              "\n",
              "         SCUS   SCUSO       TRN  TRNIPCOC      UC   UCOTHER  \n",
              "0       40769   39028   39899.0   34246.0   17745    5555.0  \n",
              "1       16287   16287   14789.0   13116.0    5737    2731.0  \n",
              "2        4391    4134   12889.0   11398.0    3796    1137.0  \n",
              "3        3402    3402   12530.0   11298.0    4395     828.0  \n",
              "4        5210    4209    7628.0    7324.0    4525    1297.0  \n",
              "...       ...     ...       ...       ...     ...       ...  \n",
              "16501   58410   11458  125457.0  117578.0   53722   50482.0  \n",
              "16502   26828       0   33590.0   30501.0    4414    3417.0  \n",
              "16503  851863  851863  100471.0   66647.0  214235  102940.0  \n",
              "16504   16776   13986   69141.0   65518.0   23833    5522.0  \n",
              "16505   20085    9067   67325.0   62975.0    3771     305.0  \n",
              "\n",
              "[16506 rows x 132 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6a97e26a-8150-4f86-bc77-d7d80af559a3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASSET</th>\n",
              "      <th>EDEPDOM</th>\n",
              "      <th>EINTEXP</th>\n",
              "      <th>EOTHNINT</th>\n",
              "      <th>EPREMAGG</th>\n",
              "      <th>ESAL</th>\n",
              "      <th>IBEFXTR</th>\n",
              "      <th>ILNDOM</th>\n",
              "      <th>...</th>\n",
              "      <th>SC</th>\n",
              "      <th>SCAF</th>\n",
              "      <th>SCPLEDGE</th>\n",
              "      <th>SCRDEBT</th>\n",
              "      <th>SCUS</th>\n",
              "      <th>SCUSO</th>\n",
              "      <th>TRN</th>\n",
              "      <th>TRNIPCOC</th>\n",
              "      <th>UC</th>\n",
              "      <th>UCOTHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>286</td>\n",
              "      <td>1041</td>\n",
              "      <td>183166</td>\n",
              "      <td>3853.0</td>\n",
              "      <td>4109.0</td>\n",
              "      <td>989.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1685.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>6161.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63801</td>\n",
              "      <td>54469</td>\n",
              "      <td>28595.0</td>\n",
              "      <td>63801.0</td>\n",
              "      <td>40769</td>\n",
              "      <td>39028</td>\n",
              "      <td>39899.0</td>\n",
              "      <td>34246.0</td>\n",
              "      <td>17745</td>\n",
              "      <td>5555.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>405</td>\n",
              "      <td>80756</td>\n",
              "      <td>1736.0</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>975.0</td>\n",
              "      <td>632.0</td>\n",
              "      <td>3195.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26214</td>\n",
              "      <td>26214</td>\n",
              "      <td>3898.0</td>\n",
              "      <td>26164.0</td>\n",
              "      <td>16287</td>\n",
              "      <td>16287</td>\n",
              "      <td>14789.0</td>\n",
              "      <td>13116.0</td>\n",
              "      <td>5737</td>\n",
              "      <td>2731.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>445</td>\n",
              "      <td>507</td>\n",
              "      <td>61227</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>2678.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6510</td>\n",
              "      <td>6510</td>\n",
              "      <td>1808.0</td>\n",
              "      <td>6510.0</td>\n",
              "      <td>4391</td>\n",
              "      <td>4134</td>\n",
              "      <td>12889.0</td>\n",
              "      <td>11398.0</td>\n",
              "      <td>3796</td>\n",
              "      <td>1137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>122</td>\n",
              "      <td>274</td>\n",
              "      <td>77724</td>\n",
              "      <td>2189.0</td>\n",
              "      <td>2241.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>518.0</td>\n",
              "      <td>3817.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4624</td>\n",
              "      <td>0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4625.0</td>\n",
              "      <td>3402</td>\n",
              "      <td>3402</td>\n",
              "      <td>12530.0</td>\n",
              "      <td>11298.0</td>\n",
              "      <td>4395</td>\n",
              "      <td>828.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>193</td>\n",
              "      <td>270</td>\n",
              "      <td>43399</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>2068.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7412</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7410.0</td>\n",
              "      <td>5210</td>\n",
              "      <td>4209</td>\n",
              "      <td>7628.0</td>\n",
              "      <td>7324.0</td>\n",
              "      <td>4525</td>\n",
              "      <td>1297.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16501</th>\n",
              "      <td>226</td>\n",
              "      <td>1165</td>\n",
              "      <td>262061</td>\n",
              "      <td>561.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>2737.0</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>5698.0</td>\n",
              "      <td>...</td>\n",
              "      <td>68548</td>\n",
              "      <td>66110</td>\n",
              "      <td>41122.0</td>\n",
              "      <td>68548.0</td>\n",
              "      <td>58410</td>\n",
              "      <td>11458</td>\n",
              "      <td>125457.0</td>\n",
              "      <td>117578.0</td>\n",
              "      <td>53722</td>\n",
              "      <td>50482.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16502</th>\n",
              "      <td>379</td>\n",
              "      <td>299</td>\n",
              "      <td>75196</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26910</td>\n",
              "      <td>0</td>\n",
              "      <td>5025.0</td>\n",
              "      <td>26869.0</td>\n",
              "      <td>26828</td>\n",
              "      <td>0</td>\n",
              "      <td>33590.0</td>\n",
              "      <td>30501.0</td>\n",
              "      <td>4414</td>\n",
              "      <td>3417.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16503</th>\n",
              "      <td>2236</td>\n",
              "      <td>5747</td>\n",
              "      <td>1866957</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>5747.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>7411.0</td>\n",
              "      <td>17649.0</td>\n",
              "      <td>18311.0</td>\n",
              "      <td>...</td>\n",
              "      <td>925496</td>\n",
              "      <td>925391</td>\n",
              "      <td>362792.0</td>\n",
              "      <td>925392.0</td>\n",
              "      <td>851863</td>\n",
              "      <td>851863</td>\n",
              "      <td>100471.0</td>\n",
              "      <td>66647.0</td>\n",
              "      <td>214235</td>\n",
              "      <td>102940.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16504</th>\n",
              "      <td>701</td>\n",
              "      <td>1780</td>\n",
              "      <td>200966</td>\n",
              "      <td>396.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>1780.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>2470.0</td>\n",
              "      <td>1434.0</td>\n",
              "      <td>5544.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42761</td>\n",
              "      <td>42761</td>\n",
              "      <td>6666.0</td>\n",
              "      <td>42761.0</td>\n",
              "      <td>16776</td>\n",
              "      <td>13986</td>\n",
              "      <td>69141.0</td>\n",
              "      <td>65518.0</td>\n",
              "      <td>23833</td>\n",
              "      <td>5522.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>430</td>\n",
              "      <td>757</td>\n",
              "      <td>111886</td>\n",
              "      <td>71.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>757.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42195</td>\n",
              "      <td>8491</td>\n",
              "      <td>500.0</td>\n",
              "      <td>42195.0</td>\n",
              "      <td>20085</td>\n",
              "      <td>9067</td>\n",
              "      <td>67325.0</td>\n",
              "      <td>62975.0</td>\n",
              "      <td>3771</td>\n",
              "      <td>305.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16506 rows × 132 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a97e26a-8150-4f86-bc77-d7d80af559a3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a97e26a-8150-4f86-bc77-d7d80af559a3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a97e26a-8150-4f86-bc77-d7d80af559a3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop(['ZIP',\"CERT\",'RSSDID','IDLNCORR'],axis =1)"
      ],
      "metadata": {
        "id": "ox-og6x3hINm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "def drop_high_vif_cols(df, threshold=5.0, sample_size=30):\n",
        "    \"\"\"\n",
        "    Iteratively drops columns from the input DataFrame with high VIF values until all VIF values are below the threshold.\n",
        "    For each iteration, a random sample of columns of size 'sample_size' is selected to calculate the VIF values.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    df : pandas DataFrame\n",
        "        Input DataFrame containing the data\n",
        "    threshold : float, default 5.0\n",
        "        The threshold VIF value above which columns will be dropped\n",
        "    sample_size : int, default 30\n",
        "        The number of columns to select as a random sample for each iteration\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pandas DataFrame\n",
        "        The final DataFrame after dropping columns with high VIF values\n",
        "    \"\"\"\n",
        "    # create a copy of the input DataFrame to work on\n",
        "    df_vif = df.copy()\n",
        "\n",
        "    # create a loop to drop columns with high VIF values iteratively\n",
        "    while True:\n",
        "        # select a random sample of columns to calculate VIF\n",
        "        columns = np.random.choice(df_vif.columns, size=min(sample_size, df_vif.shape[1]), replace=False)\n",
        "        df_vif_sample = df_vif[columns]\n",
        "\n",
        "        # calculate VIF values for the selected columns\n",
        "        vif = pd.DataFrame()\n",
        "        vif[\"VIF Factor\"] = [variance_inflation_factor(df_vif_sample.values, i) for i in range(df_vif_sample.shape[1])]\n",
        "        vif[\"features\"] = df_vif_sample.columns\n",
        "\n",
        "        # find the column with the highest VIF value\n",
        "        max_vif = vif[\"VIF Factor\"].max()\n",
        "        max_vif_idx = vif[\"VIF Factor\"].idxmax()\n",
        "\n",
        "        # if the highest VIF value is below the threshold, break out of the loop\n",
        "        if max_vif < threshold:\n",
        "            break\n",
        "\n",
        "        # drop the column with the highest VIF value from the DataFrame\n",
        "        df_vif = df_vif.drop(df_vif_sample.columns[max_vif_idx], axis=1)\n",
        "\n",
        "    # return the final DataFrame after dropping columns with high VIF values\n",
        "    return df_vif\n"
      ],
      "metadata": {
        "id": "8Go6g7zriC29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vif = drop_high_vif_cols(data)"
      ],
      "metadata": {
        "id": "glXxLOQINqgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbeUA6w-u8lE"
      },
      "outputs": [],
      "source": [
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [round(variance_inflation_factor(df_vif.values, i), 2) for i in range(df_vif.shape[1])]\n",
        "vif[\"features\"] = df_vif.columns\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_vif"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tiQEPQV19vwK",
        "outputId": "c7422603-1067-4090-c607-e4f63484e335"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       IOTNII    CD1T3   CD3T12  CDOV3S      DDT  EQCCOMPI    EQCS   NTRMUNI  \\\n",
              "0       278.0   4949.0   5582.0  3234.0  15718.0     806.0   962.0    5481.0   \n",
              "1       164.0   2884.0   1558.0  3147.0   7498.0     403.0   150.0    3896.0   \n",
              "2       102.0   2337.0   2509.0   559.0   7596.0     182.0  1043.0    1204.0   \n",
              "3        21.0   1743.0   3768.0   536.0   7464.0       0.0    64.0     431.0   \n",
              "4       193.0   1092.0   1394.0     0.0   5479.0       0.0   125.0    2161.0   \n",
              "...       ...      ...      ...     ...      ...       ...     ...       ...   \n",
              "16501   257.0   2388.0   1832.0   751.0  56083.0   -4392.0   504.0   27398.0   \n",
              "16502   379.0      0.0      0.0    75.0  18854.0    -134.0   200.0    2195.0   \n",
              "16503  1833.0  35582.0  59786.0  1524.0  71537.0 -123425.0  1800.0  215705.0   \n",
              "16504   615.0   1124.0   1638.0  4052.0  55232.0   -2908.0   180.0    8483.0   \n",
              "16505   430.0    337.0   2772.0  1049.0  66970.0   -1333.0   150.0     137.0   \n",
              "\n",
              "         ASTEMPM      EEFFR  ...   NTLNLSR    ROAPTX    ROE    ROEINJR  \\\n",
              "0       2.289575  53.444220  ...  0.206844  1.744677  13.84   7.284781   \n",
              "1       2.990963  63.729508  ...  0.090004  1.456811   7.32   5.139430   \n",
              "2       1.700750  81.443299  ...  0.132766  0.804367   5.92  -0.622486   \n",
              "3       2.507226  61.301518  ...  0.079407  1.480613  13.88  13.875427   \n",
              "4       2.169950  61.434978  ...  0.104543  1.757580  16.01   9.619055   \n",
              "...          ...        ...  ...       ...       ...    ...        ...   \n",
              "16501   7.487457  72.410291  ...  0.002422  0.883060  10.22   0.321695   \n",
              "16502   6.266333  88.838884  ...  0.000000  0.206526   2.21   2.210240   \n",
              "16503  14.935656  38.454191  ...  0.016027  1.455153  16.38  16.377795   \n",
              "16504   4.275872  72.372107  ... -0.023226  1.212002  10.60   6.446920   \n",
              "16505   5.594300  64.599564  ...  0.000000  1.397043  17.45  17.448937   \n",
              "\n",
              "       LNCONOTH  LNEXAMT  LNRECONS  LNRS1T3  LNRS3LES  SCPLEDGE  \n",
              "0       13139.0   4785.0     191.0   4854.0    1215.0   28595.0  \n",
              "1        4111.0     78.0     574.0   4640.0    2207.0    3898.0  \n",
              "2        2663.0    385.0    1743.0   6967.0    2217.0    1808.0  \n",
              "3        7406.0   1541.0    3037.0  10551.0    3388.0     200.0  \n",
              "4        1675.0    756.0    3052.0   3526.0    2076.0       0.0  \n",
              "...         ...      ...       ...      ...       ...       ...  \n",
              "16501    1789.0   6024.0    6467.0   1954.0     292.0   41122.0  \n",
              "16502     223.0      0.0     685.0    301.0       0.0    5025.0  \n",
              "16503    6944.0   2399.0   76308.0   4502.0     947.0  362792.0  \n",
              "16504   10128.0    832.0   15786.0   2535.0    2246.0    6666.0  \n",
              "16505     966.0    568.0     531.0    274.0     266.0     500.0  \n",
              "\n",
              "[16506 rows x 27 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-29b22dc1-7290-4e58-8b3c-faebcc775030\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IOTNII</th>\n",
              "      <th>CD1T3</th>\n",
              "      <th>CD3T12</th>\n",
              "      <th>CDOV3S</th>\n",
              "      <th>DDT</th>\n",
              "      <th>EQCCOMPI</th>\n",
              "      <th>EQCS</th>\n",
              "      <th>NTRMUNI</th>\n",
              "      <th>ASTEMPM</th>\n",
              "      <th>EEFFR</th>\n",
              "      <th>...</th>\n",
              "      <th>NTLNLSR</th>\n",
              "      <th>ROAPTX</th>\n",
              "      <th>ROE</th>\n",
              "      <th>ROEINJR</th>\n",
              "      <th>LNCONOTH</th>\n",
              "      <th>LNEXAMT</th>\n",
              "      <th>LNRECONS</th>\n",
              "      <th>LNRS1T3</th>\n",
              "      <th>LNRS3LES</th>\n",
              "      <th>SCPLEDGE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>278.0</td>\n",
              "      <td>4949.0</td>\n",
              "      <td>5582.0</td>\n",
              "      <td>3234.0</td>\n",
              "      <td>15718.0</td>\n",
              "      <td>806.0</td>\n",
              "      <td>962.0</td>\n",
              "      <td>5481.0</td>\n",
              "      <td>2.289575</td>\n",
              "      <td>53.444220</td>\n",
              "      <td>...</td>\n",
              "      <td>0.206844</td>\n",
              "      <td>1.744677</td>\n",
              "      <td>13.84</td>\n",
              "      <td>7.284781</td>\n",
              "      <td>13139.0</td>\n",
              "      <td>4785.0</td>\n",
              "      <td>191.0</td>\n",
              "      <td>4854.0</td>\n",
              "      <td>1215.0</td>\n",
              "      <td>28595.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>164.0</td>\n",
              "      <td>2884.0</td>\n",
              "      <td>1558.0</td>\n",
              "      <td>3147.0</td>\n",
              "      <td>7498.0</td>\n",
              "      <td>403.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>3896.0</td>\n",
              "      <td>2.990963</td>\n",
              "      <td>63.729508</td>\n",
              "      <td>...</td>\n",
              "      <td>0.090004</td>\n",
              "      <td>1.456811</td>\n",
              "      <td>7.32</td>\n",
              "      <td>5.139430</td>\n",
              "      <td>4111.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>4640.0</td>\n",
              "      <td>2207.0</td>\n",
              "      <td>3898.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>102.0</td>\n",
              "      <td>2337.0</td>\n",
              "      <td>2509.0</td>\n",
              "      <td>559.0</td>\n",
              "      <td>7596.0</td>\n",
              "      <td>182.0</td>\n",
              "      <td>1043.0</td>\n",
              "      <td>1204.0</td>\n",
              "      <td>1.700750</td>\n",
              "      <td>81.443299</td>\n",
              "      <td>...</td>\n",
              "      <td>0.132766</td>\n",
              "      <td>0.804367</td>\n",
              "      <td>5.92</td>\n",
              "      <td>-0.622486</td>\n",
              "      <td>2663.0</td>\n",
              "      <td>385.0</td>\n",
              "      <td>1743.0</td>\n",
              "      <td>6967.0</td>\n",
              "      <td>2217.0</td>\n",
              "      <td>1808.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>21.0</td>\n",
              "      <td>1743.0</td>\n",
              "      <td>3768.0</td>\n",
              "      <td>536.0</td>\n",
              "      <td>7464.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>431.0</td>\n",
              "      <td>2.507226</td>\n",
              "      <td>61.301518</td>\n",
              "      <td>...</td>\n",
              "      <td>0.079407</td>\n",
              "      <td>1.480613</td>\n",
              "      <td>13.88</td>\n",
              "      <td>13.875427</td>\n",
              "      <td>7406.0</td>\n",
              "      <td>1541.0</td>\n",
              "      <td>3037.0</td>\n",
              "      <td>10551.0</td>\n",
              "      <td>3388.0</td>\n",
              "      <td>200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>193.0</td>\n",
              "      <td>1092.0</td>\n",
              "      <td>1394.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5479.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>125.0</td>\n",
              "      <td>2161.0</td>\n",
              "      <td>2.169950</td>\n",
              "      <td>61.434978</td>\n",
              "      <td>...</td>\n",
              "      <td>0.104543</td>\n",
              "      <td>1.757580</td>\n",
              "      <td>16.01</td>\n",
              "      <td>9.619055</td>\n",
              "      <td>1675.0</td>\n",
              "      <td>756.0</td>\n",
              "      <td>3052.0</td>\n",
              "      <td>3526.0</td>\n",
              "      <td>2076.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16501</th>\n",
              "      <td>257.0</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>1832.0</td>\n",
              "      <td>751.0</td>\n",
              "      <td>56083.0</td>\n",
              "      <td>-4392.0</td>\n",
              "      <td>504.0</td>\n",
              "      <td>27398.0</td>\n",
              "      <td>7.487457</td>\n",
              "      <td>72.410291</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002422</td>\n",
              "      <td>0.883060</td>\n",
              "      <td>10.22</td>\n",
              "      <td>0.321695</td>\n",
              "      <td>1789.0</td>\n",
              "      <td>6024.0</td>\n",
              "      <td>6467.0</td>\n",
              "      <td>1954.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>41122.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16502</th>\n",
              "      <td>379.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>18854.0</td>\n",
              "      <td>-134.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>2195.0</td>\n",
              "      <td>6.266333</td>\n",
              "      <td>88.838884</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.206526</td>\n",
              "      <td>2.21</td>\n",
              "      <td>2.210240</td>\n",
              "      <td>223.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>685.0</td>\n",
              "      <td>301.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5025.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16503</th>\n",
              "      <td>1833.0</td>\n",
              "      <td>35582.0</td>\n",
              "      <td>59786.0</td>\n",
              "      <td>1524.0</td>\n",
              "      <td>71537.0</td>\n",
              "      <td>-123425.0</td>\n",
              "      <td>1800.0</td>\n",
              "      <td>215705.0</td>\n",
              "      <td>14.935656</td>\n",
              "      <td>38.454191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.016027</td>\n",
              "      <td>1.455153</td>\n",
              "      <td>16.38</td>\n",
              "      <td>16.377795</td>\n",
              "      <td>6944.0</td>\n",
              "      <td>2399.0</td>\n",
              "      <td>76308.0</td>\n",
              "      <td>4502.0</td>\n",
              "      <td>947.0</td>\n",
              "      <td>362792.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16504</th>\n",
              "      <td>615.0</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>1638.0</td>\n",
              "      <td>4052.0</td>\n",
              "      <td>55232.0</td>\n",
              "      <td>-2908.0</td>\n",
              "      <td>180.0</td>\n",
              "      <td>8483.0</td>\n",
              "      <td>4.275872</td>\n",
              "      <td>72.372107</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.023226</td>\n",
              "      <td>1.212002</td>\n",
              "      <td>10.60</td>\n",
              "      <td>6.446920</td>\n",
              "      <td>10128.0</td>\n",
              "      <td>832.0</td>\n",
              "      <td>15786.0</td>\n",
              "      <td>2535.0</td>\n",
              "      <td>2246.0</td>\n",
              "      <td>6666.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>430.0</td>\n",
              "      <td>337.0</td>\n",
              "      <td>2772.0</td>\n",
              "      <td>1049.0</td>\n",
              "      <td>66970.0</td>\n",
              "      <td>-1333.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>137.0</td>\n",
              "      <td>5.594300</td>\n",
              "      <td>64.599564</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.397043</td>\n",
              "      <td>17.45</td>\n",
              "      <td>17.448937</td>\n",
              "      <td>966.0</td>\n",
              "      <td>568.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>266.0</td>\n",
              "      <td>500.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16506 rows × 27 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-29b22dc1-7290-4e58-8b3c-faebcc775030')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-29b22dc1-7290-4e58-8b3c-faebcc775030 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-29b22dc1-7290-4e58-8b3c-faebcc775030');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 440
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_vif = data"
      ],
      "metadata": {
        "id": "odNJZXJlVGVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Create a new DataFrame with a binary target column\n",
        "new_df = pd.DataFrame()\n",
        "new_df['target'] = merged_df['change%']\n",
        "new_df['target2'] = merged_df['change_depot']\n",
        "# Add the input features to the new DataFrame\n",
        "new_df = pd.concat([new_df, df_vif], axis=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "LBplUwsKZjyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "exclude_col = ['target', 'target2']\n",
        "all_cols = new_df.columns.tolist()\n",
        "cols_less_one = [col for col in all_cols if col not in exclude_col]\n"
      ],
      "metadata": {
        "id": "z0BqbsGW0H3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "exclude_col = ['target', 'target2']\n",
        "all_cols = new_df.columns.tolist()\n",
        "cols_less_one = [col for col in all_cols if col not in exclude_col]\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y = new_df['target']\n",
        "\n",
        "# Instantiate a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the input features\n",
        "scaler.fit(X)\n",
        "\n",
        "# Transform the input features using the scaler\n",
        "X_standardized = scaler.transform(X)\n",
        "\n",
        "# Create a new dataframe with the standardized input features\n",
        "df_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
        "\n",
        "# Add the target variable back to the standardized dataframe\n",
        "df_standardized['target'] = y\n",
        "df_standardized['target2'] = new_df['target2']"
      ],
      "metadata": {
        "id": "C7SALnQK51Gy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_standardized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Dm5v4UJu6yLh",
        "outputId": "8b25fd8a-f1b7-4c93-b33d-262c87ce2032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADDNONII  ADDNONINTEXP     ASSET   EDEPDOM   EINTEXP  EOTHNINT  \\\n",
              "0     -0.054940     -0.057257 -0.047432 -0.060287 -0.049253 -0.055404   \n",
              "1     -0.055293     -0.059248 -0.049716 -0.076231 -0.055415 -0.057279   \n",
              "2     -0.054436     -0.058929 -0.050151 -0.077873 -0.056237 -0.056974   \n",
              "3     -0.055461     -0.059658 -0.049783 -0.072819 -0.054548 -0.057699   \n",
              "4     -0.055236     -0.059671 -0.050549 -0.081103 -0.057781 -0.057712   \n",
              "...         ...           ...       ...       ...       ...       ...   \n",
              "16501 -0.055131     -0.056869 -0.045673 -0.085080 -0.058632 -0.054839   \n",
              "16502 -0.054645     -0.059580 -0.049840 -0.088612 -0.060638 -0.057619   \n",
              "16503 -0.048753     -0.042525 -0.009887 -0.062893 -0.050960 -0.040131   \n",
              "16504 -0.053624     -0.054943 -0.047035 -0.086323 -0.059675 -0.052865   \n",
              "16505 -0.054484     -0.058146 -0.049022 -0.088770 -0.060604 -0.056149   \n",
              "\n",
              "       EPREMAGG      ESAL   IBEFXTR    ILNDOM  ...  SCPLEDGE   SCRDEBT  \\\n",
              "0     -0.049668 -0.050888 -0.045015 -0.068261  ... -0.045261 -0.039028   \n",
              "1     -0.053662 -0.052794 -0.048260 -0.073131  ... -0.053412 -0.042578   \n",
              "2     -0.052303 -0.052862 -0.049400 -0.073980  ... -0.054102 -0.044432   \n",
              "3     -0.053290 -0.052907 -0.048625 -0.072110  ... -0.054633 -0.044610   \n",
              "4     -0.054529 -0.053839 -0.048471 -0.074982  ... -0.054699 -0.044347   \n",
              "...         ...       ...       ...       ...  ...       ...       ...   \n",
              "16501 -0.051244 -0.048064 -0.044993 -0.069021  ... -0.041127 -0.038580   \n",
              "16502 -0.054396 -0.053871 -0.049893 -0.077568  ... -0.053040 -0.042512   \n",
              "16503 -0.044556 -0.035514  0.006237 -0.048311  ...  0.065037  0.042246   \n",
              "16504 -0.047840 -0.048780 -0.045691 -0.069274  ... -0.052499 -0.041013   \n",
              "16505 -0.052255 -0.052663 -0.047062 -0.076688  ... -0.054534 -0.041066   \n",
              "\n",
              "           SCUS     SCUSO       TRN  TRNIPCOC        UC   UCOTHER    target  \\\n",
              "0     -0.035769 -0.039619 -0.037108 -0.036387 -0.050641 -0.046365 -0.081047   \n",
              "1     -0.038508 -0.043476 -0.039551 -0.038640 -0.051157 -0.046668 -0.020648   \n",
              "2     -0.039839 -0.045537 -0.039736 -0.038823 -0.051240 -0.046839 -0.075820   \n",
              "3     -0.039950 -0.045661 -0.039771 -0.038833 -0.051214 -0.046873 -0.042989   \n",
              "4     -0.039747 -0.045524 -0.040248 -0.039257 -0.051209 -0.046822 -0.058964   \n",
              "...         ...       ...       ...       ...       ...       ...       ...   \n",
              "16501 -0.033795 -0.044295 -0.028781 -0.027505 -0.049094 -0.041537 -0.011706   \n",
              "16502 -0.037329 -0.046238 -0.037722 -0.036786 -0.051214 -0.046594 -0.026521   \n",
              "16503  0.054983  0.098224 -0.031213 -0.032933 -0.042195 -0.035899 -0.012254   \n",
              "16504 -0.038453 -0.043866 -0.034262 -0.033054 -0.050379 -0.046368 -0.000805   \n",
              "16505 -0.038083 -0.044700 -0.034439 -0.033325 -0.051241 -0.046929 -0.055864   \n",
              "\n",
              "       target2  \n",
              "0     -12816.0  \n",
              "1      -1288.0  \n",
              "2      -4050.0  \n",
              "3      -3036.0  \n",
              "4      -2247.0  \n",
              "...        ...  \n",
              "16501  -2659.0  \n",
              "16502  -1792.0  \n",
              "16503 -21679.0  \n",
              "16504   -146.0  \n",
              "16505  -5791.0  \n",
              "\n",
              "[16506 rows x 130 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c1a57310-48eb-4563-9e5e-9847cbc529f9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASSET</th>\n",
              "      <th>EDEPDOM</th>\n",
              "      <th>EINTEXP</th>\n",
              "      <th>EOTHNINT</th>\n",
              "      <th>EPREMAGG</th>\n",
              "      <th>ESAL</th>\n",
              "      <th>IBEFXTR</th>\n",
              "      <th>ILNDOM</th>\n",
              "      <th>...</th>\n",
              "      <th>SCPLEDGE</th>\n",
              "      <th>SCRDEBT</th>\n",
              "      <th>SCUS</th>\n",
              "      <th>SCUSO</th>\n",
              "      <th>TRN</th>\n",
              "      <th>TRNIPCOC</th>\n",
              "      <th>UC</th>\n",
              "      <th>UCOTHER</th>\n",
              "      <th>target</th>\n",
              "      <th>target2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.054940</td>\n",
              "      <td>-0.057257</td>\n",
              "      <td>-0.047432</td>\n",
              "      <td>-0.060287</td>\n",
              "      <td>-0.049253</td>\n",
              "      <td>-0.055404</td>\n",
              "      <td>-0.049668</td>\n",
              "      <td>-0.050888</td>\n",
              "      <td>-0.045015</td>\n",
              "      <td>-0.068261</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.045261</td>\n",
              "      <td>-0.039028</td>\n",
              "      <td>-0.035769</td>\n",
              "      <td>-0.039619</td>\n",
              "      <td>-0.037108</td>\n",
              "      <td>-0.036387</td>\n",
              "      <td>-0.050641</td>\n",
              "      <td>-0.046365</td>\n",
              "      <td>-0.081047</td>\n",
              "      <td>-12816.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.055293</td>\n",
              "      <td>-0.059248</td>\n",
              "      <td>-0.049716</td>\n",
              "      <td>-0.076231</td>\n",
              "      <td>-0.055415</td>\n",
              "      <td>-0.057279</td>\n",
              "      <td>-0.053662</td>\n",
              "      <td>-0.052794</td>\n",
              "      <td>-0.048260</td>\n",
              "      <td>-0.073131</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053412</td>\n",
              "      <td>-0.042578</td>\n",
              "      <td>-0.038508</td>\n",
              "      <td>-0.043476</td>\n",
              "      <td>-0.039551</td>\n",
              "      <td>-0.038640</td>\n",
              "      <td>-0.051157</td>\n",
              "      <td>-0.046668</td>\n",
              "      <td>-0.020648</td>\n",
              "      <td>-1288.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-0.054436</td>\n",
              "      <td>-0.058929</td>\n",
              "      <td>-0.050151</td>\n",
              "      <td>-0.077873</td>\n",
              "      <td>-0.056237</td>\n",
              "      <td>-0.056974</td>\n",
              "      <td>-0.052303</td>\n",
              "      <td>-0.052862</td>\n",
              "      <td>-0.049400</td>\n",
              "      <td>-0.073980</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054102</td>\n",
              "      <td>-0.044432</td>\n",
              "      <td>-0.039839</td>\n",
              "      <td>-0.045537</td>\n",
              "      <td>-0.039736</td>\n",
              "      <td>-0.038823</td>\n",
              "      <td>-0.051240</td>\n",
              "      <td>-0.046839</td>\n",
              "      <td>-0.075820</td>\n",
              "      <td>-4050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.055461</td>\n",
              "      <td>-0.059658</td>\n",
              "      <td>-0.049783</td>\n",
              "      <td>-0.072819</td>\n",
              "      <td>-0.054548</td>\n",
              "      <td>-0.057699</td>\n",
              "      <td>-0.053290</td>\n",
              "      <td>-0.052907</td>\n",
              "      <td>-0.048625</td>\n",
              "      <td>-0.072110</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054633</td>\n",
              "      <td>-0.044610</td>\n",
              "      <td>-0.039950</td>\n",
              "      <td>-0.045661</td>\n",
              "      <td>-0.039771</td>\n",
              "      <td>-0.038833</td>\n",
              "      <td>-0.051214</td>\n",
              "      <td>-0.046873</td>\n",
              "      <td>-0.042989</td>\n",
              "      <td>-3036.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.055236</td>\n",
              "      <td>-0.059671</td>\n",
              "      <td>-0.050549</td>\n",
              "      <td>-0.081103</td>\n",
              "      <td>-0.057781</td>\n",
              "      <td>-0.057712</td>\n",
              "      <td>-0.054529</td>\n",
              "      <td>-0.053839</td>\n",
              "      <td>-0.048471</td>\n",
              "      <td>-0.074982</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054699</td>\n",
              "      <td>-0.044347</td>\n",
              "      <td>-0.039747</td>\n",
              "      <td>-0.045524</td>\n",
              "      <td>-0.040248</td>\n",
              "      <td>-0.039257</td>\n",
              "      <td>-0.051209</td>\n",
              "      <td>-0.046822</td>\n",
              "      <td>-0.058964</td>\n",
              "      <td>-2247.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16501</th>\n",
              "      <td>-0.055131</td>\n",
              "      <td>-0.056869</td>\n",
              "      <td>-0.045673</td>\n",
              "      <td>-0.085080</td>\n",
              "      <td>-0.058632</td>\n",
              "      <td>-0.054839</td>\n",
              "      <td>-0.051244</td>\n",
              "      <td>-0.048064</td>\n",
              "      <td>-0.044993</td>\n",
              "      <td>-0.069021</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.041127</td>\n",
              "      <td>-0.038580</td>\n",
              "      <td>-0.033795</td>\n",
              "      <td>-0.044295</td>\n",
              "      <td>-0.028781</td>\n",
              "      <td>-0.027505</td>\n",
              "      <td>-0.049094</td>\n",
              "      <td>-0.041537</td>\n",
              "      <td>-0.011706</td>\n",
              "      <td>-2659.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16502</th>\n",
              "      <td>-0.054645</td>\n",
              "      <td>-0.059580</td>\n",
              "      <td>-0.049840</td>\n",
              "      <td>-0.088612</td>\n",
              "      <td>-0.060638</td>\n",
              "      <td>-0.057619</td>\n",
              "      <td>-0.054396</td>\n",
              "      <td>-0.053871</td>\n",
              "      <td>-0.049893</td>\n",
              "      <td>-0.077568</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.053040</td>\n",
              "      <td>-0.042512</td>\n",
              "      <td>-0.037329</td>\n",
              "      <td>-0.046238</td>\n",
              "      <td>-0.037722</td>\n",
              "      <td>-0.036786</td>\n",
              "      <td>-0.051214</td>\n",
              "      <td>-0.046594</td>\n",
              "      <td>-0.026521</td>\n",
              "      <td>-1792.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16503</th>\n",
              "      <td>-0.048753</td>\n",
              "      <td>-0.042525</td>\n",
              "      <td>-0.009887</td>\n",
              "      <td>-0.062893</td>\n",
              "      <td>-0.050960</td>\n",
              "      <td>-0.040131</td>\n",
              "      <td>-0.044556</td>\n",
              "      <td>-0.035514</td>\n",
              "      <td>0.006237</td>\n",
              "      <td>-0.048311</td>\n",
              "      <td>...</td>\n",
              "      <td>0.065037</td>\n",
              "      <td>0.042246</td>\n",
              "      <td>0.054983</td>\n",
              "      <td>0.098224</td>\n",
              "      <td>-0.031213</td>\n",
              "      <td>-0.032933</td>\n",
              "      <td>-0.042195</td>\n",
              "      <td>-0.035899</td>\n",
              "      <td>-0.012254</td>\n",
              "      <td>-21679.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16504</th>\n",
              "      <td>-0.053624</td>\n",
              "      <td>-0.054943</td>\n",
              "      <td>-0.047035</td>\n",
              "      <td>-0.086323</td>\n",
              "      <td>-0.059675</td>\n",
              "      <td>-0.052865</td>\n",
              "      <td>-0.047840</td>\n",
              "      <td>-0.048780</td>\n",
              "      <td>-0.045691</td>\n",
              "      <td>-0.069274</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.052499</td>\n",
              "      <td>-0.041013</td>\n",
              "      <td>-0.038453</td>\n",
              "      <td>-0.043866</td>\n",
              "      <td>-0.034262</td>\n",
              "      <td>-0.033054</td>\n",
              "      <td>-0.050379</td>\n",
              "      <td>-0.046368</td>\n",
              "      <td>-0.000805</td>\n",
              "      <td>-146.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>-0.054484</td>\n",
              "      <td>-0.058146</td>\n",
              "      <td>-0.049022</td>\n",
              "      <td>-0.088770</td>\n",
              "      <td>-0.060604</td>\n",
              "      <td>-0.056149</td>\n",
              "      <td>-0.052255</td>\n",
              "      <td>-0.052663</td>\n",
              "      <td>-0.047062</td>\n",
              "      <td>-0.076688</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.054534</td>\n",
              "      <td>-0.041066</td>\n",
              "      <td>-0.038083</td>\n",
              "      <td>-0.044700</td>\n",
              "      <td>-0.034439</td>\n",
              "      <td>-0.033325</td>\n",
              "      <td>-0.051241</td>\n",
              "      <td>-0.046929</td>\n",
              "      <td>-0.055864</td>\n",
              "      <td>-5791.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16506 rows × 130 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1a57310-48eb-4563-9e5e-9847cbc529f9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c1a57310-48eb-4563-9e5e-9847cbc529f9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c1a57310-48eb-4563-9e5e-9847cbc529f9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df_standardized\n",
        "new_df['target'] = new_df['target'].apply(lambda x: 1 if x <=-0.30 else 0)"
      ],
      "metadata": {
        "id": "G_lQwLVJ8OMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df['target'] = new_df['target'].apply(lambda x: 1 if x <=-0.30 else 0)"
      ],
      "metadata": {
        "id": "ZbaY6L76KBut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "value_counts = new_df['target'].value_counts(normalize=True)\n",
        "\n",
        "# print the percentage of 1's and 0's in the 'target' column\n",
        "print(\"Percentage of 1's:\", value_counts[1] * 100)\n",
        "print(\"Percentage of 0's:\", value_counts[0] * 100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rQcFFKAjdAUl",
        "outputId": "abba457d-1d18-4c17-fc42-942297afd0f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of 1's: 2.0901490367139224\n",
            "Percentage of 0's: 97.90985096328609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_df[cols_less_one]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "SxeV1w5Fs7ma",
        "outputId": "0cd9a04d-7077-4642-e073-ad2a9e86cac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ADDNONII  ADDNONINTEXP    ASSET  EDEPDOM  EINTEXP  EOTHNINT  EPREMAGG  \\\n",
              "0           286          1041   183166   3853.0   4109.0     989.0     507.0   \n",
              "1           175           405    80756   1736.0   1935.0     405.0     175.0   \n",
              "2           445           507    61227   1518.0   1645.0     500.0     288.0   \n",
              "3           122           274    77724   2189.0   2241.0     274.0     206.0   \n",
              "4           193           270    43399   1089.0   1100.0     270.0     103.0   \n",
              "...         ...           ...      ...      ...      ...       ...       ...   \n",
              "16501       226          1165   262061    561.0    800.0    1165.0     376.0   \n",
              "16502       379           299    75196     92.0     92.0     299.0     114.0   \n",
              "16503      2236          5747  1866957   3507.0   3507.0    5747.0     932.0   \n",
              "16504       701          1780   200966    396.0    432.0    1780.0     659.0   \n",
              "16505       430           757   111886     71.0    104.0     757.0     292.0   \n",
              "\n",
              "         ESAL  IBEFXTR   ILNDOM  ...      SC    SCAF  SCPLEDGE   SCRDEBT  \\\n",
              "0      1685.0   1645.0   6161.0  ...   63801   54469   28595.0   63801.0   \n",
              "1       975.0    632.0   3195.0  ...   26214   26214    3898.0   26164.0   \n",
              "2       950.0    276.0   2678.0  ...    6510    6510    1808.0    6510.0   \n",
              "3       933.0    518.0   3817.0  ...    4624       0     200.0    4625.0   \n",
              "4       586.0    566.0   2068.0  ...    7412       0       0.0    7410.0   \n",
              "...       ...      ...      ...  ...     ...     ...       ...       ...   \n",
              "16501  2737.0   1652.0   5698.0  ...   68548   66110   41122.0   68548.0   \n",
              "16502   574.0    122.0    493.0  ...   26910       0    5025.0   26869.0   \n",
              "16503  7411.0  17649.0  18311.0  ...  925496  925391  362792.0  925392.0   \n",
              "16504  2470.0   1434.0   5544.0  ...   42761   42761    6666.0   42761.0   \n",
              "16505  1024.0   1006.0   1029.0  ...   42195    8491     500.0   42195.0   \n",
              "\n",
              "         SCUS   SCUSO       TRN  TRNIPCOC      UC   UCOTHER  \n",
              "0       40769   39028   39899.0   34246.0   17745    5555.0  \n",
              "1       16287   16287   14789.0   13116.0    5737    2731.0  \n",
              "2        4391    4134   12889.0   11398.0    3796    1137.0  \n",
              "3        3402    3402   12530.0   11298.0    4395     828.0  \n",
              "4        5210    4209    7628.0    7324.0    4525    1297.0  \n",
              "...       ...     ...       ...       ...     ...       ...  \n",
              "16501   58410   11458  125457.0  117578.0   53722   50482.0  \n",
              "16502   26828       0   33590.0   30501.0    4414    3417.0  \n",
              "16503  851863  851863  100471.0   66647.0  214235  102940.0  \n",
              "16504   16776   13986   69141.0   65518.0   23833    5522.0  \n",
              "16505   20085    9067   67325.0   62975.0    3771     305.0  \n",
              "\n",
              "[16506 rows x 128 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ced8dc0a-71f2-4986-9c81-5fca8f4dec1d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ADDNONII</th>\n",
              "      <th>ADDNONINTEXP</th>\n",
              "      <th>ASSET</th>\n",
              "      <th>EDEPDOM</th>\n",
              "      <th>EINTEXP</th>\n",
              "      <th>EOTHNINT</th>\n",
              "      <th>EPREMAGG</th>\n",
              "      <th>ESAL</th>\n",
              "      <th>IBEFXTR</th>\n",
              "      <th>ILNDOM</th>\n",
              "      <th>...</th>\n",
              "      <th>SC</th>\n",
              "      <th>SCAF</th>\n",
              "      <th>SCPLEDGE</th>\n",
              "      <th>SCRDEBT</th>\n",
              "      <th>SCUS</th>\n",
              "      <th>SCUSO</th>\n",
              "      <th>TRN</th>\n",
              "      <th>TRNIPCOC</th>\n",
              "      <th>UC</th>\n",
              "      <th>UCOTHER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>286</td>\n",
              "      <td>1041</td>\n",
              "      <td>183166</td>\n",
              "      <td>3853.0</td>\n",
              "      <td>4109.0</td>\n",
              "      <td>989.0</td>\n",
              "      <td>507.0</td>\n",
              "      <td>1685.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>6161.0</td>\n",
              "      <td>...</td>\n",
              "      <td>63801</td>\n",
              "      <td>54469</td>\n",
              "      <td>28595.0</td>\n",
              "      <td>63801.0</td>\n",
              "      <td>40769</td>\n",
              "      <td>39028</td>\n",
              "      <td>39899.0</td>\n",
              "      <td>34246.0</td>\n",
              "      <td>17745</td>\n",
              "      <td>5555.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>175</td>\n",
              "      <td>405</td>\n",
              "      <td>80756</td>\n",
              "      <td>1736.0</td>\n",
              "      <td>1935.0</td>\n",
              "      <td>405.0</td>\n",
              "      <td>175.0</td>\n",
              "      <td>975.0</td>\n",
              "      <td>632.0</td>\n",
              "      <td>3195.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26214</td>\n",
              "      <td>26214</td>\n",
              "      <td>3898.0</td>\n",
              "      <td>26164.0</td>\n",
              "      <td>16287</td>\n",
              "      <td>16287</td>\n",
              "      <td>14789.0</td>\n",
              "      <td>13116.0</td>\n",
              "      <td>5737</td>\n",
              "      <td>2731.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>445</td>\n",
              "      <td>507</td>\n",
              "      <td>61227</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1645.0</td>\n",
              "      <td>500.0</td>\n",
              "      <td>288.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>276.0</td>\n",
              "      <td>2678.0</td>\n",
              "      <td>...</td>\n",
              "      <td>6510</td>\n",
              "      <td>6510</td>\n",
              "      <td>1808.0</td>\n",
              "      <td>6510.0</td>\n",
              "      <td>4391</td>\n",
              "      <td>4134</td>\n",
              "      <td>12889.0</td>\n",
              "      <td>11398.0</td>\n",
              "      <td>3796</td>\n",
              "      <td>1137.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>122</td>\n",
              "      <td>274</td>\n",
              "      <td>77724</td>\n",
              "      <td>2189.0</td>\n",
              "      <td>2241.0</td>\n",
              "      <td>274.0</td>\n",
              "      <td>206.0</td>\n",
              "      <td>933.0</td>\n",
              "      <td>518.0</td>\n",
              "      <td>3817.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4624</td>\n",
              "      <td>0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4625.0</td>\n",
              "      <td>3402</td>\n",
              "      <td>3402</td>\n",
              "      <td>12530.0</td>\n",
              "      <td>11298.0</td>\n",
              "      <td>4395</td>\n",
              "      <td>828.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>193</td>\n",
              "      <td>270</td>\n",
              "      <td>43399</td>\n",
              "      <td>1089.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>270.0</td>\n",
              "      <td>103.0</td>\n",
              "      <td>586.0</td>\n",
              "      <td>566.0</td>\n",
              "      <td>2068.0</td>\n",
              "      <td>...</td>\n",
              "      <td>7412</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>7410.0</td>\n",
              "      <td>5210</td>\n",
              "      <td>4209</td>\n",
              "      <td>7628.0</td>\n",
              "      <td>7324.0</td>\n",
              "      <td>4525</td>\n",
              "      <td>1297.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16501</th>\n",
              "      <td>226</td>\n",
              "      <td>1165</td>\n",
              "      <td>262061</td>\n",
              "      <td>561.0</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>376.0</td>\n",
              "      <td>2737.0</td>\n",
              "      <td>1652.0</td>\n",
              "      <td>5698.0</td>\n",
              "      <td>...</td>\n",
              "      <td>68548</td>\n",
              "      <td>66110</td>\n",
              "      <td>41122.0</td>\n",
              "      <td>68548.0</td>\n",
              "      <td>58410</td>\n",
              "      <td>11458</td>\n",
              "      <td>125457.0</td>\n",
              "      <td>117578.0</td>\n",
              "      <td>53722</td>\n",
              "      <td>50482.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16502</th>\n",
              "      <td>379</td>\n",
              "      <td>299</td>\n",
              "      <td>75196</td>\n",
              "      <td>92.0</td>\n",
              "      <td>92.0</td>\n",
              "      <td>299.0</td>\n",
              "      <td>114.0</td>\n",
              "      <td>574.0</td>\n",
              "      <td>122.0</td>\n",
              "      <td>493.0</td>\n",
              "      <td>...</td>\n",
              "      <td>26910</td>\n",
              "      <td>0</td>\n",
              "      <td>5025.0</td>\n",
              "      <td>26869.0</td>\n",
              "      <td>26828</td>\n",
              "      <td>0</td>\n",
              "      <td>33590.0</td>\n",
              "      <td>30501.0</td>\n",
              "      <td>4414</td>\n",
              "      <td>3417.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16503</th>\n",
              "      <td>2236</td>\n",
              "      <td>5747</td>\n",
              "      <td>1866957</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>3507.0</td>\n",
              "      <td>5747.0</td>\n",
              "      <td>932.0</td>\n",
              "      <td>7411.0</td>\n",
              "      <td>17649.0</td>\n",
              "      <td>18311.0</td>\n",
              "      <td>...</td>\n",
              "      <td>925496</td>\n",
              "      <td>925391</td>\n",
              "      <td>362792.0</td>\n",
              "      <td>925392.0</td>\n",
              "      <td>851863</td>\n",
              "      <td>851863</td>\n",
              "      <td>100471.0</td>\n",
              "      <td>66647.0</td>\n",
              "      <td>214235</td>\n",
              "      <td>102940.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16504</th>\n",
              "      <td>701</td>\n",
              "      <td>1780</td>\n",
              "      <td>200966</td>\n",
              "      <td>396.0</td>\n",
              "      <td>432.0</td>\n",
              "      <td>1780.0</td>\n",
              "      <td>659.0</td>\n",
              "      <td>2470.0</td>\n",
              "      <td>1434.0</td>\n",
              "      <td>5544.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42761</td>\n",
              "      <td>42761</td>\n",
              "      <td>6666.0</td>\n",
              "      <td>42761.0</td>\n",
              "      <td>16776</td>\n",
              "      <td>13986</td>\n",
              "      <td>69141.0</td>\n",
              "      <td>65518.0</td>\n",
              "      <td>23833</td>\n",
              "      <td>5522.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16505</th>\n",
              "      <td>430</td>\n",
              "      <td>757</td>\n",
              "      <td>111886</td>\n",
              "      <td>71.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>757.0</td>\n",
              "      <td>292.0</td>\n",
              "      <td>1024.0</td>\n",
              "      <td>1006.0</td>\n",
              "      <td>1029.0</td>\n",
              "      <td>...</td>\n",
              "      <td>42195</td>\n",
              "      <td>8491</td>\n",
              "      <td>500.0</td>\n",
              "      <td>42195.0</td>\n",
              "      <td>20085</td>\n",
              "      <td>9067</td>\n",
              "      <td>67325.0</td>\n",
              "      <td>62975.0</td>\n",
              "      <td>3771</td>\n",
              "      <td>305.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16506 rows × 128 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ced8dc0a-71f2-4986-9c81-5fca8f4dec1d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ced8dc0a-71f2-4986-9c81-5fca8f4dec1d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ced8dc0a-71f2-4986-9c81-5fca8f4dec1d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "teWL9K-GpLZa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model sellection and testing the impact of data precossing result"
      ],
      "metadata": {
        "id": "MGg4JG6GpM8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Reset the indices of new_df and merged_df\n",
        "new_df = new_df.reset_index(drop=True)\n",
        "merged_df = merged_df.reset_index(drop=True)\n",
        "\n",
        "# Define the independent variables\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y = new_df['target2']\n",
        "\n",
        "# Add a constant to the independent variables\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the OLS model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Print the model summary\n",
        "print(model.summary())\n"
      ],
      "metadata": {
        "id": "5T9arVAdVq1m",
        "outputId": "54b5762f-4b70-426f-d862-42e8d1180f86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                target2   R-squared:                       0.868\n",
            "Model:                            OLS   Adj. R-squared:                  0.867\n",
            "Method:                 Least Squares   F-statistic:                     849.1\n",
            "Date:                Thu, 11 May 2023   Prob (F-statistic):               0.00\n",
            "Time:                        18:52:37   Log-Likelihood:            -2.4020e+05\n",
            "No. Observations:               16506   AIC:                         4.807e+05\n",
            "Df Residuals:                   16378   BIC:                         4.816e+05\n",
            "Df Model:                         127                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "================================================================================\n",
            "                   coef    std err          t      P>|t|      [0.025      0.975]\n",
            "--------------------------------------------------------------------------------\n",
            "const        -1.722e+05   2.05e+05     -0.838      0.402   -5.75e+05     2.3e+05\n",
            "ADDNONII        -4.8311      0.252    -19.206      0.000      -5.324      -4.338\n",
            "ADDNONINTEXP -2184.3979   3.86e+04     -0.057      0.955   -7.79e+04    7.35e+04\n",
            "ASSET          121.0131   2.89e+04      0.004      0.997   -5.65e+04    5.67e+04\n",
            "EDEPDOM         -0.3612      0.580     -0.623      0.533      -1.497       0.775\n",
            "EINTEXP       1.627e+04   8.63e+04      0.188      0.851   -1.53e+05    1.86e+05\n",
            "EOTHNINT         4.3174      0.413     10.459      0.000       3.508       5.126\n",
            "EPREMAGG     -2154.1158   3.86e+04     -0.056      0.956   -7.78e+04    7.35e+04\n",
            "ESAL         -2183.0298   3.86e+04     -0.057      0.955   -7.79e+04    7.35e+04\n",
            "IBEFXTR          0.0876      2.393      0.037      0.971      -4.602       4.777\n",
            "ILNDOM           1.7089      0.285      5.988      0.000       1.150       2.268\n",
            "INTINC       -1.627e+04   8.63e+04     -0.188      0.850   -1.86e+05    1.53e+05\n",
            "IOTNII           0.7953      0.162      4.912      0.000       0.478       1.113\n",
            "ISC             -1.7887      0.548     -3.267      0.001      -2.862      -0.716\n",
            "ISERCHG        -12.7449      0.679    -18.782      0.000     -14.075     -11.415\n",
            "NETINC           0.1534      2.308      0.066      0.947      -4.371       4.678\n",
            "NIM           1.628e+04   8.63e+04      0.189      0.850   -1.53e+05    1.86e+05\n",
            "NONII            9.6895      0.454     21.320      0.000       8.799      10.580\n",
            "NONIX         2174.1628   3.86e+04      0.056      0.955   -7.35e+04    7.78e+04\n",
            "PTAXNETINC      -1.5228      0.658     -2.313      0.021      -2.813      -0.233\n",
            "ALLOTHL         -0.1225      0.050     -2.475      0.013      -0.220      -0.025\n",
            "ASSET2          -0.2397      0.038     -6.369      0.000      -0.314      -0.166\n",
            "ASSET5           0.0905      0.021      4.328      0.000       0.050       0.132\n",
            "ASSTLT           0.0711      0.022      3.218      0.001       0.028       0.114\n",
            "AVASSETJ        -0.0137      0.017     -0.783      0.434      -0.048       0.021\n",
            "CD1T3           -4.9678      0.241    -20.578      0.000      -5.441      -4.495\n",
            "CD1T3S       -1445.9166   6666.930     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "CD3LES          -2.4412      0.132    -18.473      0.000      -2.700      -2.182\n",
            "CD3LESS      -1446.4780   6666.930     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "CD3T12          -2.7950      0.134    -20.810      0.000      -3.058      -2.532\n",
            "CD3T12S      -1447.5922   6666.929     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "CDOV3S       -1448.8425   6666.928     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "COREDEP         -0.1954      0.027     -7.151      0.000      -0.249      -0.142\n",
            "DDT          -1682.3913   1.09e+04     -0.154      0.878   -2.31e+04    1.97e+04\n",
            "DEPIDOM      -1.476e+04   1.93e+04     -0.765      0.444   -5.26e+04    2.31e+04\n",
            "DEPINS           0.1478      0.014     10.636      0.000       0.121       0.175\n",
            "DEPLGAMT        -0.0961      0.014     -6.998      0.000      -0.123      -0.069\n",
            "DEPLGB          33.4224      5.962      5.606      0.000      21.737      45.108\n",
            "DEPNIDOM     -1.476e+04   1.93e+04     -0.765      0.444   -5.26e+04    2.31e+04\n",
            "DEPSMAMT        -0.1086      0.014     -7.851      0.000      -0.136      -0.082\n",
            "EQ              -6.4459      1.607     -4.011      0.000      -9.596      -3.296\n",
            "EQCCOMPI        -0.2225      0.115     -1.932      0.053      -0.448       0.003\n",
            "EQCPREV          0.1040      0.038      2.747      0.006       0.030       0.178\n",
            "EQCS            -1.2106      0.280     -4.319      0.000      -1.760      -0.661\n",
            "EQSUR           -2.1443      0.246     -8.722      0.000      -2.626      -1.662\n",
            "EQTOT        -1.603e+05   5.15e+05     -0.311      0.756   -1.17e+06     8.5e+05\n",
            "EQUPTOT         -1.2187      0.249     -4.890      0.000      -1.707      -0.730\n",
            "ERNAST          -1.5792      0.063    -25.093      0.000      -1.703      -1.456\n",
            "NTR           -958.7599   1.17e+04     -0.082      0.935   -2.39e+04     2.2e+04\n",
            "NTRCDSM          0.1780      0.087      2.045      0.041       0.007       0.349\n",
            "NTRIPC          -0.6873      0.061    -11.342      0.000      -0.806      -0.569\n",
            "NTRMUNI         -0.5192      0.071     -7.285      0.000      -0.659      -0.380\n",
            "NTRSMMDA     -1447.0252   6666.931     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "NTRSOTH      -1447.1195   6666.931     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "NTRTMLGJ     -1444.6959   6666.933     -0.217      0.828   -1.45e+04    1.16e+04\n",
            "P3ASSET         -0.6096      0.234     -2.605      0.009      -1.068      -0.151\n",
            "RBCT1J           1.3068      0.090     14.493      0.000       1.130       1.484\n",
            "TS           -1682.1796   1.09e+04     -0.154      0.878   -2.31e+04    1.97e+04\n",
            "VOLIAB          -0.0192      0.021     -0.932      0.351      -0.059       0.021\n",
            "ASTEMPM       -166.5117     52.537     -3.169      0.002    -269.489     -63.534\n",
            "DEPDASTR        42.4005    504.863      0.084      0.933    -947.186    1031.987\n",
            "EEFFR          148.9451     96.832      1.538      0.124     -40.856     338.746\n",
            "EQV           3018.0415   1841.055      1.639      0.101    -590.627    6626.710\n",
            "ERNASTR       1748.0314    810.547      2.157      0.031     159.270    3336.793\n",
            "ESTYMD          -0.0030      0.010     -0.305      0.761      -0.022       0.016\n",
            "FED          -1209.6544   1460.088     -0.828      0.407   -4071.586    1652.277\n",
            "INTEXPY      -5.393e+06   3.88e+07     -0.139      0.889   -8.14e+07    7.06e+07\n",
            "INTINCY       5.397e+06   3.88e+07      0.139      0.889   -7.06e+07    8.14e+07\n",
            "LNATRESR      3371.0985   3580.949      0.941      0.347   -3647.952    1.04e+04\n",
            "LNLSDEPR         1.3280      0.282      4.708      0.000       0.775       1.881\n",
            "LNLSNTV        321.5969    287.334      1.119      0.263    -241.609     884.803\n",
            "LNRESNCR        -0.4151      0.391     -1.061      0.289      -1.182       0.352\n",
            "NCLNLS           1.1710      0.150      7.823      0.000       0.878       1.464\n",
            "NCLNLSR       -893.1442   3679.628     -0.243      0.808   -8105.616    6319.328\n",
            "NIMY         -5.393e+06   3.88e+07     -0.139      0.889   -8.14e+07    7.06e+07\n",
            "NOIJ            -6.9515      0.923     -7.529      0.000      -8.761      -5.142\n",
            "NOIJY         4476.7702      1e+04      0.447      0.655   -1.51e+04    2.41e+04\n",
            "NONIIAY      -2218.4251   4802.293     -0.462      0.644   -1.16e+04    7194.592\n",
            "NONIXAY       2058.6253   4826.791      0.426      0.670   -7402.410    1.15e+04\n",
            "NPERFV       -1.122e+04   4689.645     -2.392      0.017   -2.04e+04   -2023.630\n",
            "NTLNLS          -5.6115      0.709     -7.913      0.000      -7.002      -4.221\n",
            "NTLNLSR      -4525.1435   3701.857     -1.222      0.222   -1.18e+04    2730.898\n",
            "RBC1AAJ      -3070.2366   1743.826     -1.761      0.078   -6488.324     347.851\n",
            "ROA           3472.6734    1.2e+04      0.290      0.772      -2e+04    2.69e+04\n",
            "ROAPTX       -2773.8333   6238.177     -0.445      0.657    -1.5e+04    9453.673\n",
            "ROE           -207.2220    561.949     -0.369      0.712   -1308.704     894.260\n",
            "ROEINJR       -708.4613    293.053     -2.418      0.016   -1282.877    -134.045\n",
            "AOA             -1.7082      0.076    -22.536      0.000      -1.857      -1.560\n",
            "BKPREM          -1.1896      0.209     -5.694      0.000      -1.599      -0.780\n",
            "CHBAL            0.3951      0.016     24.330      0.000       0.363       0.427\n",
            "CHBALNI         -2.1124      0.079    -26.805      0.000      -2.267      -1.958\n",
            "DEPDOM        1.885e+04    2.9e+04      0.650      0.516    -3.8e+04    7.57e+04\n",
            "LIAB         -1.603e+05   5.15e+05     -0.311      0.756   -1.17e+06     8.5e+05\n",
            "LIABEQ        1.602e+05   5.16e+05      0.310      0.756   -8.51e+05    1.17e+06\n",
            "LNATRES       9.133e+04   2.54e+05      0.360      0.719   -4.06e+05    5.89e+05\n",
            "LNCI             0.1052      0.019      5.582      0.000       0.068       0.142\n",
            "LNCON           -0.0071      0.020     -0.350      0.727      -0.047       0.033\n",
            "LNCONOTH        -0.0246      0.019     -1.274      0.203      -0.062       0.013\n",
            "LNEXAMT         -0.1285      0.223     -0.575      0.565      -0.566       0.309\n",
            "LNLSGR       -9.134e+04   2.54e+05     -0.360      0.719   -5.89e+05    4.06e+05\n",
            "LNLSGRS         10.0734      1.284      7.848      0.000       7.558      12.589\n",
            "LNLSNET       9.133e+04   2.54e+05      0.360      0.719   -4.06e+05    5.89e+05\n",
            "LNOT1T3          0.3112      0.050      6.259      0.000       0.214       0.409\n",
            "LNOT3LES         0.2470      0.051      4.857      0.000       0.147       0.347\n",
            "LNOT3T12         0.0090      0.063      0.142      0.887      -0.115       0.133\n",
            "LNOT3T5          0.3040      0.057      5.351      0.000       0.193       0.415\n",
            "LNOT5T15         0.3972      0.056      7.104      0.000       0.288       0.507\n",
            "LNRE             0.0235      0.081      0.290      0.772      -0.135       0.182\n",
            "LNRECONS         0.1312      0.036      3.689      0.000       0.061       0.201\n",
            "LNREDOM          0.0265      0.084      0.314      0.753      -0.139       0.192\n",
            "LNRENRES        -0.1558      0.031     -5.072      0.000      -0.216      -0.096\n",
            "LNRERES         -0.1275      0.042     -3.026      0.002      -0.210      -0.045\n",
            "LNRERSF2         0.3557      0.088      4.059      0.000       0.184       0.527\n",
            "LNRERSFM         0.4725      0.065      7.285      0.000       0.345       0.600\n",
            "LNRS1T3         -0.4738      0.076     -6.261      0.000      -0.622      -0.325\n",
            "LNRS3LES        -0.2963      0.047     -6.306      0.000      -0.388      -0.204\n",
            "LNRS3T12         1.2519      0.113     11.042      0.000       1.030       1.474\n",
            "LNRS3T5          0.1189      0.067      1.765      0.078      -0.013       0.251\n",
            "LNRS5T15        -0.1442      0.037     -3.849      0.000      -0.218      -0.071\n",
            "SC               1.1317      0.173      6.524      0.000       0.792       1.472\n",
            "SCAF            -0.1502      0.012    -12.448      0.000      -0.174      -0.127\n",
            "SCPLEDGE        -0.1452      0.015     -9.790      0.000      -0.174      -0.116\n",
            "SCRDEBT         -0.5434      0.178     -3.050      0.002      -0.893      -0.194\n",
            "SCUS            -0.0916      0.023     -4.021      0.000      -0.136      -0.047\n",
            "SCUSO           -0.1013      0.024     -4.287      0.000      -0.148      -0.055\n",
            "TRN          -2405.8299   1.11e+04     -0.216      0.829   -2.42e+04    1.94e+04\n",
            "TRNIPCOC        -0.4851      0.034    -14.128      0.000      -0.552      -0.418\n",
            "UC               0.0076      0.001      7.691      0.000       0.006       0.010\n",
            "UCOTHER          0.0054      0.005      1.062      0.288      -0.005       0.015\n",
            "==============================================================================\n",
            "Omnibus:                    52660.761   Durbin-Watson:                   2.027\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):      14913952252.978\n",
            "Skew:                         -51.527   Prob(JB):                         0.00\n",
            "Kurtosis:                    4658.590   Cond. No.                     2.25e+15\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
            "[2] The smallest eigenvalue is 6.38e-11. This might indicate that there are\n",
            "strong multicollinearity problems or that the design matrix is singular.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Create a logistic regression object with increased max_iter\n",
        "clf = LogisticRegression(max_iter=12000)\n",
        "\n",
        "# Define the probability threshold\n",
        "prob_thresh = 0.05\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "k = 10\n",
        "\n",
        "# Create a KFold object for cross-validation\n",
        "kf = KFold(n_splits=k, shuffle=True, random_state=42)\n",
        "\n",
        "# Iterate over the k folds and train/test the classifier\n",
        "scores = []\n",
        "y_pred_all = []\n",
        "for train_index, test_index in kf.split(X):\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test = X.iloc[train_index, :], X.iloc[test_index, :]\n",
        "    y_train, y_test = y_true.iloc[train_index], y_true.iloc[test_index]\n",
        "\n",
        "    # Fit the classifier to the training data\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Predict the target values for the testing data based on the probability threshold\n",
        "    y_pred_prob = clf.predict_proba(X_test)\n",
        "    y_pred = np.where(y_pred_prob[:,1] > prob_thresh, 1, 0)\n",
        "\n",
        "    # Compute the accuracy score for this fold and store it\n",
        "    fold_score = accuracy_score(y_test, y_pred)\n",
        "    scores.append(fold_score)\n",
        "\n",
        "    # Store the predicted target values for this fold\n",
        "    y_pred_all.extend(y_pred)\n",
        "\n",
        "# Compute the average accuracy score over all folds\n",
        "avg_score = sum(scores) / k\n",
        "print(\"Average accuracy:\", avg_score)\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_all)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "P3e3bLmGvXjU",
        "outputId": "abfc3bd3-9139-472e-f0c5-3471e3d14d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy: 0.9458373070499055\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Define the input features (X) and target variable (y_true)\n",
        "X = new_df[cols_less_one]\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_true, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the decision tree model\n",
        "model = DecisionTreeClassifier()\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict the target variable on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "8DTbtrVMscIu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "530a73c3-89fe-4924-c0a2-9bf32e4ac41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9624470018170805\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## random forest\n",
        "\n",
        "# Import the necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "\n",
        "\n",
        "\n",
        "# Define the input features (X) and target variable (y_true)\n",
        "X = new_df[cols_less_one]\n",
        "y_true = new_df['target']\n",
        "\n",
        "\n",
        "# Convert the data to a sparse matrix\n",
        "X_sparse = csr_matrix(X.values)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_sparse, X_test_sparse, y_train, y_test = train_test_split(X_sparse, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the random forest classifier model\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model on the training data\n",
        "rf_model.fit(X_train_sparse, y_train)\n",
        "\n",
        "# Make predictions on the testing data\n",
        "y_pred = rf_model.predict(X_test_sparse)\n",
        "\n",
        "# Evaluate the model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print('Accuracy:', accuracy)\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "bZvfYIET0dBl",
        "outputId": "fc818d16-f3e4-499f-96f4-843e10794486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9797092671108419\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the new data into a pandas DataFrame\n",
        "t2022 = pd.read_csv(\"2022q4t_file.csv\")\n",
        "t2022 = t2022.set_index(\"NAME\")\n",
        "t2022 = t2022[cols_less_one]\n",
        "t2022 = t2022.dropna()\n",
        "new_data = t2022\n",
        "\n",
        "# Preserve the original index in a separate column\n",
        "new_data['original_index'] = new_data.index\n",
        "\n",
        "# Preprocess the new data in the same way as the training data\n",
        "# ...\n",
        "\n",
        "# Convert the preprocessed data into a sparse matrix format\n",
        "new_data_sparse = csr_matrix(new_data[cols_less_one].values)\n",
        "\n",
        "# Use the trained model to predict the labels of the new data\n",
        "new_data_pred = rf_model.predict(new_data_sparse)\n",
        "\n",
        "# Find the original index of the rows in new_data where the predicted label is 1\n",
        "predicted_rows = new_data[new_data_pred == 1]['original_index']\n",
        "print(\"Indices of rows with predicted label 1:\", predicted_rows)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ouBqqsRUpRS",
        "outputId": "4617a7ff-b2f3-40a1-9a8c-cb015140f6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Indices of rows with predicted label 1: NAME\n",
            "AMERICAN TRUST&SAVINGS BANK    AMERICAN TRUST&SAVINGS BANK\n",
            "CAMP GROVE STATE BANK                CAMP GROVE STATE BANK\n",
            "BANK OF NEW CAMBRIA                    BANK OF NEW CAMBRIA\n",
            "FIRST STATE BANK                          FIRST STATE BANK\n",
            "GRAND RIVERS COMMUNITY BANK    GRAND RIVERS COMMUNITY BANK\n",
            "                                          ...             \n",
            "FARMERS NB OF EMLENTON              FARMERS NB OF EMLENTON\n",
            "LAMONT BANK OF ST JOHN              LAMONT BANK OF ST JOHN\n",
            "BANKPROV                                          BANKPROV\n",
            "THREAD BANK                                    THREAD BANK\n",
            "M1 BANK                                            M1 BANK\n",
            "Name: original_index, Length: 156, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_rows.to_csv('predicted_ones.csv', index=False)\n",
        "files.download('predicted_ones.csv')"
      ],
      "metadata": {
        "id": "lma78wlCvsjq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network works best for our problems : Testing for different optimizer and setting"
      ],
      "metadata": {
        "id": "NAwMliFu2V7f"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nB3Ffcd2UVK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.05)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping to prevent overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "# Predict the class probabilities on the test set\n",
        "y_prob = model.predict(X_test)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "y_pred = (y_prob > 0.03).astype(int)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "boF08OqeSuFA",
        "outputId": "c817749b-a814-402e-cd9a-b329acf03641"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 3ms/step - loss: 0.7966 - accuracy: 0.9370 - val_loss: 0.3775 - val_accuracy: 0.9780\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.2305 - accuracy: 0.9792 - val_loss: 0.1449 - val_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1097 - accuracy: 0.9801 - val_loss: 0.0973 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 0.0889 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0825 - accuracy: 0.9797 - val_loss: 0.0892 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.9804 - val_loss: 0.0878 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9800 - val_loss: 0.0872 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9800 - val_loss: 0.0858 - val_accuracy: 0.9807\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9800 - val_loss: 0.0869 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9803 - val_loss: 0.0881 - val_accuracy: 0.9807\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9804 - val_loss: 0.0863 - val_accuracy: 0.9807\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0807 - accuracy: 0.9798 - val_loss: 0.0915 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.9803 - val_loss: 0.0888 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9803 - val_loss: 0.0879 - val_accuracy: 0.9796\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0812 - accuracy: 0.9799 - val_loss: 0.0861 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0795 - accuracy: 0.9803 - val_loss: 0.0864 - val_accuracy: 0.9807\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0806 - accuracy: 0.9800 - val_loss: 0.0903 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0804 - accuracy: 0.9807 - val_loss: 0.0863 - val_accuracy: 0.9803\n",
            "Epoch 18: early stopping\n",
            "104/104 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.9497274379164143\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 10)                1290      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,301\n",
            "Trainable params: 1,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.05)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model with SGD optimizer\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "sgd = SGD(lr=0.01, momentum=0.9)\n",
        "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping to prevent overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "# Predict the class probabilities on the test set\n",
        "y_prob = model.predict(X_test)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "y_pred = (y_prob > 0.03).astype(int)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GdXSj4h-9euE",
        "outputId": "59189397-647d-4e15-8d34-c0783742fad0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.2864 - accuracy: 0.9723 - val_loss: 0.0881 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9796 - val_loss: 0.0900 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9796 - val_loss: 0.0879 - val_accuracy: 0.9796\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9795 - val_loss: 0.0866 - val_accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9794 - val_loss: 0.0987 - val_accuracy: 0.9796\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0835 - accuracy: 0.9796 - val_loss: 0.0874 - val_accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9796 - val_loss: 0.0909 - val_accuracy: 0.9792\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9799 - val_loss: 0.1718 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9799 - val_loss: 0.0894 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9799 - val_loss: 0.0874 - val_accuracy: 0.9799\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9796 - val_loss: 0.0888 - val_accuracy: 0.9799\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9796 - val_loss: 0.1458 - val_accuracy: 0.9799\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9798 - val_loss: 0.0861 - val_accuracy: 0.9799\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9801 - val_loss: 0.1071 - val_accuracy: 0.9807\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9802 - val_loss: 0.1448 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9795 - val_loss: 0.1683 - val_accuracy: 0.9765\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9798 - val_loss: 0.0899 - val_accuracy: 0.9799\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9804 - val_loss: 0.0973 - val_accuracy: 0.9799\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9800 - val_loss: 0.1688 - val_accuracy: 0.9796\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9797 - val_loss: 0.0889 - val_accuracy: 0.9807\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9798 - val_loss: 0.1001 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9799 - val_loss: 0.0862 - val_accuracy: 0.9807\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9806 - val_loss: 0.1027 - val_accuracy: 0.9803\n",
            "Epoch 23: early stopping\n",
            "104/104 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.9479103573591763\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"Best\"\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.20, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.5)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model with RMSprop optimizer\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "rmsprop = RMSprop(lr=0.002, rho=0.8)\n",
        "model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping to prevent overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "# Predict the class probabilities on the test set\n",
        "y_prob = model.predict(X_test)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "y_pred = (y_prob > 0.03).astype(int)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eJGsx7Tj-qJf",
        "outputId": "75da87a9-0e8e-4b7b-931b-cd0cf2d7fa3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 1.8971 - accuracy: 0.9537 - val_loss: 0.2153 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9796 - val_loss: 0.0948 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9796 - val_loss: 0.0932 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9796 - val_loss: 0.0961 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9796 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9796 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9796 - val_loss: 0.0967 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.0914 - val_accuracy: 0.9803\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9796 - val_loss: 0.0924 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.0924 - val_accuracy: 0.9803\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9796 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9796 - val_loss: 0.0929 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9796 - val_loss: 0.0909 - val_accuracy: 0.9803\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9796 - val_loss: 0.0911 - val_accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9796 - val_loss: 0.0932 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9796 - val_loss: 0.0910 - val_accuracy: 0.9803\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9796 - val_loss: 0.0921 - val_accuracy: 0.9803\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9796 - val_loss: 0.0913 - val_accuracy: 0.9803\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9796 - val_loss: 0.0911 - val_accuracy: 0.9803\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9796 - val_loss: 0.0908 - val_accuracy: 0.9803\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.0894 - val_accuracy: 0.9803\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9796 - val_loss: 0.0917 - val_accuracy: 0.9803\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9796 - val_loss: 0.0924 - val_accuracy: 0.9803\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9796 - val_loss: 0.0955 - val_accuracy: 0.9803\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 0.0909 - val_accuracy: 0.9803\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9796 - val_loss: 0.0942 - val_accuracy: 0.9803\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9796 - val_loss: 0.0932 - val_accuracy: 0.9803\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9796 - val_loss: 0.0917 - val_accuracy: 0.9803\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9796 - val_loss: 0.0899 - val_accuracy: 0.9803\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.0919 - val_accuracy: 0.9803\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9796 - val_loss: 0.0888 - val_accuracy: 0.9803\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9796 - val_loss: 0.0892 - val_accuracy: 0.9803\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9796 - val_loss: 0.0894 - val_accuracy: 0.9803\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9796 - val_loss: 0.0920 - val_accuracy: 0.9803\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9796 - val_loss: 0.0919 - val_accuracy: 0.9803\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9796 - val_loss: 0.0891 - val_accuracy: 0.9803\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9796 - val_loss: 0.0911 - val_accuracy: 0.9803\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9796 - val_loss: 0.0913 - val_accuracy: 0.9803\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9796 - val_loss: 0.0912 - val_accuracy: 0.9803\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9796 - val_loss: 0.0923 - val_accuracy: 0.9803\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9796 - val_loss: 0.0895 - val_accuracy: 0.9803\n",
            "Epoch 46: early stopping\n",
            "104/104 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.9442761962447002\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Set the initial accuracy threshold and flag\n",
        "accuracy_threshold = 0.96\n",
        "is_above_threshold = False\n",
        "\n",
        "# Loop until the accuracy threshold is reached\n",
        "while not is_above_threshold:\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Split the training data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n",
        "\n",
        "    # Define the neural network architecture with L2 regularization\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.5)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with RMSprop optimizer\n",
        "    rmsprop = RMSprop(lr=0.002, rho=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with early stopping to prevent overfitting\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "    # Predict the class probabilities on the test set\n",
        "    y_prob = model.predict(X_test)\n",
        "\n",
        "    # Threshold the probabilities to get binary predictions\n",
        "    y_pred = (y_prob > 0.03).astype(int)\n",
        "\n",
        "    # Evaluate the model's performance\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "\n",
        "    # Check if the accuracy threshold is met\n",
        "    if accuracy >= accuracy_threshold:\n",
        "        is_above_threshold = True\n",
        "\n",
        "# Print the final accuracy and confusion matrix\n",
        "print(\"Final accuracy:\", accuracy)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "yV0yS9UfWjkn",
        "outputId": "2fd62de7-08ce-4f9b-fd97-05cb5819e15f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "291/291 [==============================] - 2s 3ms/step - loss: 2.2438 - accuracy: 0.8954 - val_loss: 0.3221 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.1925 - accuracy: 0.9805 - val_loss: 0.1175 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9805 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9805 - val_loss: 0.1029 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.1031 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "291/291 [==============================] - 2s 6ms/step - loss: 0.0911 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9805 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.1001 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9805 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9805 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.0980 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9805 - val_loss: 0.0988 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9805 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9805 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9805 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9805 - val_loss: 0.0988 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9805 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.0998 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9805 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9805 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.0987 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9805 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9805 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9805 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9805 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9805 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9805 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9805 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9805 - val_loss: 0.0969 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9805 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0872 - accuracy: 0.9805 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "291/291 [==============================] - 2s 7ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9805 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0862 - accuracy: 0.9805 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
            "Epoch 51: early stopping\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.9529924884904288\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 2.2290 - accuracy: 0.8925 - val_loss: 0.3156 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.1884 - accuracy: 0.9805 - val_loss: 0.1177 - val_accuracy: 0.9780\n",
            "Epoch 3/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.1006 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9805 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "291/291 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.1007 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.1002 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "291/291 [==============================] - 3s 9ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "291/291 [==============================] - 1s 5ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9805 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "291/291 [==============================] - 2s 5ms/step - loss: 0.0897 - accuracy: 0.9805 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9805 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9805 - val_loss: 0.1017 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "291/291 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0987 - val_accuracy: 0.9784\n",
            "Epoch 20: early stopping\n",
            "129/129 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.9626847589047735\n",
            "Final accuracy: 0.9626847589047735\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAFzCAYAAADc9mULAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6WUlEQVR4nO3de1xUZf4H8M+AzADCoKgwsF4WRVG8i4WzJepPYlQ0Td0yb5S3xcAUUonNu6uYWipeUzO0sLQ2XQUvixhe8RJJ3pANxchg0CJAUIfLnN8frrNNHJVhgAHP572v81o55znnfGfM+fA8zzlnZIIgCCAiIkmzsnQBRERkeQwDIiJiGBAREcOAiIjAMCAiIjAMiIgIDAMiIgLDgIiIwDAgIiIADSxdQE2w6x5q6RKoFv16dq2lS6BaZC+XmbW/OZ8P9y+sM+vcddkzGQZERI8l44CIGIYBEUmLzLyexbOKYUBE0sKegSi+K0RExJ4BEUkMh4lEMQyISFo4TCSKYUBE0sKegSiGARFJC3sGohgGRCQt7BmIYkQSERF7BkQkMRwmEsUwICJp4TCRKIYBEUkLewaiGAZEJC3sGYhiGBCRtLBnIIrvChERsWdARBLDnoEohgERSYsV5wzEMAyISFrYMxDFMCAiaeHVRKIYBkQkLewZiOK7QkRE7BkQkcRwmEgUw4CIpIXDRKIYBkQkLewZiGIYEJG0sGcgimFARNLCnoEoRiQREbFnQEQSw2EiUQwDIpIWDhOJYkQSkbTIrKq+mGDjxo3o0qULlEollEol1Go1Dh48aNjet29fyGQyoyU4ONjoGFlZWQgMDIS9vT1cXFwwa9YslJWVGbVJSkpCjx49oFAo4OnpiZiYmCq9LewZEJG01NIwUfPmzbFs2TK0bdsWgiBg+/btGDp0KC5cuICOHTsCACZPnoxFixYZ9rG3tzf8uby8HIGBgVCpVDh9+jRycnIwfvx42NjYYOnSpQCAzMxMBAYGIjg4GLGxsUhMTMSkSZPg5uYGjUZjUr0yQRCEanjddYpd91BLl0C16Nezay1dAtUie7l5wzx2L2+s8r73900169zOzs5YsWIFJk6ciL59+6Jbt25YvXq1aNuDBw9i8ODByM7OhqurKwBg06ZNiIiIwJ07dyCXyxEREYH4+HhcvnzZsN+oUaOQn5+PQ4cOmVQbh4mIiCpJp9OhsLDQaNHpdE/dr7y8HF988QWKi4uhVqsN62NjY9G0aVN06tQJkZGRuHfvnmFbcnIyOnfubAgCANBoNCgsLMSVK1cMbfz9/Y3OpdFokJycbPJrYxgQkbSYMWcQFRUFJycnoyUqKuqxp7p06RIcHBygUCgQHByMPXv2wNvbGwAwevRofPbZZ/jmm28QGRmJTz/9FGPHjjXsq9VqjYIAgOFnrVb7xDaFhYW4f/++SW8L5wyISFrMuJooMjIS4eHhRusUCsVj23t5eSE1NRUFBQX46quvEBQUhGPHjsHb2xtTpkwxtOvcuTPc3NzQv39/XL9+HW3atKlyjVXFMCAiaTFjAlmhUDzxw/+P5HI5PD09AQA+Pj44f/481qxZg48++qhCW19fXwBARkYG2rRpA5VKhXPnzhm1yc3NBQCoVCrD/z9a9/s2SqUSdnZ2lX9h4DAREUmNTFb1xUx6vf6xcwypqakAADc3NwCAWq3GpUuXcPv2bUObhIQEKJVKw1CTWq1GYmKi0XESEhKM5iUqiz0DIpIUWS3ddBYZGYmBAweiZcuWuHv3Lnbu3ImkpCQcPnwY169fx86dOzFo0CA0adIEFy9eRFhYGPz8/NClSxcAQEBAALy9vTFu3DgsX74cWq0Wc+bMQUhIiKF3EhwcjHXr1mH27NmYMGECjh49it27dyM+Pt7kehkGREQ14Pbt2xg/fjxycnLg5OSELl264PDhw3jppZfw008/4ciRI1i9ejWKi4vRokULjBgxAnPmzDHsb21tjbi4OEydOhVqtRoNGzZEUFCQ0X0JHh4eiI+PR1hYGNasWYPmzZtj69atJt9jAPA+A3oG8D4DaTH3PoOGIz+p8r7FX71p1rnrMvYMiEha+GgiUQwDIpKU2pozqG8YBkQkKQwDcQwDIpIUhoE43mdARETsGRCRtLBnII5hQETSwiwQxTAgIklhz0Acw4CIJIVhII5hQESSwjAQx6uJiIiIPQMikhb2DMQxDIhIWpgFohgGRCQp7BmIYxgQkaQwDMQxDIhIUhgG4ng1ERERsWdARBLDjoEohgERSQqHicQxDIhIUhgG4hgGRCQpDANxDAMikhSGgTheTUREROwZEJHEsGMgimFARJLCYSJxDAMikhSGgTiGARFJCsNAHCeQiYiIYUBEEiMzYzHBxo0b0aVLFyiVSiiVSqjVahw8eNCw/cGDBwgJCUGTJk3g4OCAESNGIDc31+gYWVlZCAwMhL29PVxcXDBr1iyUlZUZtUlKSkKPHj2gUCjg6emJmJgY0wr9Lw4T1SGT//oiJo/sjVbuzgCAtBtaLN18EP8+dRUA4NG8KZaFvQJ199ZQ2DRAwuk0hL//JW7n3a1wLLlNAxz/dCa6ejWH72tRuPifnw3b/NUdMDd4EDq0ccODklKc+u46Ij74Glk5ebXzQqlSysvLsWnDOhyI34dff/kFzZq5YMjQVzD5b1Mhk8lQWlqKDWvX4OSJY7j18y04ODjAt9df8PaMcLi4uFq6/DqrtoaJmjdvjmXLlqFt27YQBAHbt2/H0KFDceHCBXTs2BFhYWGIj4/Hl19+CScnJ4SGhmL48OE4deoUgId//4GBgVCpVDh9+jRycnIwfvx42NjYYOnSpQCAzMxMBAYGIjg4GLGxsUhMTMSkSZPg5uYGjUZjUr0yQRCEan8XLMyue6ilS6iSQX6dUK7XIyPrDmSQYewQX4QF9UevUcvwY3Yezu+OxKX//IzFmw4AAOa/FQi3Zk7wG/8B/vjXuHLWCLRp6YIBL3Y0CoNW7k2Q+vUcRH92FDF7k+HkYIvlM0fAwd4Wfxn9fq2/5urw69m1li6hRny8ZRM+2xGDRUuWoU0bT1y5chkL5v4dIW/PwOgx43H37l3MCp+O4SP+inZeXigsLMSK95eivLwcO3f909Ll1xh7uXkf5q3e3l/lfX+MHmLWuZ2dnbFixQqMHDkSzZo1w86dOzFy5EgAwLVr19ChQwckJyejV69eOHjwIAYPHozs7Gy4uj4M902bNiEiIgJ37tyBXC5HREQE4uPjcfnyZcM5Ro0ahfz8fBw6dMik2jhMVIccOH4Zh09exfWsO8jIuo0F6/ej6J4Oz3fxgLpba7Ryb4LJ8z/DlYxsXMnIxqR5n6KHd0v0fb6d0XECXvBG/14dELlqT4Vz9PBuAWsrKyxYH4fMW78g9dotrN6RiK5ef0KDBvzPoS75PvUC+vTrj95+feH+p+Z4KWAAev3lBVy5dAkA4OjoiE1btiFgwED82aM1unTthnf/PhdpV68gJyfbwtXXXTKZrMqLTqdDYWGh0aLT6Z56zvLycnzxxRcoLi6GWq1GSkoKSktL4e/vb2jTvn17tGzZEsnJyQCA5ORkdO7c2RAEAKDRaFBYWIgrV64Y2vz+GI/aPDqGKSz6r/+XX37B8uXL8corr0CtVkOtVuOVV17BihUrcOfOHUuWZnFWVjL8VeODhnZynL2YCYW8AQRBgK7kf+OFD3Rl0OsF/KVbG8M6F2dHbJj7OibO3YF790sqHPe7qz9BL+gxfmgvWFnJoHSwxejA53H0bDrKyvS18tqocrp2645zZ5Px481MAEB6+jWkfvcdXnjR77H73L17FzKZDI6Oytoqs94xJwyioqLg5ORktERFRT32XJcuXYKDgwMUCgWCg4OxZ88eeHt7Q6vVQi6Xo1GjRkbtXV1dodVqAQBardYoCB5tf7TtSW0KCwtx//59k94Xi80ZnD9/HhqNBvb29vD390e7dg9/u83NzUV0dDSWLVuGw4cPo2fPnpYq0SI6erojafs7sJU3QNF9HV57Zwuu3dDil9+KUHy/BEumD8W8dfsggwz/mD4UDRpYQ9X0f//wNy8aiy1fncR3V7PQ0s25wvF/zP4Vg99aj8/en4B1741CgwbWOPP9DQwL3VibL5Mq4c2JU1BUVIxXXh4Ea2trlJeXI+TtGRg0WHyoQqfTIXrVSgwYGAgHB4darlYaIiMjER4ebrROoVA8tr2XlxdSU1NRUFCAr776CkFBQTh27FhNl1klFguDadOm4a9//Ss2bdpUYUJHEAQEBwdj2rRpT+3u6HS6Ct00QV8OmZV1tddcG/5zMxe+o6Lg5GCHV/y7Y8uicQiYtAbXbmgxZvbHiP77a3jr9T7Q6wXsPpSC765mQf/f+YK3Xu8DR3tbrNj278ce37WJIzbMHY3Y/Wex+1AKHBoqMG/qYOxcORGBwetq62VSJfz78EEcjN+Ppe+vRJs2nkhPv4aV7y9Fs2YueHnoK0ZtS0tLMXvmDAgA/j53gUXqrTfMmHJQKBRP/PD/I7lcDk9PTwCAj48Pzp8/jzVr1uC1115DSUkJ8vPzjXoHubm5UKlUAACVSoVz584ZHe/R1Ua/b/PHK5Byc3OhVCphZ2dn0muzWBh8//33iImJEZ3Zl8lkCAsLQ/fu3Z96nKioKCxcuNBonbXrc7Bxe77aaq1NpWXluPHTLwCAC2k/wadjS4S83hfTlnyBxDPX0PHlhWjSqCHKyvQoKLqPzISluHk4BQDQ97l28O3igYKzq42OeSp2Nr44+C0mz/sUf3vND4VF9/Hemn8Ztk94bzsyDv8Dz3f+M85dullbL5WeYvUHK/DmxMkYMDAQANC2nRdysrPxydbNRmFQWlqKiJlhyMnOxuaPY9greApL3nSm1+uh0+ng4+MDGxsbJCYmYsSIEQCA9PR0ZGVlQa1WAwDUajWWLFmC27dvw8XFBQCQkJAApVIJb29vQ5sDBw4YnSMhIcFwDFNYLAwepV779u1Ft587d67CWJgYsW6bS++IaqmxLrCSyaCQG/81/ZpfDADo81w7uDg7IO7YwwnFd5Z/hQXr4wzt3Jo5IW5jKMa9+wnO//dD3t5WDr3e+Mqjcv3DuQIrK96ZWZc8eHAfMivjaT0rayvohf/N7TwKgqysH7H54+1o1KhxbZdZ79RWGERGRmLgwIFo2bIl7t69i507dyIpKQmHDx+Gk5MTJk6ciPDwcDg7O0OpVGLatGlQq9Xo1asXACAgIADe3t4YN24cli9fDq1Wizlz5iAkJMTQOwkODsa6deswe/ZsTJgwAUePHsXu3bsRHx9vcr0WC4OZM2diypQpSElJQf/+/Q0f/Lm5uUhMTMSWLVuwcuXKpx5HrNtWX4eIFk17GYdPXcFPOb/BsaEtXhvYE34922LIWxsAAONe7oX0TC3u/FYE3y4eWDlrJNbGfoMffrwNAPhJ+5vR8YruPRw+u/HTHfx8Ox8AcPDEFUwb0w+RUwZg96EUONorsDD0ZfyY/StSr92qvRdLT+XXpx8+3rwJbm5uaNPGE9eupeGzHTEYNuzhb5KlpaWYFT4d19KuYs36TdDry/HLLw8vvHBycoKNjdyS5ddZtdUxuH37NsaPH4+cnBw4OTmhS5cuOHz4MF566SUAwKpVq2BlZYURI0ZAp9NBo9Fgw4YNhv2tra0RFxeHqVOnQq1Wo2HDhggKCsKiRYsMbTw8PBAfH4+wsDCsWbMGzZs3x9atW02+xwCw8H0Gu3btwqpVq5CSkoLy8nIAD98AHx8fhIeH49VXX63ScevrfQYb549Gv+e9oGqqREHRA1z+4Wd88MkRHD17DQCw+O2XMXZILzg72ePH7Dxs/eokoj87+tjjtXRzRvqBRRVuOvurxgdhQf5o28oF9x6U4OzFTMxZ8y/852buY49Vlz2r9xkUFxdhw7poHE08gt/yfkWzZi4YMDAQU6a+BRsbObJ/voXAAf6i+27Zth09n/Ot5Yprh7n3GbSdZdr197/3w4oBZp27LqsTN52Vlpbil18ejpM3bdoUNjY2Zh2vvoYBVc2zGgYkjmFQM+rE4yhsbGzg5uZm6TKISAL40FJxdSIMiIhqCx9hLY5hQESSwiwQxzAgIknhJdTiGAZEJCnsGYjjYyqJiIg9AyKSFk4gi2MYEJGkMAvEMQyISFLYMxDHMCAiSWEYiGMYEJGkMAvE8WoiIiJiz4CIpIXDROIYBkQkKcwCcQwDIpIU9gzEMQyISFKYBeIYBkQkKewZiOPVRERExJ4BEUkLOwbiGAZEJCkcJhLHMCAiSWEWiGMYEJGksGcgjmFARJLCLBDHq4mIiIg9AyKSFg4TiWMYEJGkMAvEMQyISFLYMxDHOQMikhSZTFblxRRRUVF47rnn4OjoCBcXFwwbNgzp6elGbfr27VvhHMHBwUZtsrKyEBgYCHt7e7i4uGDWrFkoKyszapOUlIQePXpAoVDA09MTMTExJr8vDAMikhSZrOqLKY4dO4aQkBCcOXMGCQkJKC0tRUBAAIqLi43aTZ48GTk5OYZl+fLlhm3l5eUIDAxESUkJTp8+je3btyMmJgbz5s0ztMnMzERgYCD69euH1NRUzJgxA5MmTcLhw4dNqpfDRERENeDQoUNGP8fExMDFxQUpKSnw8/MzrLe3t4dKpRI9xr///W9cvXoVR44cgaurK7p164bFixcjIiICCxYsgFwux6ZNm+Dh4YEPPvgAANChQwecPHkSq1atgkajqXS97BkQkaSYM0yk0+lQWFhotOh0ukqdt6CgAADg7OxstD42NhZNmzZFp06dEBkZiXv37hm2JScno3PnznB1dTWs02g0KCwsxJUrVwxt/P39jY6p0WiQnJxs0vvCMCAiSTFnmCgqKgpOTk5GS1RU1FPPqdfrMWPGDLzwwgvo1KmTYf3o0aPx2Wef4ZtvvkFkZCQ+/fRTjB071rBdq9UaBQEAw89arfaJbQoLC3H//v1Kvy8cJiIiSTHnaqLIyEiEh4cbrVMoFE/dLyQkBJcvX8bJkyeN1k+ZMsXw586dO8PNzQ39+/fH9evX0aZNmyrXWRUMAyKSFHOuLFUoFJX68P+90NBQxMXF4fjx42jevPkT2/r6+gIAMjIy0KZNG6hUKpw7d86oTW5uLgAY5hlUKpVh3e/bKJVK2NnZVbpODhMRkaRYyWRVXkwhCAJCQ0OxZ88eHD16FB4eHk/dJzU1FQDg5uYGAFCr1bh06RJu375taJOQkAClUglvb29Dm8TERKPjJCQkQK1Wm1Qvw4CIqAaEhITgs88+w86dO+Ho6AitVgutVmsYx79+/ToWL16MlJQU3Lx5E/v27cP48ePh5+eHLl26AAACAgLg7e2NcePG4fvvv8fhw4cxZ84chISEGHoowcHBuHHjBmbPno1r165hw4YN2L17N8LCwkyql2FARJJSW/cZbNy4EQUFBejbty/c3NwMy65duwAAcrkcR44cQUBAANq3b4933nkHI0aMwP79+w3HsLa2RlxcHKytraFWqzF27FiMHz8eixYtMrTx8PBAfHw8EhIS0LVrV3zwwQfYunWrSZeVAoBMEATBtJdY99l1D7V0CVSLfj271tIlUC2yl5v3OAnNhrNV3vfwW75mnbsu4wQyEUmKFR9NJIphQESSwgfViatUGOzbt6/SB3z55ZerXAwRUU1jFoirVBgMGzasUgeTyWQoLy83px4iIrKASoWBXq+v6TqIiGqFDOwaiDFrzuDBgwewtbWtrlqIiGocJ5DFmXyfQXl5ORYvXow//elPcHBwwI0bNwAAc+fOxccff1ztBRIRVafa+nKb+sbkMFiyZAliYmKwfPlyyOVyw/pOnTph69at1VocEVF1q62bzuobk8Ngx44d2Lx5M8aMGQNra2vD+q5du+LatWvVWhwRUXWrrWcT1Tcmh8HPP/8MT0/PCuv1ej1KS0urpSgiIqpdJoeBt7c3Tpw4UWH9V199he7du1dLUURENYXDROJMvppo3rx5CAoKws8//wy9Xo+vv/4a6enp2LFjB+Li4mqiRiKiavOsTwRXlck9g6FDh2L//v04cuQIGjZsiHnz5iEtLQ379+/HSy+9VBM1EhFVG/YMxFXpPoPevXsjISGhumshIqpxz/pEcFVV+aazb7/9FmlpaQAeziP4+PhUW1FERDWFUSDO5DC4desWXn/9dZw6dQqNGjUCAOTn5+Mvf/kLvvjii6d+xycREdU9Js8ZTJo0CaWlpUhLS0NeXh7y8vKQlpYGvV6PSZMm1USNRETVhncgizO5Z3Ds2DGcPn0aXl5ehnVeXl5Yu3YtevfuXa3FERFVNz6bSJzJYdCiRQvRm8vKy8vh7u5eLUUREdWUZ/03/KoyeZhoxYoVmDZtGr799lvDum+//RbTp0/HypUrq7U4IqLqxktLxVWqZ9C4cWOjNC0uLoavry8aNHi4e1lZGRo0aIAJEyZU+otwiIgsgT0DcZUKg9WrV9dwGUREZEmVCoOgoKCaroOIqFZwAlmc2d90VlJSYrROqVSaVRARUU3iMJE4kyeQi4uLERoaChcXFzRs2BCNGzc2WoiI6jKZGcuzzOQwmD17No4ePYqNGzdCoVBg69atWLhwIdzd3bFjx46aqJGIqNrwy23EmTxMtH//fuzYsQN9+/bFm2++id69e8PT0xOtWrVCbGwsxowZUxN1EhFRDTK5Z5CXl4fWrVsDeDg/kJeXBwB48cUXcfz48eqtjoiomvE+A3Emh0Hr1q2RmZkJAGjfvj12794N4GGP4dGD64iI6qraejZRVFQUnnvuOTg6OsLFxQXDhg1Denq6UZsHDx4gJCQETZo0gYODA0aMGIHc3FyjNllZWQgMDIS9vT1cXFwwa9YslJWVGbVJSkpCjx49oFAo4OnpiZiYGJPfF5PD4M0338T3338PAHj33Xexfv162NraIiwsDLNmzTK5ACKi2lRbPYNjx44hJCQEZ86cQUJCAkpLSxEQEIDi4mJDm7CwMOzfvx9ffvkljh07huzsbAwfPtywvby8HIGBgSgpKcHp06exfft2xMTEYN68eYY2mZmZCAwMRL9+/ZCamooZM2Zg0qRJOHz4sGnviyAIgmkv0diPP/6IlJQUeHp6okuXLuYcqtrYdQ+1dAlUi349u9bSJVAtspebN14z9Z9Xq7zvxhHeVd73zp07cHFxwbFjx+Dn54eCggI0a9YMO3fuxMiRIwEA165dQ4cOHZCcnIxevXrh4MGDGDx4MLKzs+Hq6goA2LRpEyIiInDnzh3I5XJEREQgPj4ely9fNpxr1KhRyM/Px6FDhypdn8k9gz9q1aoVhg8fXmeCgIjoSSw1Z1BQUAAAcHZ2BgCkpKSgtLQU/v7+hjbt27dHy5YtkZycDABITk5G586dDUEAABqNBoWFhbhy5Yqhze+P8ajNo2NUVqWuJoqOjq70Ad9++22TCiAiqi90Oh10Op3ROoVCAYVC8cT99Ho9ZsyYgRdeeAGdOnUCAGi1Wsjl8gpzra6urtBqtYY2vw+CR9sfbXtSm8LCQty/fx92dnaVem2VCoNVq1ZV6mAymYxhQER1mjl3IEdFRWHhwoVG6+bPn48FCxY8cb+QkBBcvnwZJ0+erPK5a1qlwuDR1UP1BceQpcWKD5shE5gzNh4ZGYnw8HCjdU/rFYSGhiIuLg7Hjx83+lpglUqFkpIS5OfnG/UOcnNzoVKpDG3OnTtndLxHVxv9vs0fr0DKzc2FUqmsdK8AqIY5AyKi+sScS0sVCgWUSqXR8rgwEAQBoaGh2LNnD44ePQoPDw+j7T4+PrCxsUFiYqJhXXp6OrKysqBWqwEAarUaly5dwu3btw1tEhISoFQq4e3tbWjz+2M8avPoGJVl1oPqiIjqm9rqSIaEhGDnzp3417/+BUdHR8MYv5OTE+zs7ODk5ISJEyciPDwczs7OUCqVmDZtGtRqNXr16gUACAgIgLe3N8aNG4fly5dDq9Vizpw5CAkJMYRQcHAw1q1bh9mzZ2PChAk4evQodu/ejfj4eJPqNfvS0rroXskz95LoCThMJC22Zv4KG77vWpX3/fDl9pVu+7i5iU8++QRvvPEGgIc3nb3zzjv4/PPPodPpoNFosGHDBsMQEPDw8v2pU6ciKSkJDRs2RFBQEJYtW2b4cjHg4U1nYWFhuHr1Kpo3b465c+cazlHpehkGVN8xDKSlvoRBfcNhIiKSFH6fgbgqTSCfOHECY8eOhVqtxs8//wwA+PTTT+v0ZVNERMDDOYOqLs8yk8Pgn//8JzQaDezs7HDhwgXDDRgFBQVYunRptRdIRFSd+NRScSaHwT/+8Q9s2rQJW7ZsgY2NjWH9Cy+8gO+++65aiyMiqm78chtxJs8ZpKenw8/Pr8J6Jycn5OfnV0dNREQ1hjdXiTP5fVGpVMjIyKiw/uTJk4YvvSEiovrF5DCYPHkypk+fjrNnz0ImkyE7OxuxsbGYOXMmpk6dWhM1EhFVG84ZiDN5mOjdd9+FXq9H//79ce/ePfj5+UGhUGDmzJmYNm1aTdRIRFRtnvWx/6qq8k1nJSUlyMjIQFFREby9veHg4FDdtVUZbzqTFt50Ji3m3nQ27/APVd53kaateSevw6r8tsrlcsODkoiI6gv+7iDO5DDo16/fE+/gO3r0qFkFERHVJA4TiTM5DLp162b0c2lpKVJTU3H58mUEBQVVV11ERFSLTA6Dx33r2YIFC1BUVGR2QURENYkdA3HVdv/F2LFjsW3btuo6HBFRjeCzicRV21NLk5OTYWtrW12HIyKqETI845/qVWRyGAwfPtzoZ0EQkJOTg2+//RZz586ttsKIiGrCs/4bflWZHAZOTk5GP1tZWcHLywuLFi1CQEBAtRVGRFQTGAbiTAqD8vJyvPnmm+jcuTMaN25cUzUREVEtM2kC2draGgEBAXw6KRHVWzKZrMrLs8zkq4k6deqEGzdu1EQtREQ1jlcTiavSl9vMnDkTcXFxyMnJQWFhodFCRFSX8aml4io9Z7Bo0SK88847GDRoEADg5ZdfNuo2CYIAmUyG8vLy6q+SiKia8HEU4ir91FJra2vk5OQgLS3tie369OlTLYWZg08tlRY+tVRazH1qafTJzCrv+/aLHuadvA6r9Nv6KDPqwoc9ERFVL5My9lmfTSeiZx8/xsSZFAbt2rV7aiDk5eWZVRARUU2y4uMoRJkUBgsXLqxwBzIRUX3CnoE4k8Jg1KhRcHFxqalaiIhqHK83EFfpMOB8ARE9C3hpqbhK33RWyStQiYgIwPHjxzFkyBC4u7tDJpNh7969RtvfeOONCo+7GDBggFGbvLw8jBkzBkqlEo0aNcLEiRMrfInYxYsX0bt3b9ja2qJFixZYvnx5leqtdBjo9XoOERFRvVdbdyAXFxeja9euWL9+/WPbDBgwADk5OYbl888/N9o+ZswYXLlyBQkJCYiLi8Px48cxZcoUw/bCwkIEBASgVatWSElJwYoVK7BgwQJs3rzZtGJRjV9uQ0RUH9TWMNHAgQMxcODAJ7ZRKBRQqVSi29LS0nDo0CGcP38ePXv2BACsXbsWgwYNwsqVK+Hu7o7Y2FiUlJRg27ZtkMvl6NixI1JTU/Hhhx8ahUZlVNvXXhIR1Qfm9Ax0Ol2F57HpdLoq15KUlAQXFxd4eXlh6tSp+PXXXw3bkpOT0ahRI0MQAIC/vz+srKxw9uxZQxs/Pz/I5XJDG41Gg/T0dPz2228m1cIwICJJsTJjiYqKgpOTk9ESFRVVpToGDBiAHTt2IDExEe+//z6OHTuGgQMHGp7vptVqKwzNN2jQAM7OztBqtYY2rq6uRm0e/fyoTWVxmIiIJMWcKyMjIyMRHh5utE6hUFTpWKNGjTL8uXPnzujSpQvatGmDpKQk9O/fv8o1VhV7BkRElaRQKKBUKo2WqobBH7Vu3RpNmzZFRkYGAEClUuH27dtGbcrKypCXl2eYZ1CpVMjNzTVq8+jnx81FPA7DgIgkRWbGUpNu3bqFX3/9FW5ubgAAtVqN/Px8pKSkGNocPXoUer0evr6+hjbHjx9HaWmpoU1CQgK8vLxM/mpihgERSYqVTFblxRRFRUVITU1FamoqACAzMxOpqanIyspCUVERZs2ahTNnzuDmzZtITEzE0KFD4enpCY1GAwDo0KEDBgwYgMmTJ+PcuXM4deoUQkNDMWrUKLi7uwMARo8eDblcjokTJ+LKlSvYtWsX1qxZU2EoqzIq/X0G9Qm/z0Ba+H0G0mLu9xnEptyq8r5jfJpXum1SUhL69etXYX1QUBA2btyIYcOG4cKFC8jPz4e7uzsCAgKwePFiownhvLw8hIaGYv/+/bCyssKIESMQHR0NBwcHQ5uLFy8iJCQE58+fR9OmTTFt2jRERESY/NoYBlTvMQykxdww2Pld1cNgdI/Kh0F9w6uJiEhS+Jw1cZwzICIi9gyISFr4G7A4hgERSQqHicQxDIhIUhgF4hgGRCQp7BmIYxgQkaRwzkAc3xciImLPgIikhcNE4hgGRCQpjAJxDAMikhR2DMQxDIhIUqzYNxDFMCAiSWHPQByvJiIiIvYMiEhaZBwmEsUwICJJ4TCROIYBEUkKJ5DFMQyISFLYMxDHMCAiSWEYiOPVRERExJ4BEUkLryYSxzAgIkmxYhaIYhgQkaSwZyCOYUBEksIJZHGcQCYiIvYMiEhaOEwkjmFQzwzS/B9ysrMrrH/1tdF4a9rb2Lh+Lc4kn4I2JweNGzuj7//1x1uh0+Ho6GiBaslcH2/5CIkJ/0Zm5g0obG3RrVt3zAifiT97tDa0mfjGOHx7/pzRfiNffQ1z5y+q7XLrBU4gi2MY1DOfff4V9Ppyw88ZP/yAqVMm4CWNBndu38adO7cR9s5stG7jiZzsbCxZPB937tzGyg+jLVg1VdW358/htdfHoGPnzigvK8faNR8iePJEfL0vHvb29oZ2I0a+irdC3zb8bGtnZ4ly6wX2DMRxzqCecXZ2RtOmzQzLieNJaNGiJXx6Pg/Ptu3wwaq16NP3/9CiRUs879sLodPCcDzpG5SVlVm6dKqCjZs/xtBXhsPTsy282rfHoiXLkJOTjbSrV4za2draommzZobFwcHBQhXXfTJZ1RdTHD9+HEOGDIG7uztkMhn27t1rtF0QBMybNw9ubm6ws7ODv78/fvjhB6M2eXl5GDNmDJRKJRo1aoSJEyeiqKjIqM3FixfRu3dv2NraokWLFli+fHlV3haGQX1WWlqCA3H7MPSV4Y/9ku+7RXfR0MEBDRqwE/gsKLp7FwCgdHIyWn8gfj/6vOCL4UMHY82qD3D//n1LlFcvyMxYTFFcXIyuXbti/fr1otuXL1+O6OhobNq0CWfPnkXDhg2h0Wjw4MEDQ5sxY8bgypUrSEhIQFxcHI4fP44pU6YYthcWFiIgIACtWrVCSkoKVqxYgQULFmDz5s0mVlvHh4l++uknzJ8/H9u2bbN0KXXSN4mJuHv3LoYMfUV0+2+//YYtH23EiJGv1nJlVBP0ej2Wv78U3br3QNu27QzrBw4aDDd3d7i4uOA//0nH6g9X4ubNTKxas86C1dLAgQMxcOBA0W2CIGD16tWYM2cOhg4dCgDYsWMHXF1dsXfvXowaNQppaWk4dOgQzp8/j549ewIA1q5di0GDBmHlypVwd3dHbGwsSkpKsG3bNsjlcnTs2BGpqan48MMPjUKjMup0zyAvLw/bt29/YhudTofCwkKjRafT1VKFlrV3z1d44cXecHFxrbCtqKgIb4f8Da1bt8HfpoZaoDqqbkv/sRDXf/gBy1euMlo/8tXX8MKLvdG2nRcCB7+Mfyx9H0ePJOCnrCwLVVq3WclkVV6q6/MmMzMTWq0W/v7+hnVOTk7w9fVFcnIyACA5ORmNGjUyBAEA+Pv7w8rKCmfPnjW08fPzg1wuN7TRaDRIT0/Hb7/9ZlJNFu0Z7Nu374nbb9y48dRjREVFYeHChUbr/j5nHt6bu8Cc0uq87OyfcfZMMlauWlthW3FxEUKCJ8HeviE+XLMONjY2FqiQqtPSfyzC8WNJ2Lb9M7iqVE9s27lLVwBAVtaPaNGyZW2UV6+YM30s9nkzf/58LFiwwKTjaLVaAICrq/Evcq6uroZtWq0WLi4uRtsbNGgAZ2dnozYeHh4VjvFoW+PGjStdk0XDYNiwYZDJZBAE4bFtHjcW/khkZCTCw8ON1pXL5I9p/ezYt/drODs3QW+/Pkbri4qK8NbfJkIul2P12g1QKBQWqpCqgyAIiFqyGEcTE/BxzKdo3rzFU/dJv5YGAGjWrFlNl1c/mZEGYp83z8q/MYuGgZubGzZs2GAYM/uj1NRU+Pj4PPEYCoWiwl/GvZLHh8uzQK/X419792Dwy8OMJoYfBcGD+/exZNkKFBcXobj44ZUHjRs7w9ra2lIlUxUtXbwQBw/EYfXaDWho3xC/3LkDAHBwdIStrS1+ysrCgfj96O3XB06NGuGH9HSsWB4Fn57PoZ1XewtXXzeZc2mp2OdNVaj+27vLzc2Fm5ubYX1ubi66detmaHP79m2j/crKypCXl2fYX6VSITc316jNo59VT+lB/pFFw8DHxwcpKSmPDYOn9Rqk6uyZ09DmZGPYK8ON1l9Lu4JLF78HALw8KMBoW/yhI3D/U/Naq5Gqx+5dnwN4eGPZ7y36RxSGvjIcNjY2OHsmGbGf7sD9+/egUrnB3z8Ak4PfskS59UJdeDaRh4cHVCoVEhMTDR/+hYWFOHv2LKZOnQoAUKvVyM/PR0pKiuGX4qNHj0Kv18PX19fQ5r333kNpaalhODghIQFeXl4mDREBgEyw4KftiRMnUFxcjAEDBohuLy4uxrfffos+ffqIbn+cZ71nQMaseEuppNia+SvsuRsFVd73+dZOT2/0X0VFRcjIyAAAdO/eHR9++CH69esHZ2dntGzZEu+//z6WLVuG7du3w8PDA3PnzsXFixdx9epV2NraAnh4RVJubi42bdqE0tJSvPnmm+jZsyd27twJACgoKICXlxcCAgIQERGBy5cvY8KECVi1apXJVxNZNAxqCsNAWhgG0mJuGJw3IwyeMyEMkpKS0K9fvwrrg4KCEBMTA0EQMH/+fGzevBn5+fl48cUXsWHDBrRr97/LhvPy8hAaGor9+/fDysoKI0aMQHR0tNFNhRcvXkRISAjOnz+Ppk2bYtq0aYiIiDD5tTEMqN5jGEiL2WGQaUYYeFQ+DOqbOn3TGRFRdeOzicQxDIhIUurCBHJdxDAgIklhFoir04+jICKi2sGeARFJC7sGohgGRCQpnEAWxzAgIknhBLI4hgERSQqzQBzDgIikhWkgilcTERERewZEJC2cQBbHMCAiSeEEsjiGARFJCrNAHMOAiKSFaSCKYUBEksI5A3G8moiIiNgzICJp4QSyOIYBEUkKs0Acw4CIpIVpIIphQESSwglkcQwDIpIUzhmI49VERETEngERSQs7BuIYBkQkLUwDUQwDIpIUTiCLYxgQkaRwAlkcw4CIJIVZII5XExEREcOAiCRGZsZiggULFkAmkxkt7du3N2x/8OABQkJC0KRJEzg4OGDEiBHIzc01OkZWVhYCAwNhb28PFxcXzJo1C2VlZVV73U/BYSIikpTanEDu2LEjjhw5Yvi5QYP/feSGhYUhPj4eX375JZycnBAaGorhw4fj1KlTAIDy8nIEBgZCpVLh9OnTyMnJwfjx42FjY4OlS5dWe60yQRCEaj+qhd0reeZeEj2BlRVHgaXE1sxfYTN/eVDlfT2a2la67YIFC7B3716kpqZW2FZQUIBmzZph586dGDlyJADg2rVr6NChA5KTk9GrVy8cPHgQgwcPRnZ2NlxdXQEAmzZtQkREBO7cuQO5XF7l1yGGw0REJCnmjBLpdDoUFhYaLTqd7rHn+uGHH+Du7o7WrVtjzJgxyMrKAgCkpKSgtLQU/v7+hrbt27dHy5YtkZycDABITk5G586dDUEAABqNBoWFhbhy5Up1vR0GDAMikhYz0iAqKgpOTk5GS1RUlOhpfH19ERMTg0OHDmHjxo3IzMxE7969cffuXWi1WsjlcjRq1MhoH1dXV2i1WgCAVqs1CoJH2x9tq26cMyAiqqTIyEiEh4cbrVMoFKJtBw4caPhzly5d4Ovri1atWmH37t2ws7Or0Tqrgj0DIpIUmRn/UygUUCqVRsvjwuCPGjVqhHbt2iEjIwMqlQolJSXIz883apObmwuVSgUAUKlUFa4uevTzozbViWFARJIik1V9MUdRURGuX78ONzc3+Pj4wMbGBomJiYbt6enpyMrKglqtBgCo1WpcunQJt2/fNrRJSEiAUqmEt7e3ecWI4NVEVO/xaiJpMfdqop/yHj/h+zQtnCvXCwCAmTNnYsiQIWjVqhWys7Mxf/58pKam4urVq2jWrBmmTp2KAwcOICYmBkqlEtOmTQMAnD59GsDDS0u7desGd3d3LF++HFqtFuPGjcOkSZNq5NJSzhkQkaTU1rOJbt26hddffx2//vormjVrhhdffBFnzpxBs2bNAACrVq2ClZUVRowYAZ1OB41Ggw0bNhj2t7a2RlxcHKZOnQq1Wo2GDRsiKCgIixYtqpF62TOgeo89A2kxt2dw67eSKu/bvHH1Xttfl3DOgIiIOExERNLCR1iLYxgQkaQwC8QxDIhIUtgzEMcwICJJ4ddeimMYEJG0MAtE8WoiIiJiz4CIpIUdA3EMAyKSFE4gi2MYEJGkcAJZHMOAiKSFWSCKYUBEksIsEMeriYiIiD0DIpIWTiCLYxgQkaRwAlkcw4CIJIU9A3GcMyAiIvYMiEha2DMQx54BERGxZ0BE0sIJZHEMAyKSFA4TiWMYEJGkMAvEMQyISFqYBqI4gUxEROwZEJG0cAJZHMOAiCSFE8jiGAZEJCnMAnEMAyKSFqaBKIYBEUkK5wzE8WoiIiJiz4CIpIUTyOJkgiAIli6CzKfT6RAVFYXIyEgoFApLl0M1jH/fVN0YBs+IwsJCODk5oaCgAEql0tLlUA3j3zdVN84ZEBERw4CIiBgGREQEhsEzQ6FQYP78+ZxMlAj+fVN14wQyERGxZ0BERAwDIiICw4CIiMAwICIiMAyeGevXr8ef//xn2NrawtfXF+fOnbN0SVQDjh8/jiFDhsDd3R0ymQx79+61dEn0jGAYPAN27dqF8PBwzJ8/H9999x26du0KjUaD27dvW7o0qmbFxcXo2rUr1q9fb+lS6BnDS0ufAb6+vnjuueewbt06AIBer0eLFi0wbdo0vPvuuxaujmqKTCbDnj17MGzYMEuXQs8A9gzquZKSEqSkpMDf39+wzsrKCv7+/khOTrZgZURUnzAM6rlffvkF5eXlcHV1NVrv6uoKrVZroaqIqL5hGBAREcOgvmvatCmsra2Rm5trtD43NxcqlcpCVRFRfcMwqOfkcjl8fHyQmJhoWKfX65GYmAi1Wm3ByoioPuF3ID8DwsPDERQUhJ49e+L555/H6tWrUVxcjDfffNPSpVE1KyoqQkZGhuHnzMxMpKamwtnZGS1btrRgZVTf8dLSZ8S6deuwYsUKaLVadOvWDdHR0fD19bV0WVTNkpKS0K9fvwrrg4KCEBMTU/sF0TODYUBERJwzICIihgEREYFhQEREYBgQEREYBkREBIYBERGBYUBERGAYUC154403jJ6737dvX8yYMaPW60hKSoJMJkN+fv5j25j6DWILFixAt27dzKrr5s2bkMlkSE1NNes4RFXFMJCwN954AzKZDDKZDHK5HJ6enli0aBHKyspq/Nxff/01Fi9eXKm2lfkAJyLz8NlEEjdgwAB88skn0Ol0OHDgAEJCQmBjY4PIyMgKbUtKSiCXy6vlvM7OztVyHCKqHuwZSJxCoYBKpUKrVq0wdepU+Pv7Y9++fQD+N7SzZMkSuLu7w8vLCwDw008/4dVXX0WjRo3g7OyMoUOH4ubNm4ZjlpeXIzw8HI0aNUKTJk0we/Zs/PGpJ38cJtLpdIiIiECLFi2gUCjg6emJjz/+GDdv3jQ8i6dx48aQyWR44403ADx8OmtUVBQ8PDxgZ2eHrl274quvvjI6z4EDB9CuXTvY2dmhX79+RnVWVkREBNq1awd7e3u0bt0ac+fORWlpaYV2H330EVq0aAF7e3u8+uqrKCgoMNq+detWdOjQAba2tmjfvj02bNhgci1ENYVhQEbs7OxQUlJi+DkxMRHp6elISEhAXFwcSktLodFo4OjoiBMnTuDUqVNwcHDAgAEDDPt98MEHiImJwbZt23Dy5Enk5eVhz549Tzzv+PHj8fnnnyM6OhppaWn46KOP4ODggBYtWuCf//wnACA9PR05OTlYs2YNACAqKgo7duzApk2bcOXKFYSFhWHs2LE4duwYgIehNXz4cAwZMgSpqamYNGlSlb4T2tHRETExMbh69SrWrFmDLVu2YNWqVUZtMjIysHv3buzfvx+HDh3ChQsX8NZbbxm2x8bGYt68eViyZAnS0tKwdOlSzJ07F9u3bze5HqIaIZBkBQUFCUOHDhUEQRD0er2QkJAgKBQKYebMmYbtrq6ugk6nM+zz6aefCl5eXoJerzes0+l0gp2dnXD48GFBEATBzc1NWL58uWF7aWmp0Lx5c8O5BEEQ+vTpI0yfPl0QBEFIT08XAAgJCQmidX7zzTcCAOG3334zrHvw4IFgb28vnD592qjtxIkThddff10QBEGIjIwUvL29jbZHRERUONYfARD27Nnz2O0rVqwQfHx8DD/Pnz9fsLa2Fm7dumVYd/DgQcHKykrIyckRBEEQ2rRpI+zcudPoOIsXLxbUarUgCIKQmZkpABAuXLjw2PMS1STOGUhcXFwcHBwcUFpaCr1ej9GjR2PBggWG7Z07dzaaJ/j++++RkZEBR0dHo+M8ePAA169fR0FBAXJycowen92gQQP07NmzwlDRI6mpqbC2tkafPn0qXXdGRgbu3buHl156yWh9SUkJunfvDgBIS0ur8Bjvqnzhz65duxAdHY3r16+jqKgIZWVlUCqVRm1atmyJP/3pT0bn0ev1SE9Ph6OjI65fv46JEydi8uTJhjZlZWVwcnIyuR6imsAwkLh+/fph48aNkMvlcHd3R4MGxv9JNGzY0OjnoqIi+Pj4IDY2tsKxmjVrVqUa7OzsTN6nqKgIABAfH2/0IQw8nAepLsnJyRgzZgwWLlwIjUYDJycnfPHFF/jggw9MrnXLli0Vwsna2rraaiUyB8NA4ho2bAhPT89Kt+/Rowd27doFFxeXCr8dP+Lm5oazZ8/Cz88PwMPfgFNSUtCjRw/R9p07d4Zer8exY8fg7+9fYfujnkl5eblhnbe3NxQKBbKysh7bo+jQoYNhMvyRM2fOPP1F/s7p06fRqlUrvPfee4Z1P/74Y4V2WVlZyM7Ohru7u+E8VlZW8PLygqurK9zd3XHjxg2MGTPGpPMT1RZOIJNJxowZg6ZNm2Lo0KE4ceIEMjMzkZSUhLfffhu3bt0CAEyfPh3Lli3D3r17ce3aNbz11ltPvEfgz3/+M4KCgjBhwgTs3bvXcMzdu3cDAFq1agWZTIa4uDjcuXMHRUVFcHR0xMyZMxEWFobt27fj+vXr+O6777B27VrDpGxwcDB++OEHzJo1C+np6di5c6fJ3wbWtm1bZGVl4YsvvsD169cRHR0tOhlua2uLoKAgfP/99zhx4gTefvttvPrqq1CpVACAhQsXIioqCtHR0fjPf/6DS5cu4ZNPPsGHH35oUj1ENcbSkxZkOb+fQDZle05OjjB+/HihadOmgkKhEFq3bi1MnjxZKCgoEATh4YTx9OnTBaVSKTRq1EgIDw8Xxo8f/9gJZEEQhPv37wthYWGCm5ubIJfLBU9PT2Hbtm2G7YsWLRJUKpUgk8mEoKAgQRAeTnqvXr1a8PLyEmxsbIRmzZoJGo1GOHbsmGG//fv3C56enoJCoRB69+4tbNu2zeQJ5FmzZglNmjQRHBwchNdee01YtWqV4OTkZNg+f/58oWvXrsKGDRsEd3d3wdbWVhg5cqSQl5dndNzY2FihW7duglwuFxo3biz4+fkJX3/9tSAInEAmy+PXXhIREYeJiIiIYUBERGAYEBERGAZERASGARERgWFARERgGBARERgGREQEhgEREYFhQEREYBgQEREYBkREBOD/AQBZlIlW8t35AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GveN_7sgEgu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.2, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.8)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model with Nadam optimizer\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "nadam = Nadam(lr=0.001, beta_1=0.9, beta_2=0.999)\n",
        "model.compile(loss='binary_crossentropy', optimizer=nadam, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping to prevent overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "# Predict the class probabilities on the test set\n",
        "y_prob = model.predict(X_test)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions\n",
        "y_pred = (y_prob > 0.05).astype(int)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Calculate the accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "\n",
        "# Calculate the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "0Utv4cBnB3ER",
        "outputId": "ebd0bb7e-5c0b-472e-cd52-2534308103ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Nadam.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 3s 5ms/step - loss: 4.7270 - accuracy: 0.9309 - val_loss: 0.9443 - val_accuracy: 0.9856\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.9833 - val_loss: 0.1105 - val_accuracy: 0.9860\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9833 - val_loss: 0.0762 - val_accuracy: 0.9860\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9833 - val_loss: 0.0752 - val_accuracy: 0.9860\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9833 - val_loss: 0.0729 - val_accuracy: 0.9860\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0828 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9833 - val_loss: 0.0738 - val_accuracy: 0.9860\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0829 - accuracy: 0.9833 - val_loss: 0.0735 - val_accuracy: 0.9860\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0827 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9833 - val_loss: 0.0744 - val_accuracy: 0.9860\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9833 - val_loss: 0.0758 - val_accuracy: 0.9860\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9833 - val_loss: 0.0759 - val_accuracy: 0.9860\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0826 - accuracy: 0.9833 - val_loss: 0.0738 - val_accuracy: 0.9860\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9833 - val_loss: 0.0734 - val_accuracy: 0.9860\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0823 - accuracy: 0.9833 - val_loss: 0.0742 - val_accuracy: 0.9860\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0815 - accuracy: 0.9833 - val_loss: 0.0726 - val_accuracy: 0.9860\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.9833 - val_loss: 0.0732 - val_accuracy: 0.9860\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9833 - val_loss: 0.0738 - val_accuracy: 0.9860\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0824 - accuracy: 0.9833 - val_loss: 0.0725 - val_accuracy: 0.9860\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.0728 - val_accuracy: 0.9860\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9833 - val_loss: 0.0727 - val_accuracy: 0.9860\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.0739 - val_accuracy: 0.9860\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0819 - accuracy: 0.9833 - val_loss: 0.0738 - val_accuracy: 0.9860\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0819 - accuracy: 0.9833 - val_loss: 0.0723 - val_accuracy: 0.9860\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.0728 - val_accuracy: 0.9860\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.0729 - val_accuracy: 0.9860\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 0.0734 - val_accuracy: 0.9860\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9833 - val_loss: 0.0729 - val_accuracy: 0.9860\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0817 - accuracy: 0.9833 - val_loss: 0.0728 - val_accuracy: 0.9860\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 0.0724 - val_accuracy: 0.9860\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9833 - val_loss: 0.0721 - val_accuracy: 0.9860\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0813 - accuracy: 0.9833 - val_loss: 0.0733 - val_accuracy: 0.9860\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0814 - accuracy: 0.9833 - val_loss: 0.0725 - val_accuracy: 0.9860\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0810 - accuracy: 0.9833 - val_loss: 0.0740 - val_accuracy: 0.9860\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0811 - accuracy: 0.9833 - val_loss: 0.0721 - val_accuracy: 0.9860\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0809 - accuracy: 0.9833 - val_loss: 0.0717 - val_accuracy: 0.9860\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0721 - val_accuracy: 0.9860\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0812 - accuracy: 0.9833 - val_loss: 0.0754 - val_accuracy: 0.9860\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0810 - accuracy: 0.9833 - val_loss: 0.0731 - val_accuracy: 0.9860\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9833 - val_loss: 0.0746 - val_accuracy: 0.9860\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9833 - val_loss: 0.0748 - val_accuracy: 0.9860\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0796 - accuracy: 0.9833 - val_loss: 0.0711 - val_accuracy: 0.9860\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0738 - val_accuracy: 0.9860\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0714 - val_accuracy: 0.9860\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0719 - val_accuracy: 0.9860\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0802 - accuracy: 0.9833 - val_loss: 0.0720 - val_accuracy: 0.9860\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9833 - val_loss: 0.0742 - val_accuracy: 0.9860\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9833 - val_loss: 0.0711 - val_accuracy: 0.9860\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.9833 - val_loss: 0.0727 - val_accuracy: 0.9860\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0790 - accuracy: 0.9833 - val_loss: 0.0722 - val_accuracy: 0.9860\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0805 - accuracy: 0.9833 - val_loss: 0.0715 - val_accuracy: 0.9860\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 2s 5ms/step - loss: 0.0797 - accuracy: 0.9833 - val_loss: 0.0712 - val_accuracy: 0.9860\n",
            "Epoch 54: early stopping\n",
            "104/104 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.9766807995154452\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one].values\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target'].values\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "def create_model(input_dim):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=input_dim, activation='relu', kernel_regularizer=l2(0.5)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model\n",
        "\n",
        "# Set up k-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize lists to store the performance metrics for each fold\n",
        "acc_per_fold = []\n",
        "cm_per_fold = []\n",
        "\n",
        "# Iterate over the folds\n",
        "for fold, (train_indices, val_indices) in enumerate(kfold.split(X, y_true)):\n",
        "    print(f'Fold {fold+1}...')\n",
        "\n",
        "    # Split the data into training and validation sets for this fold\n",
        "    X_train, y_train = X[train_indices], y_true[train_indices]\n",
        "    X_val, y_val = X[val_indices], y_true[val_indices]\n",
        "\n",
        "    # Standardize the input features using the training set statistics\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "    # Define the neural network\n",
        "    model = create_model(X_train.shape[1])\n",
        "\n",
        "    # Compile the model with RMSprop optimizer\n",
        "    rmsprop = RMSprop(lr=0.002, rho=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with early stopping to prevent overfitting\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "    history = model.fit(X_train_scaled, y_train, epochs=100, batch_size=32, validation_data=(X_val_scaled, y_val), callbacks=[es])\n",
        "\n",
        "    # Predict the class probabilities on the validation set\n",
        "    y_prob = model.predict(X_val_scaled)\n",
        "\n",
        "    # Threshold the probabilities to get binary predictions\n",
        "    y_pred = (y_prob > 0.05).astype(int)\n",
        "\n",
        "    # Evaluate the model's performance on the validation set\n",
        "    acc = accuracy_score(y_val, y_pred)\n",
        "    acc_per_fold.append(acc)\n",
        "    cm = confusion_matrix(y_val, y_pred)\n",
        "    cm_per_fold.append(cm)\n",
        "\n",
        "    print(f'Accuracy: {acc:.2f}')\n",
        "    print(f'Confusion matrix:\\n{cm}')\n",
        "\n",
        "# Calculate the mean and standard deviation of the performance metrics across the folds\n",
        "mean_acc = np.mean(acc_per_fold)\n",
        "std_acc =np.std(acc_per_fold)\n",
        "mean_cm = np.mean(cm_per_fold, axis=0)\n",
        "std_cm = np.std(cm_per_fold, axis=0)\n",
        "\n",
        "# Print the overall performance metrics\n",
        "print(f'\\nOverall accuracy: {mean_acc:.2f} +/- {std_acc:.2f}')\n",
        "print(f'Overall confusion matrix:\\n{mean_cm}')\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(mean_cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8PnBXn_L8wI4",
        "outputId": "e9e34f9f-7227-4e84-fb50-519fe446862e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1...\n",
            "Epoch 1/100\n",
            "334/334 [==============================] - 2s 3ms/step - loss: 2.1812 - accuracy: 0.7769 - val_loss: 0.4471 - val_accuracy: 0.9546\n",
            "Epoch 2/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.3514 - accuracy: 0.9547 - val_loss: 0.2700 - val_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.2209 - accuracy: 0.9547 - val_loss: 0.1930 - val_accuracy: 0.9546\n",
            "Epoch 4/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1796 - accuracy: 0.9547 - val_loss: 0.1825 - val_accuracy: 0.9546\n",
            "Epoch 5/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1747 - accuracy: 0.9547 - val_loss: 0.1808 - val_accuracy: 0.9546\n",
            "Epoch 6/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9547 - val_loss: 0.1799 - val_accuracy: 0.9546\n",
            "Epoch 7/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1740 - accuracy: 0.9547 - val_loss: 0.1810 - val_accuracy: 0.9546\n",
            "Epoch 8/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1737 - accuracy: 0.9547 - val_loss: 0.1802 - val_accuracy: 0.9546\n",
            "Epoch 9/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1735 - accuracy: 0.9547 - val_loss: 0.1780 - val_accuracy: 0.9546\n",
            "Epoch 10/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9547 - val_loss: 0.1812 - val_accuracy: 0.9546\n",
            "Epoch 11/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1727 - accuracy: 0.9547 - val_loss: 0.1785 - val_accuracy: 0.9546\n",
            "Epoch 12/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9547 - val_loss: 0.1798 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1726 - accuracy: 0.9547 - val_loss: 0.1806 - val_accuracy: 0.9546\n",
            "Epoch 14/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.9547 - val_loss: 0.1788 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1718 - accuracy: 0.9547 - val_loss: 0.1803 - val_accuracy: 0.9546\n",
            "Epoch 16/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9547 - val_loss: 0.1783 - val_accuracy: 0.9546\n",
            "Epoch 17/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1713 - accuracy: 0.9547 - val_loss: 0.1806 - val_accuracy: 0.9546\n",
            "Epoch 18/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1712 - accuracy: 0.9547 - val_loss: 0.1779 - val_accuracy: 0.9546\n",
            "Epoch 19/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9547 - val_loss: 0.1799 - val_accuracy: 0.9546\n",
            "Epoch 20/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9547 - val_loss: 0.1780 - val_accuracy: 0.9546\n",
            "Epoch 21/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9547 - val_loss: 0.1791 - val_accuracy: 0.9546\n",
            "Epoch 22/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1702 - accuracy: 0.9547 - val_loss: 0.1792 - val_accuracy: 0.9546\n",
            "Epoch 23/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1697 - accuracy: 0.9547 - val_loss: 0.1788 - val_accuracy: 0.9546\n",
            "Epoch 24/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9547 - val_loss: 0.1794 - val_accuracy: 0.9546\n",
            "Epoch 25/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1694 - accuracy: 0.9547 - val_loss: 0.1796 - val_accuracy: 0.9546\n",
            "Epoch 26/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9547 - val_loss: 0.1789 - val_accuracy: 0.9546\n",
            "Epoch 27/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9547 - val_loss: 0.1773 - val_accuracy: 0.9546\n",
            "Epoch 28/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9547 - val_loss: 0.1787 - val_accuracy: 0.9546\n",
            "Epoch 29/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9547 - val_loss: 0.1787 - val_accuracy: 0.9546\n",
            "Epoch 30/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1687 - accuracy: 0.9547 - val_loss: 0.1805 - val_accuracy: 0.9546\n",
            "Epoch 31/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1683 - accuracy: 0.9547 - val_loss: 0.1821 - val_accuracy: 0.9546\n",
            "Epoch 32/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9547 - val_loss: 0.1759 - val_accuracy: 0.9546\n",
            "Epoch 33/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9547 - val_loss: 0.1813 - val_accuracy: 0.9546\n",
            "Epoch 34/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9547 - val_loss: 0.1789 - val_accuracy: 0.9546\n",
            "Epoch 35/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9547 - val_loss: 0.1816 - val_accuracy: 0.9546\n",
            "Epoch 36/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1678 - accuracy: 0.9547 - val_loss: 0.1796 - val_accuracy: 0.9546\n",
            "Epoch 37/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1674 - accuracy: 0.9547 - val_loss: 0.1805 - val_accuracy: 0.9546\n",
            "Epoch 38/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9547 - val_loss: 0.1791 - val_accuracy: 0.9546\n",
            "Epoch 39/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9547 - val_loss: 0.1775 - val_accuracy: 0.9546\n",
            "Epoch 40/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9547 - val_loss: 0.1774 - val_accuracy: 0.9546\n",
            "Epoch 41/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9547 - val_loss: 0.1796 - val_accuracy: 0.9546\n",
            "Epoch 42/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1664 - accuracy: 0.9547 - val_loss: 0.1740 - val_accuracy: 0.9546\n",
            "Epoch 43/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1668 - accuracy: 0.9547 - val_loss: 0.1812 - val_accuracy: 0.9546\n",
            "Epoch 44/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1660 - accuracy: 0.9547 - val_loss: 0.1776 - val_accuracy: 0.9546\n",
            "Epoch 45/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9547 - val_loss: 0.1767 - val_accuracy: 0.9546\n",
            "Epoch 46/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9547 - val_loss: 0.1771 - val_accuracy: 0.9546\n",
            "Epoch 47/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9547 - val_loss: 0.1796 - val_accuracy: 0.9546\n",
            "Epoch 48/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9547 - val_loss: 0.1745 - val_accuracy: 0.9546\n",
            "Epoch 49/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9547 - val_loss: 0.1774 - val_accuracy: 0.9546\n",
            "Epoch 50/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9547 - val_loss: 0.1836 - val_accuracy: 0.9546\n",
            "Epoch 51/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9547 - val_loss: 0.1800 - val_accuracy: 0.9546\n",
            "Epoch 52/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9547 - val_loss: 0.1850 - val_accuracy: 0.9546\n",
            "Epoch 52: early stopping\n",
            "84/84 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.85\n",
            "Confusion matrix:\n",
            "[[2188  357]\n",
            " [  41   80]]\n",
            "Fold 2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "334/334 [==============================] - 2s 3ms/step - loss: 2.0503 - accuracy: 0.8355 - val_loss: 0.3802 - val_accuracy: 0.9550\n",
            "Epoch 2/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.2785 - accuracy: 0.9546 - val_loss: 0.2048 - val_accuracy: 0.9550\n",
            "Epoch 3/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9546 - val_loss: 0.1751 - val_accuracy: 0.9550\n",
            "Epoch 4/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1743 - accuracy: 0.9546 - val_loss: 0.1736 - val_accuracy: 0.9550\n",
            "Epoch 5/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9546 - val_loss: 0.1738 - val_accuracy: 0.9550\n",
            "Epoch 6/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1744 - accuracy: 0.9546 - val_loss: 0.1732 - val_accuracy: 0.9550\n",
            "Epoch 7/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9546 - val_loss: 0.1727 - val_accuracy: 0.9550\n",
            "Epoch 8/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1733 - accuracy: 0.9546 - val_loss: 0.1728 - val_accuracy: 0.9550\n",
            "Epoch 9/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9546 - val_loss: 0.1719 - val_accuracy: 0.9550\n",
            "Epoch 10/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1728 - accuracy: 0.9546 - val_loss: 0.1724 - val_accuracy: 0.9550\n",
            "Epoch 11/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1731 - accuracy: 0.9546 - val_loss: 0.1722 - val_accuracy: 0.9550\n",
            "Epoch 12/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1719 - accuracy: 0.9546 - val_loss: 0.1728 - val_accuracy: 0.9550\n",
            "Epoch 13/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1722 - accuracy: 0.9546 - val_loss: 0.1725 - val_accuracy: 0.9550\n",
            "Epoch 14/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1713 - accuracy: 0.9546 - val_loss: 0.1719 - val_accuracy: 0.9550\n",
            "Epoch 15/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1719 - accuracy: 0.9546 - val_loss: 0.1704 - val_accuracy: 0.9550\n",
            "Epoch 16/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9546 - val_loss: 0.1708 - val_accuracy: 0.9550\n",
            "Epoch 17/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9546 - val_loss: 0.1719 - val_accuracy: 0.9550\n",
            "Epoch 18/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1704 - accuracy: 0.9546 - val_loss: 0.1698 - val_accuracy: 0.9550\n",
            "Epoch 19/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1705 - accuracy: 0.9546 - val_loss: 0.1715 - val_accuracy: 0.9550\n",
            "Epoch 20/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1695 - accuracy: 0.9546 - val_loss: 0.1713 - val_accuracy: 0.9550\n",
            "Epoch 21/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1707 - accuracy: 0.9546 - val_loss: 0.1694 - val_accuracy: 0.9550\n",
            "Epoch 22/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9546 - val_loss: 0.1709 - val_accuracy: 0.9550\n",
            "Epoch 23/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9546 - val_loss: 0.1698 - val_accuracy: 0.9550\n",
            "Epoch 24/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1701 - accuracy: 0.9546 - val_loss: 0.1691 - val_accuracy: 0.9550\n",
            "Epoch 25/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.9546 - val_loss: 0.1682 - val_accuracy: 0.9550\n",
            "Epoch 26/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1686 - accuracy: 0.9546 - val_loss: 0.1691 - val_accuracy: 0.9550\n",
            "Epoch 27/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1693 - accuracy: 0.9546 - val_loss: 0.1684 - val_accuracy: 0.9550\n",
            "Epoch 28/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1686 - accuracy: 0.9546 - val_loss: 0.1677 - val_accuracy: 0.9550\n",
            "Epoch 29/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9546 - val_loss: 0.1675 - val_accuracy: 0.9550\n",
            "Epoch 30/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9546 - val_loss: 0.1689 - val_accuracy: 0.9550\n",
            "Epoch 31/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1676 - accuracy: 0.9546 - val_loss: 0.1673 - val_accuracy: 0.9550\n",
            "Epoch 32/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9546 - val_loss: 0.1685 - val_accuracy: 0.9550\n",
            "Epoch 33/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9546 - val_loss: 0.1676 - val_accuracy: 0.9550\n",
            "Epoch 34/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1674 - accuracy: 0.9546 - val_loss: 0.1673 - val_accuracy: 0.9550\n",
            "Epoch 35/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9546 - val_loss: 0.1690 - val_accuracy: 0.9550\n",
            "Epoch 36/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9546 - val_loss: 0.1657 - val_accuracy: 0.9550\n",
            "Epoch 37/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9546 - val_loss: 0.1667 - val_accuracy: 0.9550\n",
            "Epoch 38/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9546 - val_loss: 0.1655 - val_accuracy: 0.9550\n",
            "Epoch 39/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9546 - val_loss: 0.1661 - val_accuracy: 0.9550\n",
            "Epoch 40/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9546 - val_loss: 0.1662 - val_accuracy: 0.9550\n",
            "Epoch 41/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1633 - accuracy: 0.9546 - val_loss: 0.1654 - val_accuracy: 0.9550\n",
            "Epoch 42/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9546 - val_loss: 0.1658 - val_accuracy: 0.9550\n",
            "Epoch 43/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1638 - accuracy: 0.9546 - val_loss: 0.1654 - val_accuracy: 0.9550\n",
            "Epoch 44/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1637 - accuracy: 0.9546 - val_loss: 0.1654 - val_accuracy: 0.9550\n",
            "Epoch 45/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9546 - val_loss: 0.1645 - val_accuracy: 0.9550\n",
            "Epoch 46/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9546 - val_loss: 0.1633 - val_accuracy: 0.9550\n",
            "Epoch 47/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9546 - val_loss: 0.1636 - val_accuracy: 0.9550\n",
            "Epoch 48/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9546 - val_loss: 0.1640 - val_accuracy: 0.9550\n",
            "Epoch 49/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1628 - accuracy: 0.9546 - val_loss: 0.1632 - val_accuracy: 0.9550\n",
            "Epoch 50/100\n",
            "334/334 [==============================] - 2s 5ms/step - loss: 0.1616 - accuracy: 0.9546 - val_loss: 0.1646 - val_accuracy: 0.9550\n",
            "Epoch 51/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9546 - val_loss: 0.1652 - val_accuracy: 0.9550\n",
            "Epoch 52/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1625 - accuracy: 0.9546 - val_loss: 0.1649 - val_accuracy: 0.9550\n",
            "Epoch 53/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9546 - val_loss: 0.1631 - val_accuracy: 0.9550\n",
            "Epoch 54/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9546 - val_loss: 0.1642 - val_accuracy: 0.9550\n",
            "Epoch 55/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1609 - accuracy: 0.9546 - val_loss: 0.1628 - val_accuracy: 0.9550\n",
            "Epoch 56/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9546 - val_loss: 0.1636 - val_accuracy: 0.9550\n",
            "Epoch 57/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9546 - val_loss: 0.1643 - val_accuracy: 0.9550\n",
            "Epoch 58/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9546 - val_loss: 0.1616 - val_accuracy: 0.9550\n",
            "Epoch 59/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9546 - val_loss: 0.1625 - val_accuracy: 0.9550\n",
            "Epoch 60/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9546 - val_loss: 0.1613 - val_accuracy: 0.9550\n",
            "Epoch 61/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9546 - val_loss: 0.1630 - val_accuracy: 0.9546\n",
            "Epoch 62/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9557 - val_loss: 0.1634 - val_accuracy: 0.9557\n",
            "Epoch 63/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1598 - accuracy: 0.9568 - val_loss: 0.1633 - val_accuracy: 0.9546\n",
            "Epoch 64/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1597 - accuracy: 0.9565 - val_loss: 0.1640 - val_accuracy: 0.9565\n",
            "Epoch 65/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1615 - accuracy: 0.9560 - val_loss: 0.1661 - val_accuracy: 0.9572\n",
            "Epoch 66/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9565 - val_loss: 0.1614 - val_accuracy: 0.9565\n",
            "Epoch 67/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9569 - val_loss: 0.1611 - val_accuracy: 0.9561\n",
            "Epoch 68/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9561 - val_loss: 0.1609 - val_accuracy: 0.9565\n",
            "Epoch 69/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9563 - val_loss: 0.1646 - val_accuracy: 0.9568\n",
            "Epoch 70/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9560 - val_loss: 0.1611 - val_accuracy: 0.9572\n",
            "Epoch 71/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9561 - val_loss: 0.1615 - val_accuracy: 0.9572\n",
            "Epoch 72/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9566 - val_loss: 0.1614 - val_accuracy: 0.9553\n",
            "Epoch 73/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9563 - val_loss: 0.1608 - val_accuracy: 0.9565\n",
            "Epoch 74/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1590 - accuracy: 0.9564 - val_loss: 0.1618 - val_accuracy: 0.9557\n",
            "Epoch 75/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9562 - val_loss: 0.1594 - val_accuracy: 0.9565\n",
            "Epoch 76/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1594 - accuracy: 0.9568 - val_loss: 0.1618 - val_accuracy: 0.9561\n",
            "Epoch 77/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1591 - accuracy: 0.9566 - val_loss: 0.1616 - val_accuracy: 0.9538\n",
            "Epoch 78/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9564 - val_loss: 0.1604 - val_accuracy: 0.9546\n",
            "Epoch 79/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1588 - accuracy: 0.9561 - val_loss: 0.1596 - val_accuracy: 0.9572\n",
            "Epoch 80/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9569 - val_loss: 0.1598 - val_accuracy: 0.9553\n",
            "Epoch 81/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9569 - val_loss: 0.1588 - val_accuracy: 0.9565\n",
            "Epoch 82/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9569 - val_loss: 0.1624 - val_accuracy: 0.9550\n",
            "Epoch 83/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1578 - accuracy: 0.9565 - val_loss: 0.1620 - val_accuracy: 0.9576\n",
            "Epoch 84/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1579 - accuracy: 0.9566 - val_loss: 0.1612 - val_accuracy: 0.9565\n",
            "Epoch 85/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9566 - val_loss: 0.1610 - val_accuracy: 0.9557\n",
            "Epoch 86/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9569 - val_loss: 0.1632 - val_accuracy: 0.9542\n",
            "Epoch 87/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1602 - accuracy: 0.9565 - val_loss: 0.1617 - val_accuracy: 0.9572\n",
            "Epoch 88/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9568 - val_loss: 0.1624 - val_accuracy: 0.9572\n",
            "Epoch 89/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9569 - val_loss: 0.1599 - val_accuracy: 0.9576\n",
            "Epoch 90/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1573 - accuracy: 0.9570 - val_loss: 0.1596 - val_accuracy: 0.9565\n",
            "Epoch 91/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1557 - accuracy: 0.9573 - val_loss: 0.1579 - val_accuracy: 0.9568\n",
            "Epoch 92/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.9573 - val_loss: 0.1613 - val_accuracy: 0.9546\n",
            "Epoch 93/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1568 - accuracy: 0.9567 - val_loss: 0.1627 - val_accuracy: 0.9535\n",
            "Epoch 94/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9565 - val_loss: 0.1634 - val_accuracy: 0.9572\n",
            "Epoch 95/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9567 - val_loss: 0.1598 - val_accuracy: 0.9553\n",
            "Epoch 96/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9567 - val_loss: 0.1600 - val_accuracy: 0.9546\n",
            "Epoch 97/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1572 - accuracy: 0.9557 - val_loss: 0.1609 - val_accuracy: 0.9542\n",
            "Epoch 98/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1566 - accuracy: 0.9570 - val_loss: 0.1607 - val_accuracy: 0.9568\n",
            "Epoch 99/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1549 - accuracy: 0.9567 - val_loss: 0.1584 - val_accuracy: 0.9542\n",
            "Epoch 100/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1570 - accuracy: 0.9564 - val_loss: 0.1599 - val_accuracy: 0.9568\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.87\n",
            "Confusion matrix:\n",
            "[[2239  306]\n",
            " [  51   69]]\n",
            "Fold 3...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "334/334 [==============================] - 2s 3ms/step - loss: 1.7185 - accuracy: 0.9552 - val_loss: 0.1824 - val_accuracy: 0.9542\n",
            "Epoch 2/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9547 - val_loss: 0.1675 - val_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9547 - val_loss: 0.1696 - val_accuracy: 0.9546\n",
            "Epoch 4/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9547 - val_loss: 0.1650 - val_accuracy: 0.9546\n",
            "Epoch 5/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9547 - val_loss: 0.1654 - val_accuracy: 0.9546\n",
            "Epoch 6/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1711 - accuracy: 0.9547 - val_loss: 0.1661 - val_accuracy: 0.9546\n",
            "Epoch 7/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1708 - accuracy: 0.9547 - val_loss: 0.1643 - val_accuracy: 0.9546\n",
            "Epoch 8/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1698 - accuracy: 0.9547 - val_loss: 0.1633 - val_accuracy: 0.9546\n",
            "Epoch 9/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1710 - accuracy: 0.9547 - val_loss: 0.1660 - val_accuracy: 0.9546\n",
            "Epoch 10/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1704 - accuracy: 0.9547 - val_loss: 0.1661 - val_accuracy: 0.9546\n",
            "Epoch 11/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9547 - val_loss: 0.1615 - val_accuracy: 0.9546\n",
            "Epoch 12/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.9547 - val_loss: 0.1599 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9547 - val_loss: 0.1651 - val_accuracy: 0.9546\n",
            "Epoch 14/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1685 - accuracy: 0.9547 - val_loss: 0.1606 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9547 - val_loss: 0.1656 - val_accuracy: 0.9546\n",
            "Epoch 16/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1679 - accuracy: 0.9547 - val_loss: 0.1590 - val_accuracy: 0.9546\n",
            "Epoch 17/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9547 - val_loss: 0.1615 - val_accuracy: 0.9546\n",
            "Epoch 18/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1668 - accuracy: 0.9547 - val_loss: 0.1580 - val_accuracy: 0.9546\n",
            "Epoch 19/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1653 - accuracy: 0.9547 - val_loss: 0.1585 - val_accuracy: 0.9546\n",
            "Epoch 20/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1664 - accuracy: 0.9547 - val_loss: 0.1603 - val_accuracy: 0.9546\n",
            "Epoch 21/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9547 - val_loss: 0.1571 - val_accuracy: 0.9546\n",
            "Epoch 22/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1647 - accuracy: 0.9547 - val_loss: 0.1577 - val_accuracy: 0.9546\n",
            "Epoch 23/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1634 - accuracy: 0.9547 - val_loss: 0.1589 - val_accuracy: 0.9546\n",
            "Epoch 24/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1654 - accuracy: 0.9547 - val_loss: 0.1577 - val_accuracy: 0.9546\n",
            "Epoch 25/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9547 - val_loss: 0.1556 - val_accuracy: 0.9546\n",
            "Epoch 26/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.9547 - val_loss: 0.1615 - val_accuracy: 0.9546\n",
            "Epoch 27/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1639 - accuracy: 0.9547 - val_loss: 0.1557 - val_accuracy: 0.9546\n",
            "Epoch 28/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9547 - val_loss: 0.1548 - val_accuracy: 0.9546\n",
            "Epoch 29/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9547 - val_loss: 0.1597 - val_accuracy: 0.9546\n",
            "Epoch 30/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1622 - accuracy: 0.9547 - val_loss: 0.1616 - val_accuracy: 0.9546\n",
            "Epoch 31/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1658 - accuracy: 0.9547 - val_loss: 0.1539 - val_accuracy: 0.9546\n",
            "Epoch 32/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9547 - val_loss: 0.1524 - val_accuracy: 0.9546\n",
            "Epoch 33/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1646 - accuracy: 0.9547 - val_loss: 0.1651 - val_accuracy: 0.9546\n",
            "Epoch 34/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9547 - val_loss: 0.1581 - val_accuracy: 0.9546\n",
            "Epoch 35/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1649 - accuracy: 0.9547 - val_loss: 0.1541 - val_accuracy: 0.9546\n",
            "Epoch 36/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1646 - accuracy: 0.9547 - val_loss: 0.1597 - val_accuracy: 0.9546\n",
            "Epoch 37/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9547 - val_loss: 0.1567 - val_accuracy: 0.9546\n",
            "Epoch 38/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1621 - accuracy: 0.9547 - val_loss: 0.1516 - val_accuracy: 0.9546\n",
            "Epoch 39/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1627 - accuracy: 0.9547 - val_loss: 0.1560 - val_accuracy: 0.9546\n",
            "Epoch 40/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1644 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9546\n",
            "Epoch 41/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1619 - accuracy: 0.9547 - val_loss: 0.1533 - val_accuracy: 0.9546\n",
            "Epoch 42/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9547 - val_loss: 0.1535 - val_accuracy: 0.9546\n",
            "Epoch 43/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9547 - val_loss: 0.1528 - val_accuracy: 0.9546\n",
            "Epoch 44/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1623 - accuracy: 0.9547 - val_loss: 0.1531 - val_accuracy: 0.9546\n",
            "Epoch 45/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9546 - val_loss: 0.1534 - val_accuracy: 0.9542\n",
            "Epoch 46/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9558 - val_loss: 0.1544 - val_accuracy: 0.9546\n",
            "Epoch 47/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9554 - val_loss: 0.1524 - val_accuracy: 0.9553\n",
            "Epoch 48/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9562 - val_loss: 0.1494 - val_accuracy: 0.9591\n",
            "Epoch 49/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9558 - val_loss: 0.1605 - val_accuracy: 0.9595\n",
            "Epoch 50/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9566 - val_loss: 0.1621 - val_accuracy: 0.9595\n",
            "Epoch 51/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9559 - val_loss: 0.1549 - val_accuracy: 0.9561\n",
            "Epoch 52/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9559 - val_loss: 0.1514 - val_accuracy: 0.9595\n",
            "Epoch 53/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1637 - accuracy: 0.9561 - val_loss: 0.1549 - val_accuracy: 0.9587\n",
            "Epoch 54/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1609 - accuracy: 0.9569 - val_loss: 0.1517 - val_accuracy: 0.9572\n",
            "Epoch 55/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.9564 - val_loss: 0.1548 - val_accuracy: 0.9516\n",
            "Epoch 56/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9564 - val_loss: 0.1486 - val_accuracy: 0.9576\n",
            "Epoch 57/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9559 - val_loss: 0.1530 - val_accuracy: 0.9538\n",
            "Epoch 58/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1623 - accuracy: 0.9560 - val_loss: 0.1505 - val_accuracy: 0.9565\n",
            "Epoch 59/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9567 - val_loss: 0.1493 - val_accuracy: 0.9568\n",
            "Epoch 60/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9560 - val_loss: 0.1529 - val_accuracy: 0.9595\n",
            "Epoch 61/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9557 - val_loss: 0.1602 - val_accuracy: 0.9568\n",
            "Epoch 62/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1577 - accuracy: 0.9560 - val_loss: 0.1524 - val_accuracy: 0.9538\n",
            "Epoch 63/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1594 - accuracy: 0.9562 - val_loss: 0.1544 - val_accuracy: 0.9538\n",
            "Epoch 64/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1632 - accuracy: 0.9560 - val_loss: 0.1505 - val_accuracy: 0.9542\n",
            "Epoch 65/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9565 - val_loss: 0.1504 - val_accuracy: 0.9568\n",
            "Epoch 66/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9563 - val_loss: 0.1516 - val_accuracy: 0.9557\n",
            "Epoch 66: early stopping\n",
            "84/84 [==============================] - 0s 3ms/step\n",
            "Accuracy: 0.88\n",
            "Confusion matrix:\n",
            "[[2264  280]\n",
            " [  44   77]]\n",
            "Fold 4...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "334/334 [==============================] - 2s 4ms/step - loss: 1.8041 - accuracy: 0.9167 - val_loss: 0.2649 - val_accuracy: 0.9546\n",
            "Epoch 2/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1961 - accuracy: 0.9547 - val_loss: 0.1782 - val_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9547 - val_loss: 0.1734 - val_accuracy: 0.9546\n",
            "Epoch 4/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1734 - accuracy: 0.9547 - val_loss: 0.1759 - val_accuracy: 0.9546\n",
            "Epoch 5/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1732 - accuracy: 0.9547 - val_loss: 0.1736 - val_accuracy: 0.9546\n",
            "Epoch 6/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1744 - accuracy: 0.9547 - val_loss: 0.1741 - val_accuracy: 0.9546\n",
            "Epoch 7/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1732 - accuracy: 0.9547 - val_loss: 0.1718 - val_accuracy: 0.9546\n",
            "Epoch 8/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1728 - accuracy: 0.9547 - val_loss: 0.1790 - val_accuracy: 0.9546\n",
            "Epoch 9/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1706 - accuracy: 0.9547 - val_loss: 0.1753 - val_accuracy: 0.9546\n",
            "Epoch 10/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9547 - val_loss: 0.1736 - val_accuracy: 0.9546\n",
            "Epoch 11/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1714 - accuracy: 0.9547 - val_loss: 0.1758 - val_accuracy: 0.9546\n",
            "Epoch 12/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1718 - accuracy: 0.9547 - val_loss: 0.1693 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1713 - accuracy: 0.9547 - val_loss: 0.1732 - val_accuracy: 0.9546\n",
            "Epoch 14/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1707 - accuracy: 0.9547 - val_loss: 0.1785 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9547 - val_loss: 0.1691 - val_accuracy: 0.9546\n",
            "Epoch 16/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1708 - accuracy: 0.9547 - val_loss: 0.1770 - val_accuracy: 0.9546\n",
            "Epoch 17/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9547 - val_loss: 0.1698 - val_accuracy: 0.9546\n",
            "Epoch 18/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1689 - accuracy: 0.9547 - val_loss: 0.1685 - val_accuracy: 0.9546\n",
            "Epoch 19/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9547 - val_loss: 0.1726 - val_accuracy: 0.9546\n",
            "Epoch 20/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9547 - val_loss: 0.1690 - val_accuracy: 0.9546\n",
            "Epoch 21/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1682 - accuracy: 0.9547 - val_loss: 0.1643 - val_accuracy: 0.9546\n",
            "Epoch 22/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1681 - accuracy: 0.9547 - val_loss: 0.1665 - val_accuracy: 0.9546\n",
            "Epoch 23/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.9547 - val_loss: 0.1685 - val_accuracy: 0.9546\n",
            "Epoch 24/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1679 - accuracy: 0.9547 - val_loss: 0.1756 - val_accuracy: 0.9546\n",
            "Epoch 25/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1691 - accuracy: 0.9547 - val_loss: 0.1685 - val_accuracy: 0.9546\n",
            "Epoch 26/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9547 - val_loss: 0.1661 - val_accuracy: 0.9546\n",
            "Epoch 27/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1663 - accuracy: 0.9547 - val_loss: 0.1643 - val_accuracy: 0.9546\n",
            "Epoch 28/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1674 - accuracy: 0.9547 - val_loss: 0.1645 - val_accuracy: 0.9546\n",
            "Epoch 29/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1676 - accuracy: 0.9547 - val_loss: 0.1676 - val_accuracy: 0.9546\n",
            "Epoch 30/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9547 - val_loss: 0.1715 - val_accuracy: 0.9542\n",
            "Epoch 31/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1655 - accuracy: 0.9547 - val_loss: 0.1690 - val_accuracy: 0.9542\n",
            "Epoch 32/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1652 - accuracy: 0.9547 - val_loss: 0.1679 - val_accuracy: 0.9542\n",
            "Epoch 33/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1645 - accuracy: 0.9547 - val_loss: 0.1625 - val_accuracy: 0.9546\n",
            "Epoch 34/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1648 - accuracy: 0.9547 - val_loss: 0.1657 - val_accuracy: 0.9546\n",
            "Epoch 35/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1644 - accuracy: 0.9547 - val_loss: 0.1623 - val_accuracy: 0.9546\n",
            "Epoch 36/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1650 - accuracy: 0.9547 - val_loss: 0.1623 - val_accuracy: 0.9546\n",
            "Epoch 37/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9547 - val_loss: 0.1650 - val_accuracy: 0.9546\n",
            "Epoch 38/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1650 - accuracy: 0.9547 - val_loss: 0.1595 - val_accuracy: 0.9546\n",
            "Epoch 39/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1631 - accuracy: 0.9547 - val_loss: 0.1591 - val_accuracy: 0.9546\n",
            "Epoch 40/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1641 - accuracy: 0.9547 - val_loss: 0.1602 - val_accuracy: 0.9546\n",
            "Epoch 41/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1628 - accuracy: 0.9547 - val_loss: 0.1648 - val_accuracy: 0.9546\n",
            "Epoch 42/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9547 - val_loss: 0.1610 - val_accuracy: 0.9538\n",
            "Epoch 43/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1656 - accuracy: 0.9547 - val_loss: 0.1625 - val_accuracy: 0.9546\n",
            "Epoch 44/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9547 - val_loss: 0.1607 - val_accuracy: 0.9538\n",
            "Epoch 45/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9547 - val_loss: 0.1610 - val_accuracy: 0.9546\n",
            "Epoch 46/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1642 - accuracy: 0.9547 - val_loss: 0.1589 - val_accuracy: 0.9546\n",
            "Epoch 47/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1609 - accuracy: 0.9542 - val_loss: 0.1590 - val_accuracy: 0.9546\n",
            "Epoch 48/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9558 - val_loss: 0.1609 - val_accuracy: 0.9546\n",
            "Epoch 49/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9560 - val_loss: 0.1833 - val_accuracy: 0.9546\n",
            "Epoch 50/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1635 - accuracy: 0.9557 - val_loss: 0.1564 - val_accuracy: 0.9553\n",
            "Epoch 51/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9569 - val_loss: 0.1613 - val_accuracy: 0.9546\n",
            "Epoch 52/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1622 - accuracy: 0.9560 - val_loss: 0.1555 - val_accuracy: 0.9561\n",
            "Epoch 53/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9562 - val_loss: 0.1587 - val_accuracy: 0.9550\n",
            "Epoch 54/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9558 - val_loss: 0.1609 - val_accuracy: 0.9546\n",
            "Epoch 55/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9562 - val_loss: 0.1730 - val_accuracy: 0.9542\n",
            "Epoch 56/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1645 - accuracy: 0.9563 - val_loss: 0.1593 - val_accuracy: 0.9553\n",
            "Epoch 57/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1612 - accuracy: 0.9567 - val_loss: 0.1612 - val_accuracy: 0.9542\n",
            "Epoch 58/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1616 - accuracy: 0.9558 - val_loss: 0.1693 - val_accuracy: 0.9546\n",
            "Epoch 59/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9568 - val_loss: 0.1560 - val_accuracy: 0.9550\n",
            "Epoch 60/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1625 - accuracy: 0.9566 - val_loss: 0.1615 - val_accuracy: 0.9546\n",
            "Epoch 61/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1606 - accuracy: 0.9563 - val_loss: 0.1694 - val_accuracy: 0.9561\n",
            "Epoch 62/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1603 - accuracy: 0.9560 - val_loss: 0.1649 - val_accuracy: 0.9505\n",
            "Epoch 62: early stopping\n",
            "84/84 [==============================] - 0s 1ms/step\n",
            "Accuracy: 0.86\n",
            "Confusion matrix:\n",
            "[[2225  319]\n",
            " [  47   74]]\n",
            "Fold 5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "334/334 [==============================] - 2s 3ms/step - loss: 2.0875 - accuracy: 0.8672 - val_loss: 0.3154 - val_accuracy: 0.9546\n",
            "Epoch 2/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.2166 - accuracy: 0.9547 - val_loss: 0.1787 - val_accuracy: 0.9546\n",
            "Epoch 3/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1738 - accuracy: 0.9547 - val_loss: 0.1774 - val_accuracy: 0.9546\n",
            "Epoch 4/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1739 - accuracy: 0.9547 - val_loss: 0.1765 - val_accuracy: 0.9546\n",
            "Epoch 5/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.9547 - val_loss: 0.1761 - val_accuracy: 0.9546\n",
            "Epoch 6/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1735 - accuracy: 0.9547 - val_loss: 0.1763 - val_accuracy: 0.9546\n",
            "Epoch 7/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1727 - accuracy: 0.9547 - val_loss: 0.1756 - val_accuracy: 0.9546\n",
            "Epoch 8/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9547 - val_loss: 0.1748 - val_accuracy: 0.9546\n",
            "Epoch 9/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1715 - accuracy: 0.9547 - val_loss: 0.1756 - val_accuracy: 0.9546\n",
            "Epoch 10/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 0.9547 - val_loss: 0.1740 - val_accuracy: 0.9546\n",
            "Epoch 11/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1708 - accuracy: 0.9547 - val_loss: 0.1734 - val_accuracy: 0.9546\n",
            "Epoch 12/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9547 - val_loss: 0.1728 - val_accuracy: 0.9546\n",
            "Epoch 13/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9547 - val_loss: 0.1741 - val_accuracy: 0.9546\n",
            "Epoch 14/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1699 - accuracy: 0.9547 - val_loss: 0.1720 - val_accuracy: 0.9546\n",
            "Epoch 15/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1703 - accuracy: 0.9547 - val_loss: 0.1732 - val_accuracy: 0.9546\n",
            "Epoch 16/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1690 - accuracy: 0.9547 - val_loss: 0.1740 - val_accuracy: 0.9546\n",
            "Epoch 17/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.9547 - val_loss: 0.1721 - val_accuracy: 0.9546\n",
            "Epoch 18/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1672 - accuracy: 0.9547 - val_loss: 0.1720 - val_accuracy: 0.9546\n",
            "Epoch 19/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1672 - accuracy: 0.9547 - val_loss: 0.1693 - val_accuracy: 0.9546\n",
            "Epoch 20/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1671 - accuracy: 0.9547 - val_loss: 0.1699 - val_accuracy: 0.9546\n",
            "Epoch 21/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.9547 - val_loss: 0.1719 - val_accuracy: 0.9546\n",
            "Epoch 22/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1646 - accuracy: 0.9547 - val_loss: 0.1688 - val_accuracy: 0.9546\n",
            "Epoch 23/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1661 - accuracy: 0.9547 - val_loss: 0.1705 - val_accuracy: 0.9546\n",
            "Epoch 24/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1662 - accuracy: 0.9547 - val_loss: 0.1668 - val_accuracy: 0.9546\n",
            "Epoch 25/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9547 - val_loss: 0.1674 - val_accuracy: 0.9546\n",
            "Epoch 26/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1647 - accuracy: 0.9547 - val_loss: 0.1717 - val_accuracy: 0.9546\n",
            "Epoch 27/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1647 - accuracy: 0.9547 - val_loss: 0.1659 - val_accuracy: 0.9546\n",
            "Epoch 28/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1644 - accuracy: 0.9547 - val_loss: 0.1667 - val_accuracy: 0.9546\n",
            "Epoch 29/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9547 - val_loss: 0.1681 - val_accuracy: 0.9546\n",
            "Epoch 30/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9547 - val_loss: 0.1671 - val_accuracy: 0.9546\n",
            "Epoch 31/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1651 - accuracy: 0.9547 - val_loss: 0.1662 - val_accuracy: 0.9546\n",
            "Epoch 32/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1627 - accuracy: 0.9547 - val_loss: 0.1676 - val_accuracy: 0.9546\n",
            "Epoch 33/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1629 - accuracy: 0.9547 - val_loss: 0.1699 - val_accuracy: 0.9546\n",
            "Epoch 34/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1653 - accuracy: 0.9547 - val_loss: 0.1653 - val_accuracy: 0.9546\n",
            "Epoch 35/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1635 - accuracy: 0.9547 - val_loss: 0.1648 - val_accuracy: 0.9546\n",
            "Epoch 36/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1615 - accuracy: 0.9547 - val_loss: 0.1657 - val_accuracy: 0.9546\n",
            "Epoch 37/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1619 - accuracy: 0.9547 - val_loss: 0.1678 - val_accuracy: 0.9546\n",
            "Epoch 38/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1630 - accuracy: 0.9547 - val_loss: 0.1639 - val_accuracy: 0.9546\n",
            "Epoch 39/100\n",
            "334/334 [==============================] - 1s 2ms/step - loss: 0.1634 - accuracy: 0.9547 - val_loss: 0.1629 - val_accuracy: 0.9546\n",
            "Epoch 40/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1610 - accuracy: 0.9547 - val_loss: 0.1623 - val_accuracy: 0.9546\n",
            "Epoch 41/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1598 - accuracy: 0.9547 - val_loss: 0.1654 - val_accuracy: 0.9546\n",
            "Epoch 42/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9547 - val_loss: 0.1666 - val_accuracy: 0.9546\n",
            "Epoch 43/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1620 - accuracy: 0.9547 - val_loss: 0.1620 - val_accuracy: 0.9546\n",
            "Epoch 44/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1614 - accuracy: 0.9547 - val_loss: 0.1681 - val_accuracy: 0.9546\n",
            "Epoch 45/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9547 - val_loss: 0.1714 - val_accuracy: 0.9546\n",
            "Epoch 46/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1608 - accuracy: 0.9547 - val_loss: 0.1614 - val_accuracy: 0.9546\n",
            "Epoch 47/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1605 - accuracy: 0.9547 - val_loss: 0.1607 - val_accuracy: 0.9546\n",
            "Epoch 48/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1600 - accuracy: 0.9547 - val_loss: 0.1656 - val_accuracy: 0.9546\n",
            "Epoch 49/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1594 - accuracy: 0.9557 - val_loss: 0.1622 - val_accuracy: 0.9557\n",
            "Epoch 50/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9555 - val_loss: 0.1608 - val_accuracy: 0.9557\n",
            "Epoch 51/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1618 - accuracy: 0.9552 - val_loss: 0.1622 - val_accuracy: 0.9568\n",
            "Epoch 52/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9551 - val_loss: 0.1651 - val_accuracy: 0.9550\n",
            "Epoch 53/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1596 - accuracy: 0.9565 - val_loss: 0.1619 - val_accuracy: 0.9557\n",
            "Epoch 54/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1597 - accuracy: 0.9557 - val_loss: 0.1649 - val_accuracy: 0.9557\n",
            "Epoch 55/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1595 - accuracy: 0.9564 - val_loss: 0.1607 - val_accuracy: 0.9553\n",
            "Epoch 56/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1607 - accuracy: 0.9568 - val_loss: 0.1615 - val_accuracy: 0.9557\n",
            "Epoch 57/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1600 - accuracy: 0.9559 - val_loss: 0.1597 - val_accuracy: 0.9553\n",
            "Epoch 58/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9567 - val_loss: 0.1617 - val_accuracy: 0.9568\n",
            "Epoch 59/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1565 - accuracy: 0.9557 - val_loss: 0.1635 - val_accuracy: 0.9546\n",
            "Epoch 60/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9555 - val_loss: 0.1630 - val_accuracy: 0.9568\n",
            "Epoch 61/100\n",
            "334/334 [==============================] - 1s 4ms/step - loss: 0.1592 - accuracy: 0.9564 - val_loss: 0.1624 - val_accuracy: 0.9550\n",
            "Epoch 62/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9559 - val_loss: 0.1599 - val_accuracy: 0.9565\n",
            "Epoch 63/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1586 - accuracy: 0.9563 - val_loss: 0.1645 - val_accuracy: 0.9591\n",
            "Epoch 64/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1592 - accuracy: 0.9565 - val_loss: 0.1618 - val_accuracy: 0.9565\n",
            "Epoch 65/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1587 - accuracy: 0.9569 - val_loss: 0.1647 - val_accuracy: 0.9561\n",
            "Epoch 66/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1561 - accuracy: 0.9558 - val_loss: 0.1598 - val_accuracy: 0.9561\n",
            "Epoch 67/100\n",
            "334/334 [==============================] - 1s 3ms/step - loss: 0.1563 - accuracy: 0.9570 - val_loss: 0.1656 - val_accuracy: 0.9523\n",
            "Epoch 67: early stopping\n",
            "84/84 [==============================] - 0s 2ms/step\n",
            "Accuracy: 0.86\n",
            "Confusion matrix:\n",
            "[[2221  323]\n",
            " [  52   69]]\n",
            "\n",
            "Overall accuracy: 0.86 +/- 0.01\n",
            "Overall confusion matrix:\n",
            "[[2227.4  317. ]\n",
            " [  47.    73.8]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3SS6bzGb9WNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Finding the best probablity threshold"
      ],
      "metadata": {
        "id": "cfqbpXmPFGNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.20, random_state=42)\n",
        "\n",
        "# Split the training data into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=42)\n",
        "\n",
        "# Define the neural network architecture with L2 regularization\n",
        "model = Sequential()\n",
        "model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.8)))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model with RMSprop optimizer\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "rmsprop = RMSprop(lr=0.002, rho=0.8)\n",
        "model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "\n",
        "# Train the model with early stopping to prevent overfitting\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
        "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "# Predict the class probabilities on the test set\n",
        "y_prob = model.predict(X_test)\n",
        "\n",
        "# Collect ROC AUC, accuracy, and threshold values\n",
        "aucs = []\n",
        "accuracies = []\n",
        "thresholds = np.arange(0.01, 1, 0.01)\n",
        "for threshold in thresholds:\n",
        "    # Threshold the probabilities to get binary predictions using the current threshold\n",
        "    y_pred = (y_prob > threshold).astype(int)\n",
        "\n",
        "    # Evaluate the model's performance using the current threshold\n",
        "    auc = roc_auc_score(y_test, y_pred)\n",
        "    aucs.append(auc)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    accuracies.append(accuracy)\n",
        "\n",
        "# Draw the ROC AUC and accuracy curves\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(thresholds, aucs, label='ROC AUC')\n",
        "ax.plot(thresholds, accuracies, label='Accuracy')\n",
        "ax.set_xlabel('Threshold')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Threshold vs. Score')\n",
        "ax.legend()\n",
        "plt.show()\n",
        "\n",
        "# Find the threshold that maximizes the ROC AUC and the accuracy\n",
        "max_auc = max(aucs)\n",
        "max_idx = aucs.index(max_auc)\n",
        "best_auc_threshold = thresholds[max_idx]\n",
        "\n",
        "max_acc = max(accuracies)\n",
        "max_idx = accuracies.index(max_acc)\n",
        "best_acc_threshold = thresholds[max_idx]\n",
        "\n",
        "print(\"Best threshold (AUC):\", best_auc_threshold)\n",
        "print(\"Max ROC AUC:\", max_auc)\n",
        "\n",
        "print(\"Best threshold (Accuracy):\", best_acc_threshold)\n",
        "print(\"Max Accuracy:\",max_acc)\n",
        "\n",
        "# Threshold the probabilities to get binary predictions using the best threshold for ROC AUC\n",
        "y_pred_auc = (y_prob > best_auc_threshold).astype(int)\n",
        "\n",
        "# Evaluate the model's performance using the best threshold for ROC AUC\n",
        "accuracy_auc = accuracy_score(y_test, y_pred_auc)\n",
        "print(\"Accuracy (AUC):\", accuracy_auc)\n",
        "\n",
        "cm_auc = confusion_matrix(y_test, y_pred_auc)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm_auc, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix (AUC)')\n",
        "plt.show()\n",
        "\n",
        "# Threshold the probabilities to get binary predictions using the best threshold for accuracy\n",
        "y_pred_acc = (y_prob > best_acc_threshold).astype(int)\n",
        "\n",
        "# Evaluate the model's performance using the best threshold for accuracy\n",
        "accuracy_acc = accuracy_score(y_test, y_pred_acc)\n",
        "print(\"Accuracy (Accuracy):\", accuracy_acc)\n",
        "\n",
        "cm_acc = confusion_matrix(y_test, y_pred_acc)\n",
        "plt.figure(figsize=(4, 4))\n",
        "sns.heatmap(cm_acc, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Confusion Matrix (Accuracy)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sjAvKkNFFMN8",
        "outputId": "af6b4e23-1f66-403b-8391-0f2df21474cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 5s 10ms/step - loss: 2.7022 - accuracy: 0.9312 - val_loss: 0.2143 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 3s 8ms/step - loss: 0.1301 - accuracy: 0.9796 - val_loss: 0.0974 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 2s 6ms/step - loss: 0.0973 - accuracy: 0.9796 - val_loss: 0.0948 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 2s 7ms/step - loss: 0.0963 - accuracy: 0.9796 - val_loss: 0.0941 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9796 - val_loss: 0.0937 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9796 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9796 - val_loss: 0.0956 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9796 - val_loss: 0.0945 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.0948 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9796 - val_loss: 0.0952 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0929 - val_accuracy: 0.9803\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9796 - val_loss: 0.0970 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9796 - val_loss: 0.0957 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9796 - val_loss: 0.0963 - val_accuracy: 0.9803\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.0949 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9796 - val_loss: 0.0950 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.0950 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9796 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 0.0956 - val_accuracy: 0.9803\n",
            "Epoch 21: early stopping\n",
            "104/104 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best threshold (AUC): 0.02\n",
            "Max ROC AUC: 0.7534038054968288\n",
            "Best threshold (Accuracy): 0.38\n",
            "Max Accuracy: 0.9772864930345245\n",
            "Accuracy (AUC): 0.7783161720169595\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Accuracy): 0.9772864930345245\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "So_xk4GiF2Kk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make prediction for current situation base on 2022Q4 data"
      ],
      "metadata": {
        "id": "j6ZiSamFO7il"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t2022 = pd.read_csv(\"2022q4t_file.csv\")\n",
        "t2022 = t2022.set_index(\"NAME\")\n",
        "t2022 = t2022[cols_less_one]\n",
        "t2022 = t2022.dropna()"
      ],
      "metadata": {
        "id": "7GyphJ6aVrbn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Store the index of the t2020 DataFrame\n",
        "t2022_index = t2022.index\n",
        "\n",
        "# Drop the index from the t2020 DataFrame\n",
        "X = t2022.reset_index(drop=True)\n",
        "\n",
        "# Instantiate a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the input features\n",
        "scaler.fit(X)\n",
        "\n",
        "# Transform the input features using the scaler\n",
        "X_standardized = scaler.transform(X)\n",
        "\n",
        "# Create a new DataFrame with the standardized input features\n",
        "t2022_standardized = pd.DataFrame(X_standardized, columns=X.columns)\n",
        "\n",
        "# Set the index of the standardized DataFrame to the original index\n",
        "t2022_standardized.index = t2022_index\n",
        "\n",
        "# Use the standardized DataFrame for further analysis\n",
        "t2022 = t2022_standardized\n"
      ],
      "metadata": {
        "id": "XKK18dLESkCG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the input features and target variable\n",
        "X_new = t2022\n",
        "# Scale the input features using the same StandardScaler as before\n",
        "X_new_scaled = scaler.transform(X_new)\n",
        "\n",
        "# Use the trained model to make predictions on the new data\n",
        "\n",
        "y_new_prob = model.predict(X_new_scaled)\n",
        "y_new_pred = (y_new_prob > 0.03).astype(int)\n",
        "\n",
        "# Find the rows of the new data that are predicted as 1 and convert to a new DataFrame\n",
        "df_predicted_ones = pd.DataFrame(t2022[y_new_pred == 1])\n",
        "\n",
        "# Print out the predicted 1s\n",
        "print('Predicted 1s:')\n",
        "print(df_predicted_ones)\n",
        "\n",
        "# Find the rows of the new data that are predicted as 1\n",
        "predicted_ones = t2022.loc[y_new_pred.flatten() == 1]\n",
        "\n",
        "# Print out the rows of t2020 that are predicted as 1\n",
        "print(predicted_ones.index.to_frame(index=False))\n",
        "\n",
        "# Save the predicted 1s names and other columns to a CSV file\n",
        "predicted_ones.reset_index(inplace=True)\n",
        "predicted_ones.to_csv('predicted_ones.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZN9kPq5cLYbY",
        "outputId": "80c0feb3-dec1-4bfd-a8df-0d9fdd379f9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "149/149 [==============================] - 0s 1ms/step\n",
            "Predicted 1s:\n",
            "                              ADDNONII  ADDNONINTEXP      ASSET    EDEPDOM  \\\n",
            "NAME                                                                         \n",
            "FIRST-CITIZENS BANK&TRUST CO   2210319       1467598  109180139   335422.0   \n",
            "REGIONS BANK                   1418000       1193000  154203000   197000.0   \n",
            "TRANSACT BANK NATIONAL ASSN       -165           814      14668       15.0   \n",
            "STATE STREET BANK&TRUST CO     2222000       2209000  298020000   920000.0   \n",
            "BMO HARRIS BANK NA              737982       1568950  176980258   823685.0   \n",
            "...                                ...           ...        ...        ...   \n",
            "CIBC NATIONAL TRUST CO           -2171        -26932     342946        1.0   \n",
            "NORTHERN TRUST CO               300967       1962546  154522864   251582.0   \n",
            "VALLEY NATIONAL BANK            171490        324449   57451653   256400.0   \n",
            "LOCAL BANK                           1           325      31655       18.0   \n",
            "TRUIST BANK                    5662000       4675000  546228000  1146000.0   \n",
            "\n",
            "                                EINTEXP   EOTHNINT   EPREMAGG       ESAL  \\\n",
            "NAME                                                                       \n",
            "FIRST-CITIZENS BANK&TRUST CO   449440.0  1444824.0   268745.0  1559299.0   \n",
            "REGIONS BANK                   231000.0  1142000.0   459000.0  2235000.0   \n",
            "TRANSACT BANK NATIONAL ASSN        15.0      814.0      338.0      859.0   \n",
            "STATE STREET BANK&TRUST CO    1277000.0  1974000.0  1894000.0  4186000.0   \n",
            "BMO HARRIS BANK NA            1518035.0  1561326.0   371509.0  1681141.0   \n",
            "...                                 ...        ...        ...        ...   \n",
            "CIBC NATIONAL TRUST CO              1.0   -28697.0    12116.0    97829.0   \n",
            "NORTHERN TRUST CO              971165.0  1953331.0   348314.0  2581544.0   \n",
            "VALLEY NATIONAL BANK           288644.0   286742.0   167534.0   523276.0   \n",
            "LOCAL BANK                         18.0      325.0      221.0      806.0   \n",
            "TRUIST BANK                   1900000.0  4123000.0  1198000.0  7530000.0   \n",
            "\n",
            "                                IBEFXTR      ILNDOM  ...         SC      SCAF  \\\n",
            "NAME                                                 ...                        \n",
            "FIRST-CITIZENS BANK&TRUST CO  1198202.0   2784406.0  ...   19269898   8991116   \n",
            "REGIONS BANK                  2381000.0   4049000.0  ...   29057000  27912000   \n",
            "TRANSACT BANK NATIONAL ASSN     -1364.0       105.0  ...        629       629   \n",
            "STATE STREET BANK&TRUST CO    2775000.0    838000.0  ...  105007000  40302000   \n",
            "BMO HARRIS BANK NA            1021582.0   4133864.0  ...   44937762  42582518   \n",
            "...                                 ...         ...  ...        ...       ...   \n",
            "CIBC NATIONAL TRUST CO          48626.0         0.0  ...          0         0   \n",
            "NORTHERN TRUST CO             1338536.0   1242754.0  ...   51684196  26699941   \n",
            "VALLEY NATIONAL BANK           604720.0   1793768.0  ...    5122044   1261397   \n",
            "LOCAL BANK                       -487.0       586.0  ...       6487      6487   \n",
            "TRUIST BANK                   6189000.0  13129000.0  ...  130037000  71529000   \n",
            "\n",
            "                              SCPLEDGE      SCRDEBT       SCUS      SCUSO  \\\n",
            "NAME                                                                        \n",
            "FIRST-CITIZENS BANK&TRUST CO   4229615   19267963.0   18435930   16068029   \n",
            "REGIONS BANK                   8810000   28713000.0   21244000   20078000   \n",
            "TRANSACT BANK NATIONAL ASSN          0        629.0        629        629   \n",
            "STATE STREET BANK&TRUST CO    70442000  105002000.0   60726000   41327000   \n",
            "BMO HARRIS BANK NA             3023460   44937762.0   43313984   25958128   \n",
            "...                                ...          ...        ...        ...   \n",
            "CIBC NATIONAL TRUST CO               0          0.0          0          0   \n",
            "NORTHERN TRUST CO             31418618   51700141.0   23750365   20953056   \n",
            "VALLEY NATIONAL BANK           1218109    5090381.0    4172689    3826280   \n",
            "LOCAL BANK                           0       6487.0       6487       5525   \n",
            "TRUIST BANK                   35668000  129242000.0  125681000  115651000   \n",
            "\n",
            "                                    TRN   TRNIPCOC         UC      UCOTHER  \n",
            "NAME                                                                        \n",
            "FIRST-CITIZENS BANK&TRUST CO   12004324    7544167   23772804   11447469.0  \n",
            "REGIONS BANK                   79047000   71590000   65460000   42157000.0  \n",
            "TRANSACT BANK NATIONAL ASSN       11762      11762          0          0.0  \n",
            "STATE STREET BANK&TRUST CO    154670000  154669000   31220000   31176000.0  \n",
            "BMO HARRIS BANK NA             17046004   15005809   87870673   74516692.0  \n",
            "...                                 ...        ...        ...          ...  \n",
            "CIBC NATIONAL TRUST CO              102        102          0          0.0  \n",
            "NORTHERN TRUST CO              22334821   22326644   30960581   29654777.0  \n",
            "VALLEY NATIONAL BANK            2542649    2381313   12616554    7207002.0  \n",
            "LOCAL BANK                         8322       7565       1252        377.0  \n",
            "TRUIST BANK                   248160000  223182000  217441000  154886000.0  \n",
            "\n",
            "[183 rows x 128 columns]\n",
            "                             NAME\n",
            "0    FIRST-CITIZENS BANK&TRUST CO\n",
            "1                    REGIONS BANK\n",
            "2     TRANSACT BANK NATIONAL ASSN\n",
            "3      STATE STREET BANK&TRUST CO\n",
            "4              BMO HARRIS BANK NA\n",
            "..                            ...\n",
            "178        CIBC NATIONAL TRUST CO\n",
            "179             NORTHERN TRUST CO\n",
            "180          VALLEY NATIONAL BANK\n",
            "181                    LOCAL BANK\n",
            "182                   TRUIST BANK\n",
            "\n",
            "[183 rows x 1 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bank_names = ['SILICON VALLEY BANK', 'FIRST REPUBLIC BANK', 'SIGNATURE BANK', 'SILVERGATE BANK']\n",
        "\n",
        "# Test if the DataFrame contains the bank names\n",
        "contains_bank_names = predicted_ones['NAME'].str.contains('|'.join(bank_names), case=False)\n",
        "\n",
        "# Count the occurrences of True\n",
        "count_true = contains_bank_names.sum()\n",
        "\n",
        "print(count_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PuI17tJOGmfb",
        "outputId": "5b90b3aa-2229-4a22-f56b-46b5ee0bfadb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQelOH0oPFhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## reduce the randomness of neural network sellection"
      ],
      "metadata": {
        "id": "hwUXsGgXPGuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Define the input features (i.e., the independent variables)\n",
        "X = new_df[cols_less_one]\n",
        "\n",
        "# Define the target variable (i.e., the dependent variable)\n",
        "y_true = new_df['target']\n",
        "\n",
        "# Convert the target variable to a numpy array\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "# Standardize the input features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Load the new data into a DataFrame\n",
        "t2022 = pd.read_csv(\"2022q4t_file.csv\")\n",
        "t2022 = t2022.set_index(\"NAME\")\n",
        "t2022 = t2022[cols_less_one]\n",
        "t2022 = t2022.dropna()\n",
        "new_data = t2022\n",
        "\n",
        "# Save the index of the new data\n",
        "new_data_index = new_data.index\n",
        "\n",
        "# Define an empty DataFrame to store the predictions\n",
        "predictions_df = pd.DataFrame(columns=['index', 'prediction'])\n",
        "\n",
        "# Set the number of iterations\n",
        "num_iterations = 50\n",
        "\n",
        "# Loop through the specified number of iterations\n",
        "for i in range(num_iterations):\n",
        "    print(f\"Iteration {i+1} of {num_iterations}\")\n",
        "\n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_true, test_size=0.20, random_state=i)\n",
        "\n",
        "    # Split the training data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, random_state=i)\n",
        "\n",
        "    # Define the neural network architecture with L2 regularization\n",
        "    model = Sequential()\n",
        "    model.add(Dense(10, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.8)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model with RMSprop optimizer\n",
        "    rmsprop = RMSprop(lr=0.002, rho=0.8)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=rmsprop, metrics=['accuracy'])\n",
        "\n",
        "    # Train the model with early stopping to prevent overfitting\n",
        "    es = EarlyStopping(monitor='val_loss', mode='min', verbose=0, patience=10)\n",
        "    history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])\n",
        "\n",
        "    # Standardize the new data using the same scaler as before\n",
        "    new_data_scaled = scaler.transform(new_data[cols_less_one])\n",
        "\n",
        "    # Predict the class probabilities on the new data\n",
        "    y_prob = model.predict(new_data_scaled)\n",
        "\n",
        "    # Threshold the probabilities to get binary predictions\n",
        "    threshold = 0.03 # Use the same threshold value as during training\n",
        "    y_pred = (y_prob > threshold).astype(int)\n",
        "\n",
        "    # Store the predictions in the DataFrame\n",
        "    for j in range(len(new_data_index)):\n",
        "      if y_pred[j] == 1:\n",
        "          predictions_df.loc[len(predictions_df)] = [new_data_index[j], y_pred[j]]\n",
        "\n",
        "# Save the predictions to a CSV file\n",
        "predictions_df.to_csv('predictions.csv', index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HREz4BCqHO1t",
        "outputId": "b4e29f8a-39dd-4dea-8e0c-b1eb74fcc762"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 3s 6ms/step - loss: 2.7209 - accuracy: 0.9407 - val_loss: 0.1877 - val_accuracy: 0.9761\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 2s 5ms/step - loss: 0.1138 - accuracy: 0.9802 - val_loss: 0.1136 - val_accuracy: 0.9761\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 2s 5ms/step - loss: 0.0939 - accuracy: 0.9802 - val_loss: 0.1098 - val_accuracy: 0.9758\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 2s 6ms/step - loss: 0.0936 - accuracy: 0.9802 - val_loss: 0.1080 - val_accuracy: 0.9761\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 2s 7ms/step - loss: 0.0936 - accuracy: 0.9802 - val_loss: 0.1096 - val_accuracy: 0.9761\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9802 - val_loss: 0.1090 - val_accuracy: 0.9761\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9802 - val_loss: 0.1082 - val_accuracy: 0.9761\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9802 - val_loss: 0.1114 - val_accuracy: 0.9761\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9802 - val_loss: 0.1073 - val_accuracy: 0.9761\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9802 - val_loss: 0.1125 - val_accuracy: 0.9761\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9802 - val_loss: 0.1140 - val_accuracy: 0.9761\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9761\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9802 - val_loss: 0.1077 - val_accuracy: 0.9761\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9802 - val_loss: 0.1083 - val_accuracy: 0.9761\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9802 - val_loss: 0.1081 - val_accuracy: 0.9761\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9802 - val_loss: 0.1059 - val_accuracy: 0.9761\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9802 - val_loss: 0.1071 - val_accuracy: 0.9761\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9802 - val_loss: 0.1078 - val_accuracy: 0.9761\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9802 - val_loss: 0.1059 - val_accuracy: 0.9761\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9802 - val_loss: 0.1065 - val_accuracy: 0.9761\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9802 - val_loss: 0.1101 - val_accuracy: 0.9761\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9802 - val_loss: 0.1091 - val_accuracy: 0.9761\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9802 - val_loss: 0.1091 - val_accuracy: 0.9761\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9802 - val_loss: 0.1077 - val_accuracy: 0.9761\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9802 - val_loss: 0.1081 - val_accuracy: 0.9761\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9802 - val_loss: 0.1050 - val_accuracy: 0.9761\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9802 - val_loss: 0.1093 - val_accuracy: 0.9761\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9802 - val_loss: 0.1054 - val_accuracy: 0.9761\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9802 - val_loss: 0.1068 - val_accuracy: 0.9761\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9802 - val_loss: 0.1060 - val_accuracy: 0.9761\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9802 - val_loss: 0.1073 - val_accuracy: 0.9761\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9761\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9802 - val_loss: 0.1042 - val_accuracy: 0.9761\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9802 - val_loss: 0.1080 - val_accuracy: 0.9761\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9802 - val_loss: 0.1049 - val_accuracy: 0.9761\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9802 - val_loss: 0.1060 - val_accuracy: 0.9761\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9802 - val_loss: 0.1054 - val_accuracy: 0.9761\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9802 - val_loss: 0.1055 - val_accuracy: 0.9761\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9802 - val_loss: 0.1053 - val_accuracy: 0.9761\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9802 - val_loss: 0.1060 - val_accuracy: 0.9761\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9802 - val_loss: 0.1061 - val_accuracy: 0.9761\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9802 - val_loss: 0.1051 - val_accuracy: 0.9761\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9802 - val_loss: 0.1036 - val_accuracy: 0.9761\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9802 - val_loss: 0.1086 - val_accuracy: 0.9761\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9802 - val_loss: 0.1016 - val_accuracy: 0.9761\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9802 - val_loss: 0.1068 - val_accuracy: 0.9761\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9802 - val_loss: 0.1066 - val_accuracy: 0.9761\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9802 - val_loss: 0.1075 - val_accuracy: 0.9761\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9802 - val_loss: 0.1051 - val_accuracy: 0.9761\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9802 - val_loss: 0.1051 - val_accuracy: 0.9761\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9802 - val_loss: 0.1032 - val_accuracy: 0.9761\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9802 - val_loss: 0.1071 - val_accuracy: 0.9761\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9802 - val_loss: 0.1074 - val_accuracy: 0.9761\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9802 - val_loss: 0.1072 - val_accuracy: 0.9761\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9802 - val_loss: 0.1036 - val_accuracy: 0.9761\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.7376 - accuracy: 0.9375 - val_loss: 0.2667 - val_accuracy: 0.9799\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1578 - accuracy: 0.9804 - val_loss: 0.1029 - val_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9804 - val_loss: 0.0951 - val_accuracy: 0.9799\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9804 - val_loss: 0.0960 - val_accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9804 - val_loss: 0.1026 - val_accuracy: 0.9799\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9804 - val_loss: 0.0957 - val_accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9804 - val_loss: 0.0955 - val_accuracy: 0.9799\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9804 - val_loss: 0.0949 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9804 - val_loss: 0.0948 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9804 - val_loss: 0.0947 - val_accuracy: 0.9799\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9804 - val_loss: 0.0951 - val_accuracy: 0.9799\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9804 - val_loss: 0.0970 - val_accuracy: 0.9799\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9804 - val_loss: 0.0946 - val_accuracy: 0.9799\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9804 - val_loss: 0.0947 - val_accuracy: 0.9799\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9804 - val_loss: 0.0952 - val_accuracy: 0.9799\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9804 - val_loss: 0.0949 - val_accuracy: 0.9799\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9804 - val_loss: 0.0953 - val_accuracy: 0.9799\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9804 - val_loss: 0.0944 - val_accuracy: 0.9799\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9804 - val_loss: 0.0951 - val_accuracy: 0.9799\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9804 - val_loss: 0.1002 - val_accuracy: 0.9799\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9804 - val_loss: 0.0954 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9804 - val_loss: 0.0946 - val_accuracy: 0.9799\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9804 - val_loss: 0.0941 - val_accuracy: 0.9799\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0935 - val_accuracy: 0.9799\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9804 - val_loss: 0.0955 - val_accuracy: 0.9799\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9804 - val_loss: 0.0952 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.0930 - val_accuracy: 0.9799\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0951 - val_accuracy: 0.9799\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9804 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9804 - val_loss: 0.0936 - val_accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9804 - val_loss: 0.0930 - val_accuracy: 0.9799\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9799\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0946 - val_accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9804 - val_loss: 0.0955 - val_accuracy: 0.9799\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9804 - val_loss: 0.1027 - val_accuracy: 0.9799\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9804 - val_loss: 0.1004 - val_accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9804 - val_loss: 0.0927 - val_accuracy: 0.9799\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9804 - val_loss: 0.0925 - val_accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9804 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9804 - val_loss: 0.0936 - val_accuracy: 0.9799\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0938 - val_accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9804 - val_loss: 0.0946 - val_accuracy: 0.9799\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0942 - val_accuracy: 0.9799\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9804 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9804 - val_loss: 0.0929 - val_accuracy: 0.9799\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0888 - accuracy: 0.9804 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9804 - val_loss: 0.0941 - val_accuracy: 0.9799\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9804 - val_loss: 0.0963 - val_accuracy: 0.9799\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 3 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8111 - accuracy: 0.8871 - val_loss: 0.2991 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1765 - accuracy: 0.9789 - val_loss: 0.1088 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9789 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9789 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9789 - val_loss: 0.1013 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9789 - val_loss: 0.1006 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9789 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9789 - val_loss: 0.1044 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9789 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9789 - val_loss: 0.1001 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9789 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9789 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 0.1012 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9789 - val_loss: 0.0998 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9789 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9789 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9789 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9789 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9789 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9789 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9789 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9789 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9789 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9789 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9789 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9789 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9789 - val_loss: 0.1017 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9789 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9789 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9789 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9789 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9789 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9789 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9789 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9789 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0986 - accuracy: 0.9789 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9789 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9789 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9789 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9789 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9789 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9789 - val_loss: 0.0985 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9789 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9789 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9789 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9789 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9789 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9789 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9789 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9789 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9789 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9789 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9789 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9789 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9789 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9789 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9789 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9789 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9789 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9789 - val_loss: 0.0948 - val_accuracy: 0.9784\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9789 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9789 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9789 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0945 - accuracy: 0.9789 - val_loss: 0.0938 - val_accuracy: 0.9784\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9789 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9789 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9789 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9789 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9789 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9789 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9789 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9789 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9789 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9789 - val_loss: 0.0941 - val_accuracy: 0.9784\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9789 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9789 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9789 - val_loss: 0.0904 - val_accuracy: 0.9784\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9789 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9789 - val_loss: 0.0893 - val_accuracy: 0.9784\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9789 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0934 - accuracy: 0.9789 - val_loss: 0.0893 - val_accuracy: 0.9784\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9789 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9789 - val_loss: 0.0909 - val_accuracy: 0.9784\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9789 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9789 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9789 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9789 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
            "Epoch 90/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9789 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
            "Epoch 91/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9789 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 4 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6471 - accuracy: 0.9751 - val_loss: 0.1584 - val_accuracy: 0.9799\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1089 - accuracy: 0.9799 - val_loss: 0.0922 - val_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9799 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9799 - val_loss: 0.0957 - val_accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9799 - val_loss: 0.0914 - val_accuracy: 0.9799\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 0.0944 - val_accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9799\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9799 - val_loss: 0.0908 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9799 - val_loss: 0.0925 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9799 - val_loss: 0.0926 - val_accuracy: 0.9799\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9799 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.0907 - val_accuracy: 0.9799\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9799 - val_loss: 0.0904 - val_accuracy: 0.9799\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9799 - val_loss: 0.0904 - val_accuracy: 0.9799\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.0908 - val_accuracy: 0.9799\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9799\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9799 - val_loss: 0.0906 - val_accuracy: 0.9799\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9799 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9799 - val_loss: 0.0911 - val_accuracy: 0.9799\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9799 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9799 - val_loss: 0.0885 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9799 - val_loss: 0.0886 - val_accuracy: 0.9799\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9799 - val_loss: 0.0904 - val_accuracy: 0.9799\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9799 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.0884 - val_accuracy: 0.9799\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9799 - val_loss: 0.0962 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9799 - val_loss: 0.0877 - val_accuracy: 0.9799\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9799 - val_loss: 0.0881 - val_accuracy: 0.9799\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9799 - val_loss: 0.0918 - val_accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9799 - val_loss: 0.0883 - val_accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9799 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9799 - val_loss: 0.0927 - val_accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9799 - val_loss: 0.0975 - val_accuracy: 0.9799\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9799 - val_loss: 0.0884 - val_accuracy: 0.9799\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9799 - val_loss: 0.0879 - val_accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9799 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 5 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 5ms/step - loss: 2.7450 - accuracy: 0.9382 - val_loss: 0.2090 - val_accuracy: 0.9811\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1272 - accuracy: 0.9806 - val_loss: 0.0905 - val_accuracy: 0.9811\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9806 - val_loss: 0.0887 - val_accuracy: 0.9811\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9806 - val_loss: 0.0893 - val_accuracy: 0.9811\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9806 - val_loss: 0.0884 - val_accuracy: 0.9811\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9806 - val_loss: 0.0883 - val_accuracy: 0.9811\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9806 - val_loss: 0.0918 - val_accuracy: 0.9811\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9806 - val_loss: 0.0914 - val_accuracy: 0.9811\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9806 - val_loss: 0.0897 - val_accuracy: 0.9811\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9806 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9806 - val_loss: 0.0882 - val_accuracy: 0.9811\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9806 - val_loss: 0.0895 - val_accuracy: 0.9811\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9806 - val_loss: 0.0878 - val_accuracy: 0.9811\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9806 - val_loss: 0.0882 - val_accuracy: 0.9811\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9806 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9806 - val_loss: 0.0891 - val_accuracy: 0.9811\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9806 - val_loss: 0.0907 - val_accuracy: 0.9811\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9806 - val_loss: 0.0877 - val_accuracy: 0.9811\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9806 - val_loss: 0.0900 - val_accuracy: 0.9811\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9806 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9806 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9806 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9806 - val_loss: 0.0879 - val_accuracy: 0.9811\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9806 - val_loss: 0.0883 - val_accuracy: 0.9811\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9806 - val_loss: 0.0885 - val_accuracy: 0.9811\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9806 - val_loss: 0.0871 - val_accuracy: 0.9811\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9806 - val_loss: 0.0856 - val_accuracy: 0.9811\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9806 - val_loss: 0.0853 - val_accuracy: 0.9811\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9806 - val_loss: 0.0856 - val_accuracy: 0.9811\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9806 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9806 - val_loss: 0.0862 - val_accuracy: 0.9811\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9806 - val_loss: 0.0853 - val_accuracy: 0.9811\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9806 - val_loss: 0.0849 - val_accuracy: 0.9811\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9806 - val_loss: 0.0860 - val_accuracy: 0.9811\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9806 - val_loss: 0.0963 - val_accuracy: 0.9811\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9806 - val_loss: 0.0858 - val_accuracy: 0.9811\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9806 - val_loss: 0.0870 - val_accuracy: 0.9811\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9806 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9806 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9806 - val_loss: 0.0870 - val_accuracy: 0.9811\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9806 - val_loss: 0.0847 - val_accuracy: 0.9811\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9806 - val_loss: 0.0847 - val_accuracy: 0.9811\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0882 - accuracy: 0.9806 - val_loss: 0.0847 - val_accuracy: 0.9811\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9806 - val_loss: 0.0848 - val_accuracy: 0.9811\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9806 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9806 - val_loss: 0.0841 - val_accuracy: 0.9811\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9806 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0875 - accuracy: 0.9806 - val_loss: 0.0841 - val_accuracy: 0.9811\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0890 - accuracy: 0.9806 - val_loss: 0.0871 - val_accuracy: 0.9811\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9806 - val_loss: 0.0857 - val_accuracy: 0.9811\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9806 - val_loss: 0.0871 - val_accuracy: 0.9811\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9806 - val_loss: 0.0843 - val_accuracy: 0.9811\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9806 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9806 - val_loss: 0.0935 - val_accuracy: 0.9811\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9806 - val_loss: 0.0850 - val_accuracy: 0.9811\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0877 - accuracy: 0.9806 - val_loss: 0.0832 - val_accuracy: 0.9811\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9806 - val_loss: 0.0834 - val_accuracy: 0.9811\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9806 - val_loss: 0.0847 - val_accuracy: 0.9811\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9806 - val_loss: 0.0865 - val_accuracy: 0.9811\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9806 - val_loss: 0.0871 - val_accuracy: 0.9811\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9806 - val_loss: 0.0836 - val_accuracy: 0.9811\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9806 - val_loss: 0.0837 - val_accuracy: 0.9811\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9806 - val_loss: 0.0835 - val_accuracy: 0.9811\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9806 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0888 - accuracy: 0.9806 - val_loss: 0.0875 - val_accuracy: 0.9811\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0878 - accuracy: 0.9806 - val_loss: 0.0835 - val_accuracy: 0.9811\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 6 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7977 - accuracy: 0.9644 - val_loss: 0.2098 - val_accuracy: 0.9788\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1294 - accuracy: 0.9784 - val_loss: 0.0990 - val_accuracy: 0.9788\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9784 - val_loss: 0.0972 - val_accuracy: 0.9788\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9784 - val_loss: 0.0947 - val_accuracy: 0.9788\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0967 - val_accuracy: 0.9788\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0986 - val_accuracy: 0.9788\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0940 - val_accuracy: 0.9788\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9784 - val_loss: 0.0959 - val_accuracy: 0.9788\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9784 - val_loss: 0.0962 - val_accuracy: 0.9788\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9788\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9784 - val_loss: 0.0943 - val_accuracy: 0.9788\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9784 - val_loss: 0.0935 - val_accuracy: 0.9788\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9784 - val_loss: 0.0941 - val_accuracy: 0.9788\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9784 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9784 - val_loss: 0.0924 - val_accuracy: 0.9788\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9784 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9784 - val_loss: 0.0939 - val_accuracy: 0.9788\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9784 - val_loss: 0.0909 - val_accuracy: 0.9788\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9784 - val_loss: 0.0920 - val_accuracy: 0.9788\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9784 - val_loss: 0.0919 - val_accuracy: 0.9788\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9784 - val_loss: 0.0909 - val_accuracy: 0.9788\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9784 - val_loss: 0.0902 - val_accuracy: 0.9788\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9784 - val_loss: 0.0898 - val_accuracy: 0.9788\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9784 - val_loss: 0.0933 - val_accuracy: 0.9788\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9784 - val_loss: 0.0986 - val_accuracy: 0.9788\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9784 - val_loss: 0.0916 - val_accuracy: 0.9788\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9784 - val_loss: 0.0922 - val_accuracy: 0.9788\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9784 - val_loss: 0.0919 - val_accuracy: 0.9788\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.0942 - val_accuracy: 0.9788\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9784 - val_loss: 0.0887 - val_accuracy: 0.9788\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9784 - val_loss: 0.0917 - val_accuracy: 0.9788\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9784 - val_loss: 0.0900 - val_accuracy: 0.9788\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.0922 - val_accuracy: 0.9788\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9784 - val_loss: 0.0968 - val_accuracy: 0.9788\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9784 - val_loss: 0.0877 - val_accuracy: 0.9788\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9784 - val_loss: 0.0896 - val_accuracy: 0.9788\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9784 - val_loss: 0.0895 - val_accuracy: 0.9788\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9784 - val_loss: 0.0885 - val_accuracy: 0.9788\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9784 - val_loss: 0.0886 - val_accuracy: 0.9788\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9784 - val_loss: 0.0885 - val_accuracy: 0.9788\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9784 - val_loss: 0.0880 - val_accuracy: 0.9788\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9784 - val_loss: 0.0883 - val_accuracy: 0.9788\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9784 - val_loss: 0.0882 - val_accuracy: 0.9788\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9784 - val_loss: 0.0885 - val_accuracy: 0.9788\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9784 - val_loss: 0.0901 - val_accuracy: 0.9788\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 7 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.5868 - accuracy: 0.9519 - val_loss: 0.1712 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1097 - accuracy: 0.9801 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9801 - val_loss: 0.1038 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9801 - val_loss: 0.1010 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9801 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9801 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9801 - val_loss: 0.1024 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9801 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9801 - val_loss: 0.1023 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9801 - val_loss: 0.1070 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9801 - val_loss: 0.0999 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9801 - val_loss: 0.1029 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 8 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.7684 - accuracy: 0.9543 - val_loss: 0.2104 - val_accuracy: 0.9769\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1229 - accuracy: 0.9810 - val_loss: 0.1059 - val_accuracy: 0.9769\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9810 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9810 - val_loss: 0.1077 - val_accuracy: 0.9769\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9810 - val_loss: 0.1062 - val_accuracy: 0.9769\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9810 - val_loss: 0.1038 - val_accuracy: 0.9769\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9810 - val_loss: 0.1039 - val_accuracy: 0.9769\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9810 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9810 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9810 - val_loss: 0.1060 - val_accuracy: 0.9769\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9810 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9810 - val_loss: 0.1053 - val_accuracy: 0.9769\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9810 - val_loss: 0.1032 - val_accuracy: 0.9769\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9810 - val_loss: 0.1056 - val_accuracy: 0.9769\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9810 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9810 - val_loss: 0.1046 - val_accuracy: 0.9769\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9810 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9810 - val_loss: 0.1046 - val_accuracy: 0.9769\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9810 - val_loss: 0.1035 - val_accuracy: 0.9769\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9810 - val_loss: 0.1042 - val_accuracy: 0.9769\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1031 - val_accuracy: 0.9769\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0892 - accuracy: 0.9810 - val_loss: 0.1040 - val_accuracy: 0.9769\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9810 - val_loss: 0.1051 - val_accuracy: 0.9769\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0895 - accuracy: 0.9810 - val_loss: 0.1031 - val_accuracy: 0.9769\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.1027 - val_accuracy: 0.9769\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9810 - val_loss: 0.1072 - val_accuracy: 0.9769\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9810 - val_loss: 0.1045 - val_accuracy: 0.9769\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.1021 - val_accuracy: 0.9769\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.1052 - val_accuracy: 0.9769\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.1028 - val_accuracy: 0.9769\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9810 - val_loss: 0.1038 - val_accuracy: 0.9769\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9810 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.1019 - val_accuracy: 0.9769\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.1009 - val_accuracy: 0.9769\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0876 - accuracy: 0.9810 - val_loss: 0.1040 - val_accuracy: 0.9769\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9769\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9769\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9810 - val_loss: 0.1031 - val_accuracy: 0.9769\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.9810 - val_loss: 0.1018 - val_accuracy: 0.9769\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9810 - val_loss: 0.1003 - val_accuracy: 0.9769\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.9810 - val_loss: 0.0997 - val_accuracy: 0.9769\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9810 - val_loss: 0.1025 - val_accuracy: 0.9769\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9810 - val_loss: 0.0993 - val_accuracy: 0.9769\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0873 - accuracy: 0.9810 - val_loss: 0.1037 - val_accuracy: 0.9769\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0872 - accuracy: 0.9810 - val_loss: 0.1002 - val_accuracy: 0.9769\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.1006 - val_accuracy: 0.9769\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9810 - val_loss: 0.1015 - val_accuracy: 0.9769\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0875 - accuracy: 0.9810 - val_loss: 0.0997 - val_accuracy: 0.9769\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.9810 - val_loss: 0.0992 - val_accuracy: 0.9769\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9810 - val_loss: 0.1014 - val_accuracy: 0.9769\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9810 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0867 - accuracy: 0.9810 - val_loss: 0.1022 - val_accuracy: 0.9769\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.1028 - val_accuracy: 0.9769\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0865 - accuracy: 0.9810 - val_loss: 0.1043 - val_accuracy: 0.9769\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0868 - accuracy: 0.9810 - val_loss: 0.0990 - val_accuracy: 0.9769\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.9810 - val_loss: 0.0995 - val_accuracy: 0.9769\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9810 - val_loss: 0.0985 - val_accuracy: 0.9769\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0863 - accuracy: 0.9810 - val_loss: 0.1007 - val_accuracy: 0.9769\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.9810 - val_loss: 0.0991 - val_accuracy: 0.9769\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0859 - accuracy: 0.9810 - val_loss: 0.0987 - val_accuracy: 0.9769\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9810 - val_loss: 0.1030 - val_accuracy: 0.9769\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9810 - val_loss: 0.1028 - val_accuracy: 0.9769\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9810 - val_loss: 0.1026 - val_accuracy: 0.9769\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9810 - val_loss: 0.0984 - val_accuracy: 0.9769\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0864 - accuracy: 0.9810 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0849 - accuracy: 0.9810 - val_loss: 0.0993 - val_accuracy: 0.9769\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0858 - accuracy: 0.9810 - val_loss: 0.0992 - val_accuracy: 0.9769\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.9810 - val_loss: 0.1009 - val_accuracy: 0.9769\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0855 - accuracy: 0.9810 - val_loss: 0.1008 - val_accuracy: 0.9769\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9810 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9810 - val_loss: 0.0984 - val_accuracy: 0.9769\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0833 - accuracy: 0.9810 - val_loss: 0.1005 - val_accuracy: 0.9769\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0861 - accuracy: 0.9810 - val_loss: 0.0974 - val_accuracy: 0.9769\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0843 - accuracy: 0.9810 - val_loss: 0.1006 - val_accuracy: 0.9769\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.9810 - val_loss: 0.0980 - val_accuracy: 0.9769\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0846 - accuracy: 0.9810 - val_loss: 0.0988 - val_accuracy: 0.9769\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0869 - accuracy: 0.9810 - val_loss: 0.0978 - val_accuracy: 0.9769\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0828 - accuracy: 0.9810 - val_loss: 0.0954 - val_accuracy: 0.9769\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 0.1034 - val_accuracy: 0.9769\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0843 - accuracy: 0.9810 - val_loss: 0.0980 - val_accuracy: 0.9769\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0817 - accuracy: 0.9810 - val_loss: 0.1034 - val_accuracy: 0.9769\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9810 - val_loss: 0.0977 - val_accuracy: 0.9769\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0850 - accuracy: 0.9810 - val_loss: 0.0975 - val_accuracy: 0.9769\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0845 - accuracy: 0.9810 - val_loss: 0.1001 - val_accuracy: 0.9769\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.0970 - val_accuracy: 0.9769\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0824 - accuracy: 0.9810 - val_loss: 0.1004 - val_accuracy: 0.9769\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0854 - accuracy: 0.9810 - val_loss: 0.0975 - val_accuracy: 0.9769\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0841 - accuracy: 0.9810 - val_loss: 0.0986 - val_accuracy: 0.9769\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 9 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.8316 - accuracy: 0.8447 - val_loss: 0.2666 - val_accuracy: 0.9818\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1621 - accuracy: 0.9783 - val_loss: 0.0971 - val_accuracy: 0.9818\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9783 - val_loss: 0.0874 - val_accuracy: 0.9818\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9783 - val_loss: 0.0865 - val_accuracy: 0.9818\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9783 - val_loss: 0.0863 - val_accuracy: 0.9818\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9783 - val_loss: 0.0866 - val_accuracy: 0.9818\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9783 - val_loss: 0.0860 - val_accuracy: 0.9818\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9783 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9783 - val_loss: 0.0854 - val_accuracy: 0.9818\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9783 - val_loss: 0.0861 - val_accuracy: 0.9818\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9783 - val_loss: 0.0860 - val_accuracy: 0.9818\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9783 - val_loss: 0.0863 - val_accuracy: 0.9818\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9783 - val_loss: 0.0853 - val_accuracy: 0.9818\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9783 - val_loss: 0.0879 - val_accuracy: 0.9818\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9783 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9783 - val_loss: 0.0847 - val_accuracy: 0.9818\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9783 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9783 - val_loss: 0.0845 - val_accuracy: 0.9818\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9783 - val_loss: 0.0850 - val_accuracy: 0.9818\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9783 - val_loss: 0.0867 - val_accuracy: 0.9818\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9783 - val_loss: 0.0875 - val_accuracy: 0.9818\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9783 - val_loss: 0.0874 - val_accuracy: 0.9818\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9783 - val_loss: 0.0853 - val_accuracy: 0.9818\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9783 - val_loss: 0.0854 - val_accuracy: 0.9818\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9783 - val_loss: 0.0841 - val_accuracy: 0.9818\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9783 - val_loss: 0.0837 - val_accuracy: 0.9818\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.0880 - val_accuracy: 0.9818\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9783 - val_loss: 0.0842 - val_accuracy: 0.9818\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9783 - val_loss: 0.0832 - val_accuracy: 0.9818\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9783 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9783 - val_loss: 0.0840 - val_accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9783 - val_loss: 0.0838 - val_accuracy: 0.9818\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9783 - val_loss: 0.0827 - val_accuracy: 0.9818\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.0837 - val_accuracy: 0.9818\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9783 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9783 - val_loss: 0.0840 - val_accuracy: 0.9818\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.0835 - val_accuracy: 0.9818\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9783 - val_loss: 0.0831 - val_accuracy: 0.9818\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9783 - val_loss: 0.0825 - val_accuracy: 0.9818\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9783 - val_loss: 0.0812 - val_accuracy: 0.9818\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.0819 - val_accuracy: 0.9818\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9783 - val_loss: 0.0838 - val_accuracy: 0.9818\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9783 - val_loss: 0.0814 - val_accuracy: 0.9818\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9783 - val_loss: 0.0847 - val_accuracy: 0.9818\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9783 - val_loss: 0.0837 - val_accuracy: 0.9818\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9783 - val_loss: 0.0815 - val_accuracy: 0.9818\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9783 - val_loss: 0.0830 - val_accuracy: 0.9818\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9783 - val_loss: 0.0834 - val_accuracy: 0.9818\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9783 - val_loss: 0.0815 - val_accuracy: 0.9818\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9783 - val_loss: 0.0816 - val_accuracy: 0.9818\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 10 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7357 - accuracy: 0.9726 - val_loss: 0.1886 - val_accuracy: 0.9777\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1142 - accuracy: 0.9805 - val_loss: 0.1003 - val_accuracy: 0.9777\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9805 - val_loss: 0.1016 - val_accuracy: 0.9777\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9777\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9805 - val_loss: 0.1060 - val_accuracy: 0.9777\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9805 - val_loss: 0.1023 - val_accuracy: 0.9777\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9805 - val_loss: 0.1004 - val_accuracy: 0.9777\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9805 - val_loss: 0.1008 - val_accuracy: 0.9777\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9805 - val_loss: 0.1001 - val_accuracy: 0.9777\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9805 - val_loss: 0.1017 - val_accuracy: 0.9777\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9805 - val_loss: 0.0995 - val_accuracy: 0.9777\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9805 - val_loss: 0.1005 - val_accuracy: 0.9777\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9805 - val_loss: 0.0984 - val_accuracy: 0.9777\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9805 - val_loss: 0.1002 - val_accuracy: 0.9777\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9805 - val_loss: 0.1044 - val_accuracy: 0.9777\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9805 - val_loss: 0.1011 - val_accuracy: 0.9777\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.0973 - val_accuracy: 0.9777\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.1000 - val_accuracy: 0.9777\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9805 - val_loss: 0.0970 - val_accuracy: 0.9777\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9805 - val_loss: 0.0980 - val_accuracy: 0.9777\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9805 - val_loss: 0.0972 - val_accuracy: 0.9777\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0989 - val_accuracy: 0.9777\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.0983 - val_accuracy: 0.9777\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9805 - val_loss: 0.1063 - val_accuracy: 0.9777\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9805 - val_loss: 0.1023 - val_accuracy: 0.9777\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0971 - val_accuracy: 0.9777\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9805 - val_loss: 0.0967 - val_accuracy: 0.9777\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.0967 - val_accuracy: 0.9777\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9805 - val_loss: 0.0964 - val_accuracy: 0.9777\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9805 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9805 - val_loss: 0.0989 - val_accuracy: 0.9777\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9805 - val_loss: 0.0970 - val_accuracy: 0.9777\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0958 - val_accuracy: 0.9777\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9805 - val_loss: 0.0957 - val_accuracy: 0.9777\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0999 - val_accuracy: 0.9777\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9805 - val_loss: 0.0962 - val_accuracy: 0.9777\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.0961 - val_accuracy: 0.9777\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9805 - val_loss: 0.0930 - val_accuracy: 0.9777\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9805 - val_loss: 0.0947 - val_accuracy: 0.9777\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0952 - val_accuracy: 0.9777\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9805 - val_loss: 0.0971 - val_accuracy: 0.9777\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.1037 - val_accuracy: 0.9777\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.0944 - val_accuracy: 0.9777\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.0949 - val_accuracy: 0.9777\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9805 - val_loss: 0.0963 - val_accuracy: 0.9777\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9805 - val_loss: 0.0962 - val_accuracy: 0.9777\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9805 - val_loss: 0.0943 - val_accuracy: 0.9777\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0906 - accuracy: 0.9805 - val_loss: 0.0962 - val_accuracy: 0.9777\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 11 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.7071 - accuracy: 0.9372 - val_loss: 0.2226 - val_accuracy: 0.9796\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9780 - val_loss: 0.0953 - val_accuracy: 0.9796\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9780 - val_loss: 0.0952 - val_accuracy: 0.9796\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.9780 - val_loss: 0.0931 - val_accuracy: 0.9796\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9780 - val_loss: 0.0934 - val_accuracy: 0.9796\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1032 - accuracy: 0.9779 - val_loss: 0.0925 - val_accuracy: 0.9796\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9780 - val_loss: 0.0937 - val_accuracy: 0.9796\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1016 - accuracy: 0.9780 - val_loss: 0.0925 - val_accuracy: 0.9796\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1016 - accuracy: 0.9780 - val_loss: 0.0918 - val_accuracy: 0.9796\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1031 - accuracy: 0.9780 - val_loss: 0.0918 - val_accuracy: 0.9796\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1026 - accuracy: 0.9780 - val_loss: 0.0920 - val_accuracy: 0.9796\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9780 - val_loss: 0.0920 - val_accuracy: 0.9796\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1020 - accuracy: 0.9780 - val_loss: 0.0919 - val_accuracy: 0.9796\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9780 - val_loss: 0.0947 - val_accuracy: 0.9796\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9780 - val_loss: 0.0931 - val_accuracy: 0.9796\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9780 - val_loss: 0.0944 - val_accuracy: 0.9796\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9780 - val_loss: 0.0908 - val_accuracy: 0.9796\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9780 - val_loss: 0.0906 - val_accuracy: 0.9796\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9780 - val_loss: 0.0945 - val_accuracy: 0.9796\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9780 - val_loss: 0.0949 - val_accuracy: 0.9796\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9780 - val_loss: 0.0906 - val_accuracy: 0.9796\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9780 - val_loss: 0.0908 - val_accuracy: 0.9796\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9780 - val_loss: 0.0927 - val_accuracy: 0.9796\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9780 - val_loss: 0.0908 - val_accuracy: 0.9796\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9780 - val_loss: 0.0897 - val_accuracy: 0.9796\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9780 - val_loss: 0.0900 - val_accuracy: 0.9796\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9780 - val_loss: 0.0909 - val_accuracy: 0.9796\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9780 - val_loss: 0.0896 - val_accuracy: 0.9796\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0997 - accuracy: 0.9780 - val_loss: 0.0889 - val_accuracy: 0.9796\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9780 - val_loss: 0.0891 - val_accuracy: 0.9796\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9780 - val_loss: 0.0921 - val_accuracy: 0.9796\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9780 - val_loss: 0.0965 - val_accuracy: 0.9796\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9780 - val_loss: 0.0883 - val_accuracy: 0.9796\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9780 - val_loss: 0.0888 - val_accuracy: 0.9796\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9780 - val_loss: 0.0888 - val_accuracy: 0.9796\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9780 - val_loss: 0.0949 - val_accuracy: 0.9796\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9780 - val_loss: 0.0890 - val_accuracy: 0.9796\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9780 - val_loss: 0.0884 - val_accuracy: 0.9796\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9780 - val_loss: 0.0879 - val_accuracy: 0.9796\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9780 - val_loss: 0.0867 - val_accuracy: 0.9796\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9780 - val_loss: 0.0867 - val_accuracy: 0.9796\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9780 - val_loss: 0.0902 - val_accuracy: 0.9796\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9780 - val_loss: 0.0883 - val_accuracy: 0.9796\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9780 - val_loss: 0.0887 - val_accuracy: 0.9796\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9780 - val_loss: 0.0868 - val_accuracy: 0.9796\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9780 - val_loss: 0.0890 - val_accuracy: 0.9796\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9780 - val_loss: 0.0871 - val_accuracy: 0.9796\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9780 - val_loss: 0.0880 - val_accuracy: 0.9796\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9780 - val_loss: 0.0914 - val_accuracy: 0.9796\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9780 - val_loss: 0.0883 - val_accuracy: 0.9796\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 12 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.6694 - accuracy: 0.9481 - val_loss: 0.2822 - val_accuracy: 0.9773\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9805 - val_loss: 0.1109 - val_accuracy: 0.9773\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9805 - val_loss: 0.1037 - val_accuracy: 0.9773\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9805 - val_loss: 0.1051 - val_accuracy: 0.9773\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9805 - val_loss: 0.1033 - val_accuracy: 0.9773\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9805 - val_loss: 0.1022 - val_accuracy: 0.9773\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9805 - val_loss: 0.1029 - val_accuracy: 0.9773\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9805 - val_loss: 0.1029 - val_accuracy: 0.9773\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9805 - val_loss: 0.1060 - val_accuracy: 0.9773\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9805 - val_loss: 0.1028 - val_accuracy: 0.9773\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9805 - val_loss: 0.1033 - val_accuracy: 0.9773\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9805 - val_loss: 0.1025 - val_accuracy: 0.9773\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9805 - val_loss: 0.1068 - val_accuracy: 0.9773\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9805 - val_loss: 0.1039 - val_accuracy: 0.9773\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9805 - val_loss: 0.1024 - val_accuracy: 0.9773\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9805 - val_loss: 0.1029 - val_accuracy: 0.9773\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 13 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7621 - accuracy: 0.9085 - val_loss: 0.3074 - val_accuracy: 0.9796\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9791 - val_loss: 0.1095 - val_accuracy: 0.9796\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9791 - val_loss: 0.0977 - val_accuracy: 0.9796\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9791 - val_loss: 0.0987 - val_accuracy: 0.9796\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9791 - val_loss: 0.0982 - val_accuracy: 0.9796\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9791 - val_loss: 0.0979 - val_accuracy: 0.9796\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9791 - val_loss: 0.0978 - val_accuracy: 0.9796\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9791 - val_loss: 0.0979 - val_accuracy: 0.9796\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9791 - val_loss: 0.0983 - val_accuracy: 0.9796\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9791 - val_loss: 0.0975 - val_accuracy: 0.9796\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9791 - val_loss: 0.0987 - val_accuracy: 0.9796\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9791 - val_loss: 0.0981 - val_accuracy: 0.9796\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9791 - val_loss: 0.0980 - val_accuracy: 0.9796\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9791 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9791 - val_loss: 0.0984 - val_accuracy: 0.9796\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9791 - val_loss: 0.0977 - val_accuracy: 0.9796\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9791 - val_loss: 0.0980 - val_accuracy: 0.9796\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9791 - val_loss: 0.1020 - val_accuracy: 0.9796\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9791 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9791 - val_loss: 0.0980 - val_accuracy: 0.9796\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9791 - val_loss: 0.0970 - val_accuracy: 0.9796\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9791 - val_loss: 0.0971 - val_accuracy: 0.9796\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9791 - val_loss: 0.0994 - val_accuracy: 0.9796\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9791 - val_loss: 0.0972 - val_accuracy: 0.9796\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 14 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6891 - accuracy: 0.8943 - val_loss: 0.2804 - val_accuracy: 0.9777\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1634 - accuracy: 0.9793 - val_loss: 0.1089 - val_accuracy: 0.9777\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9793 - val_loss: 0.1010 - val_accuracy: 0.9777\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9793 - val_loss: 0.1009 - val_accuracy: 0.9777\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9793 - val_loss: 0.1026 - val_accuracy: 0.9777\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9793 - val_loss: 0.1044 - val_accuracy: 0.9777\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9793 - val_loss: 0.1017 - val_accuracy: 0.9777\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0981 - accuracy: 0.9793 - val_loss: 0.1029 - val_accuracy: 0.9777\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9793 - val_loss: 0.1032 - val_accuracy: 0.9777\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9793 - val_loss: 0.1024 - val_accuracy: 0.9777\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.1029 - val_accuracy: 0.9777\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9793 - val_loss: 0.1002 - val_accuracy: 0.9777\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.1020 - val_accuracy: 0.9777\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9793 - val_loss: 0.0996 - val_accuracy: 0.9777\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9793 - val_loss: 0.1012 - val_accuracy: 0.9777\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9793 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9793 - val_loss: 0.1001 - val_accuracy: 0.9777\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.1003 - val_accuracy: 0.9777\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9793 - val_loss: 0.1005 - val_accuracy: 0.9777\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9793 - val_loss: 0.0980 - val_accuracy: 0.9777\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0986 - val_accuracy: 0.9777\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9793 - val_loss: 0.1009 - val_accuracy: 0.9777\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9793 - val_loss: 0.0987 - val_accuracy: 0.9777\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9793 - val_loss: 0.1009 - val_accuracy: 0.9777\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9793 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9793 - val_loss: 0.0974 - val_accuracy: 0.9777\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9793 - val_loss: 0.0985 - val_accuracy: 0.9777\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9793 - val_loss: 0.1011 - val_accuracy: 0.9777\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9793 - val_loss: 0.0964 - val_accuracy: 0.9777\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9793 - val_loss: 0.0983 - val_accuracy: 0.9777\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.0980 - val_accuracy: 0.9777\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9793 - val_loss: 0.0967 - val_accuracy: 0.9777\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9793 - val_loss: 0.0970 - val_accuracy: 0.9777\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.0982 - val_accuracy: 0.9777\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9793 - val_loss: 0.0965 - val_accuracy: 0.9777\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9793 - val_loss: 0.0972 - val_accuracy: 0.9777\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9793 - val_loss: 0.0968 - val_accuracy: 0.9777\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9793 - val_loss: 0.0972 - val_accuracy: 0.9777\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9793 - val_loss: 0.1001 - val_accuracy: 0.9777\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 15 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 3ms/step - loss: 2.5344 - accuracy: 0.9680 - val_loss: 0.1604 - val_accuracy: 0.9780\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1136 - accuracy: 0.9782 - val_loss: 0.1005 - val_accuracy: 0.9780\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9781 - val_loss: 0.1017 - val_accuracy: 0.9780\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9782 - val_loss: 0.0991 - val_accuracy: 0.9780\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9782 - val_loss: 0.0990 - val_accuracy: 0.9780\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1024 - accuracy: 0.9782 - val_loss: 0.0966 - val_accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9782 - val_loss: 0.0966 - val_accuracy: 0.9780\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9782 - val_loss: 0.0965 - val_accuracy: 0.9780\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1014 - accuracy: 0.9782 - val_loss: 0.1005 - val_accuracy: 0.9780\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.1001 - val_accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9782 - val_loss: 0.1020 - val_accuracy: 0.9780\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9782 - val_loss: 0.0998 - val_accuracy: 0.9780\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9782 - val_loss: 0.0980 - val_accuracy: 0.9780\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9782 - val_loss: 0.1002 - val_accuracy: 0.9780\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0986 - val_accuracy: 0.9780\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9782 - val_loss: 0.1011 - val_accuracy: 0.9780\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0945 - val_accuracy: 0.9780\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9782 - val_loss: 0.0981 - val_accuracy: 0.9780\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9782 - val_loss: 0.0942 - val_accuracy: 0.9780\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9782 - val_loss: 0.1024 - val_accuracy: 0.9780\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0968 - val_accuracy: 0.9780\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0977 - val_accuracy: 0.9780\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0938 - val_accuracy: 0.9780\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9782 - val_loss: 0.0962 - val_accuracy: 0.9780\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0943 - val_accuracy: 0.9780\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9782 - val_loss: 0.0975 - val_accuracy: 0.9780\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.0959 - val_accuracy: 0.9780\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9782 - val_loss: 0.0930 - val_accuracy: 0.9780\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.0982 - val_accuracy: 0.9780\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9782 - val_loss: 0.0952 - val_accuracy: 0.9780\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9782 - val_loss: 0.0985 - val_accuracy: 0.9780\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0931 - val_accuracy: 0.9780\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.0926 - val_accuracy: 0.9780\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9782 - val_loss: 0.0927 - val_accuracy: 0.9780\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0953 - val_accuracy: 0.9780\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9782 - val_loss: 0.0932 - val_accuracy: 0.9780\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0939 - val_accuracy: 0.9780\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9782 - val_loss: 0.1003 - val_accuracy: 0.9780\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0996 - val_accuracy: 0.9780\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9782 - val_loss: 0.0917 - val_accuracy: 0.9780\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9782 - val_loss: 0.0917 - val_accuracy: 0.9780\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9782 - val_loss: 0.0929 - val_accuracy: 0.9780\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.0944 - val_accuracy: 0.9780\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9782 - val_loss: 0.0905 - val_accuracy: 0.9780\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9782 - val_loss: 0.0954 - val_accuracy: 0.9780\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0926 - val_accuracy: 0.9780\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.0923 - val_accuracy: 0.9780\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.0960 - val_accuracy: 0.9780\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9782 - val_loss: 0.0915 - val_accuracy: 0.9780\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9782 - val_loss: 0.0948 - val_accuracy: 0.9780\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9782 - val_loss: 0.0929 - val_accuracy: 0.9780\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9782 - val_loss: 0.0972 - val_accuracy: 0.9780\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0937 - val_accuracy: 0.9780\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9782 - val_loss: 0.0971 - val_accuracy: 0.9780\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 16 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.7161 - accuracy: 0.9264 - val_loss: 0.2246 - val_accuracy: 0.9807\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1409 - accuracy: 0.9782 - val_loss: 0.0926 - val_accuracy: 0.9807\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9782 - val_loss: 0.0951 - val_accuracy: 0.9807\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9782 - val_loss: 0.0889 - val_accuracy: 0.9807\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9782 - val_loss: 0.0890 - val_accuracy: 0.9807\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0884 - val_accuracy: 0.9807\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9782 - val_loss: 0.0920 - val_accuracy: 0.9807\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0908 - val_accuracy: 0.9807\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0895 - val_accuracy: 0.9807\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.0885 - val_accuracy: 0.9807\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9782 - val_loss: 0.0903 - val_accuracy: 0.9807\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9782 - val_loss: 0.0888 - val_accuracy: 0.9807\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9782 - val_loss: 0.0886 - val_accuracy: 0.9807\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9782 - val_loss: 0.0887 - val_accuracy: 0.9807\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0880 - val_accuracy: 0.9807\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9782 - val_loss: 0.0902 - val_accuracy: 0.9807\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.0917 - val_accuracy: 0.9807\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0888 - val_accuracy: 0.9807\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9782 - val_loss: 0.0941 - val_accuracy: 0.9807\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.0880 - val_accuracy: 0.9807\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0869 - val_accuracy: 0.9807\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0877 - val_accuracy: 0.9807\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0895 - val_accuracy: 0.9807\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9782 - val_loss: 0.0970 - val_accuracy: 0.9807\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.0891 - val_accuracy: 0.9807\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0874 - val_accuracy: 0.9807\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9782 - val_loss: 0.0893 - val_accuracy: 0.9807\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.0858 - val_accuracy: 0.9807\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0854 - val_accuracy: 0.9807\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9782 - val_loss: 0.0882 - val_accuracy: 0.9807\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9782 - val_loss: 0.0864 - val_accuracy: 0.9807\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0875 - val_accuracy: 0.9807\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9782 - val_loss: 0.0857 - val_accuracy: 0.9807\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9782 - val_loss: 0.0858 - val_accuracy: 0.9807\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0855 - val_accuracy: 0.9807\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9782 - val_loss: 0.0853 - val_accuracy: 0.9807\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9782 - val_loss: 0.0848 - val_accuracy: 0.9807\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9782 - val_loss: 0.0869 - val_accuracy: 0.9807\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9782 - val_loss: 0.0861 - val_accuracy: 0.9807\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.0847 - val_accuracy: 0.9807\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.0863 - val_accuracy: 0.9807\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9782 - val_loss: 0.0861 - val_accuracy: 0.9807\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9782 - val_loss: 0.0849 - val_accuracy: 0.9807\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9782 - val_loss: 0.0851 - val_accuracy: 0.9807\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.0853 - val_accuracy: 0.9807\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9782 - val_loss: 0.0882 - val_accuracy: 0.9807\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9782 - val_loss: 0.0841 - val_accuracy: 0.9807\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9782 - val_loss: 0.0866 - val_accuracy: 0.9807\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9782 - val_loss: 0.0860 - val_accuracy: 0.9807\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9782 - val_loss: 0.0864 - val_accuracy: 0.9807\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9782 - val_loss: 0.0862 - val_accuracy: 0.9807\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9782 - val_loss: 0.0861 - val_accuracy: 0.9807\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9782 - val_loss: 0.0875 - val_accuracy: 0.9807\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9782 - val_loss: 0.0838 - val_accuracy: 0.9807\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9782 - val_loss: 0.0831 - val_accuracy: 0.9807\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9782 - val_loss: 0.0829 - val_accuracy: 0.9807\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9782 - val_loss: 0.0844 - val_accuracy: 0.9807\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9782 - val_loss: 0.0847 - val_accuracy: 0.9807\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9782 - val_loss: 0.0872 - val_accuracy: 0.9807\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9782 - val_loss: 0.0841 - val_accuracy: 0.9807\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.0830 - val_accuracy: 0.9807\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0831 - val_accuracy: 0.9807\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9782 - val_loss: 0.0835 - val_accuracy: 0.9807\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9782 - val_loss: 0.0826 - val_accuracy: 0.9807\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0827 - val_accuracy: 0.9807\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9782 - val_loss: 0.0824 - val_accuracy: 0.9807\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9782 - val_loss: 0.0838 - val_accuracy: 0.9807\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9782 - val_loss: 0.0836 - val_accuracy: 0.9807\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9807\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9782 - val_loss: 0.0825 - val_accuracy: 0.9807\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9782 - val_loss: 0.0817 - val_accuracy: 0.9807\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.0821 - val_accuracy: 0.9807\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9782 - val_loss: 0.0844 - val_accuracy: 0.9807\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9782 - val_loss: 0.0810 - val_accuracy: 0.9807\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9782 - val_loss: 0.0805 - val_accuracy: 0.9807\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9782 - val_loss: 0.0829 - val_accuracy: 0.9807\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9782 - val_loss: 0.0869 - val_accuracy: 0.9807\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9782 - val_loss: 0.0830 - val_accuracy: 0.9807\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.0822 - val_accuracy: 0.9807\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9782 - val_loss: 0.0827 - val_accuracy: 0.9807\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9782 - val_loss: 0.0856 - val_accuracy: 0.9807\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 0.0817 - val_accuracy: 0.9807\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9782 - val_loss: 0.0836 - val_accuracy: 0.9807\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9782 - val_loss: 0.0801 - val_accuracy: 0.9807\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9782 - val_loss: 0.0814 - val_accuracy: 0.9807\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9782 - val_loss: 0.0801 - val_accuracy: 0.9807\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9782 - val_loss: 0.0798 - val_accuracy: 0.9807\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9782 - val_loss: 0.0792 - val_accuracy: 0.9807\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 0.0805 - val_accuracy: 0.9807\n",
            "Epoch 90/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9782 - val_loss: 0.0827 - val_accuracy: 0.9807\n",
            "Epoch 91/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9782 - val_loss: 0.0811 - val_accuracy: 0.9807\n",
            "Epoch 92/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 0.0822 - val_accuracy: 0.9807\n",
            "Epoch 93/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9782 - val_loss: 0.0800 - val_accuracy: 0.9807\n",
            "Epoch 94/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.0793 - val_accuracy: 0.9807\n",
            "Epoch 95/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9782 - val_loss: 0.0805 - val_accuracy: 0.9807\n",
            "Epoch 96/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9782 - val_loss: 0.0816 - val_accuracy: 0.9807\n",
            "Epoch 97/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9782 - val_loss: 0.0791 - val_accuracy: 0.9807\n",
            "Epoch 98/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9782 - val_loss: 0.0834 - val_accuracy: 0.9807\n",
            "Epoch 99/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9782 - val_loss: 0.0787 - val_accuracy: 0.9807\n",
            "Epoch 100/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9782 - val_loss: 0.0802 - val_accuracy: 0.9807\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 17 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.9717 - accuracy: 0.8777 - val_loss: 0.3011 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1848 - accuracy: 0.9798 - val_loss: 0.1154 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9799 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9799 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9799 - val_loss: 0.0970 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9799 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9799 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9799 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9799 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9799 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9799 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9799 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9799 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9799 - val_loss: 0.0949 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9799 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0930 - accuracy: 0.9799 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9799 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9799 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9799 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9799 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9799 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9799 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9799 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9799 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9799 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9799 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9799 - val_loss: 0.0941 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9799 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9799 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0910 - accuracy: 0.9799 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9799 - val_loss: 0.0921 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9799 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9799 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9799 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9799 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9799 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.0912 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9799 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9799 - val_loss: 0.0913 - val_accuracy: 0.9784\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9799 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9799 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9799 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9799 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9799 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9799 - val_loss: 0.0911 - val_accuracy: 0.9784\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9799 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9799 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9799 - val_loss: 0.0940 - val_accuracy: 0.9784\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9799 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9799 - val_loss: 0.0909 - val_accuracy: 0.9784\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9799 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9799 - val_loss: 0.0904 - val_accuracy: 0.9784\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9799 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9799 - val_loss: 0.0931 - val_accuracy: 0.9784\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9799 - val_loss: 0.0901 - val_accuracy: 0.9784\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9799 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9799 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9799 - val_loss: 0.0902 - val_accuracy: 0.9784\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0879 - accuracy: 0.9799 - val_loss: 0.0904 - val_accuracy: 0.9784\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9799 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0889 - accuracy: 0.9799 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0864 - accuracy: 0.9799 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9799 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9799 - val_loss: 0.0901 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 18 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7909 - accuracy: 0.9586 - val_loss: 0.1967 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1189 - accuracy: 0.9804 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9804 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9804 - val_loss: 0.0987 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9804 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9804 - val_loss: 0.1001 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9804 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9804 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9804 - val_loss: 0.1001 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9804 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0980 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9804 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9804 - val_loss: 0.0985 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9804 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9804 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9804 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9804 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9804 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9804 - val_loss: 0.1037 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9804 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9804 - val_loss: 0.0968 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9804 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9804 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9804 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9804 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0900 - accuracy: 0.9804 - val_loss: 0.0949 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0909 - accuracy: 0.9804 - val_loss: 0.0941 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9804 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9804 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0964 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9804 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9804 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9804 - val_loss: 0.0943 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9804 - val_loss: 0.1019 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9804 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9804 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9804 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9804 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9804 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9804 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9804 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9804 - val_loss: 0.0970 - val_accuracy: 0.9784\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9804 - val_loss: 0.0932 - val_accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9804 - val_loss: 0.0910 - val_accuracy: 0.9784\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9804 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9804 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9804 - val_loss: 0.0914 - val_accuracy: 0.9784\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9804 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9804 - val_loss: 0.0906 - val_accuracy: 0.9784\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9804 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9804 - val_loss: 0.0890 - val_accuracy: 0.9784\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9804 - val_loss: 0.0917 - val_accuracy: 0.9784\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0870 - accuracy: 0.9804 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0860 - accuracy: 0.9804 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9804 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0869 - accuracy: 0.9804 - val_loss: 0.0893 - val_accuracy: 0.9784\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9804 - val_loss: 0.0896 - val_accuracy: 0.9784\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9804 - val_loss: 0.0912 - val_accuracy: 0.9784\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9804 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9804 - val_loss: 0.0907 - val_accuracy: 0.9784\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0857 - accuracy: 0.9804 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 19 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 2.8841 - accuracy: 0.8600 - val_loss: 0.3269 - val_accuracy: 0.9780\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1906 - accuracy: 0.9791 - val_loss: 0.1146 - val_accuracy: 0.9780\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1013 - accuracy: 0.9791 - val_loss: 0.1013 - val_accuracy: 0.9780\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0996 - accuracy: 0.9791 - val_loss: 0.1025 - val_accuracy: 0.9780\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9791 - val_loss: 0.1022 - val_accuracy: 0.9780\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9791 - val_loss: 0.1034 - val_accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9791 - val_loss: 0.1009 - val_accuracy: 0.9780\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9791 - val_loss: 0.1081 - val_accuracy: 0.9780\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9791 - val_loss: 0.1016 - val_accuracy: 0.9780\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9791 - val_loss: 0.1022 - val_accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9791 - val_loss: 0.1006 - val_accuracy: 0.9780\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9791 - val_loss: 0.1001 - val_accuracy: 0.9780\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9791 - val_loss: 0.1039 - val_accuracy: 0.9780\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9791 - val_loss: 0.1002 - val_accuracy: 0.9780\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9791 - val_loss: 0.1007 - val_accuracy: 0.9780\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9791 - val_loss: 0.1012 - val_accuracy: 0.9780\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9791 - val_loss: 0.1003 - val_accuracy: 0.9780\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9791 - val_loss: 0.1006 - val_accuracy: 0.9780\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9791 - val_loss: 0.1003 - val_accuracy: 0.9780\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9791 - val_loss: 0.1031 - val_accuracy: 0.9780\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9791 - val_loss: 0.1005 - val_accuracy: 0.9780\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9791 - val_loss: 0.1001 - val_accuracy: 0.9780\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 20 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.8849 - accuracy: 0.8597 - val_loss: 0.2740 - val_accuracy: 0.9769\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1600 - accuracy: 0.9800 - val_loss: 0.1107 - val_accuracy: 0.9769\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9769\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9800 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9800 - val_loss: 0.1045 - val_accuracy: 0.9769\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9769\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9800 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9800 - val_loss: 0.1073 - val_accuracy: 0.9769\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9800 - val_loss: 0.1046 - val_accuracy: 0.9769\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9800 - val_loss: 0.1061 - val_accuracy: 0.9769\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9769\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9800 - val_loss: 0.1047 - val_accuracy: 0.9769\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9800 - val_loss: 0.1049 - val_accuracy: 0.9769\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9800 - val_loss: 0.1048 - val_accuracy: 0.9769\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9800 - val_loss: 0.1055 - val_accuracy: 0.9769\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 21 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7137 - accuracy: 0.9154 - val_loss: 0.2296 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1381 - accuracy: 0.9778 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1035 - accuracy: 0.9778 - val_loss: 0.1009 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9778 - val_loss: 0.1005 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1031 - accuracy: 0.9778 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1034 - accuracy: 0.9778 - val_loss: 0.1041 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1023 - accuracy: 0.9778 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1030 - accuracy: 0.9778 - val_loss: 0.1014 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.9778 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1026 - accuracy: 0.9778 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9778 - val_loss: 0.1014 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9778 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1033 - accuracy: 0.9778 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9778 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1016 - accuracy: 0.9778 - val_loss: 0.0988 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1020 - accuracy: 0.9778 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1018 - accuracy: 0.9778 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9778 - val_loss: 0.0980 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9778 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1021 - accuracy: 0.9778 - val_loss: 0.0985 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9778 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9778 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9778 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1022 - accuracy: 0.9778 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9778 - val_loss: 0.0997 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9778 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9778 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9778 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9778 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9778 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9778 - val_loss: 0.0953 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9778 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9778 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9778 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1019 - accuracy: 0.9778 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9778 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9778 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9778 - val_loss: 0.0952 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9778 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9778 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 22 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.5454 - accuracy: 0.9759 - val_loss: 0.1119 - val_accuracy: 0.9845\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1042 - accuracy: 0.9782 - val_loss: 0.0744 - val_accuracy: 0.9845\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.0747 - val_accuracy: 0.9845\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0764 - val_accuracy: 0.9845\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9782 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9782 - val_loss: 0.0743 - val_accuracy: 0.9845\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0733 - val_accuracy: 0.9845\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0737 - val_accuracy: 0.9845\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0742 - val_accuracy: 0.9845\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0747 - val_accuracy: 0.9845\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9782 - val_loss: 0.0768 - val_accuracy: 0.9845\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9782 - val_loss: 0.0741 - val_accuracy: 0.9845\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9782 - val_loss: 0.0753 - val_accuracy: 0.9845\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0988 - accuracy: 0.9782 - val_loss: 0.0762 - val_accuracy: 0.9845\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9782 - val_loss: 0.0731 - val_accuracy: 0.9845\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9782 - val_loss: 0.0731 - val_accuracy: 0.9845\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9782 - val_loss: 0.0729 - val_accuracy: 0.9845\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9782 - val_loss: 0.0712 - val_accuracy: 0.9845\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9782 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9782 - val_loss: 0.0723 - val_accuracy: 0.9845\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9782 - val_loss: 0.0730 - val_accuracy: 0.9845\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9782 - val_loss: 0.0728 - val_accuracy: 0.9845\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9782 - val_loss: 0.0718 - val_accuracy: 0.9845\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9782 - val_loss: 0.0730 - val_accuracy: 0.9845\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9782 - val_loss: 0.0726 - val_accuracy: 0.9845\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9782 - val_loss: 0.0721 - val_accuracy: 0.9845\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9782 - val_loss: 0.0746 - val_accuracy: 0.9845\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9782 - val_loss: 0.0748 - val_accuracy: 0.9845\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 23 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.6912 - accuracy: 0.9778 - val_loss: 0.1431 - val_accuracy: 0.9743\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1024 - accuracy: 0.9801 - val_loss: 0.1108 - val_accuracy: 0.9743\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9801 - val_loss: 0.1126 - val_accuracy: 0.9743\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.1130 - val_accuracy: 0.9743\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9801 - val_loss: 0.1162 - val_accuracy: 0.9743\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9801 - val_loss: 0.1125 - val_accuracy: 0.9743\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9801 - val_loss: 0.1141 - val_accuracy: 0.9743\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9801 - val_loss: 0.1136 - val_accuracy: 0.9743\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9801 - val_loss: 0.1119 - val_accuracy: 0.9743\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9801 - val_loss: 0.1127 - val_accuracy: 0.9743\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9801 - val_loss: 0.1102 - val_accuracy: 0.9743\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.1158 - val_accuracy: 0.9743\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9801 - val_loss: 0.1120 - val_accuracy: 0.9743\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9801 - val_loss: 0.1127 - val_accuracy: 0.9743\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9801 - val_loss: 0.1103 - val_accuracy: 0.9743\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.1140 - val_accuracy: 0.9743\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9801 - val_loss: 0.1112 - val_accuracy: 0.9743\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9801 - val_loss: 0.1115 - val_accuracy: 0.9743\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9801 - val_loss: 0.1101 - val_accuracy: 0.9743\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.1101 - val_accuracy: 0.9743\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9801 - val_loss: 0.1201 - val_accuracy: 0.9743\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9801 - val_loss: 0.1101 - val_accuracy: 0.9743\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9801 - val_loss: 0.1095 - val_accuracy: 0.9743\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9801 - val_loss: 0.1115 - val_accuracy: 0.9743\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9801 - val_loss: 0.1118 - val_accuracy: 0.9743\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9801 - val_loss: 0.1116 - val_accuracy: 0.9743\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9801 - val_loss: 0.1104 - val_accuracy: 0.9743\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9801 - val_loss: 0.1135 - val_accuracy: 0.9743\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.1077 - val_accuracy: 0.9743\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9801 - val_loss: 0.1101 - val_accuracy: 0.9743\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9801 - val_loss: 0.1125 - val_accuracy: 0.9743\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.1081 - val_accuracy: 0.9743\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9801 - val_loss: 0.1079 - val_accuracy: 0.9743\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9801 - val_loss: 0.1079 - val_accuracy: 0.9743\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9801 - val_loss: 0.1069 - val_accuracy: 0.9743\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.1111 - val_accuracy: 0.9743\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9801 - val_loss: 0.1090 - val_accuracy: 0.9743\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9801 - val_loss: 0.1058 - val_accuracy: 0.9743\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9801 - val_loss: 0.1185 - val_accuracy: 0.9743\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9801 - val_loss: 0.1068 - val_accuracy: 0.9743\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9801 - val_loss: 0.1064 - val_accuracy: 0.9743\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9801 - val_loss: 0.1051 - val_accuracy: 0.9743\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9801 - val_loss: 0.1221 - val_accuracy: 0.9743\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.1072 - val_accuracy: 0.9743\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9801 - val_loss: 0.1076 - val_accuracy: 0.9743\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.1052 - val_accuracy: 0.9743\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9801 - val_loss: 0.1063 - val_accuracy: 0.9743\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9801 - val_loss: 0.1047 - val_accuracy: 0.9743\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9801 - val_loss: 0.1073 - val_accuracy: 0.9743\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9801 - val_loss: 0.1066 - val_accuracy: 0.9743\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9801 - val_loss: 0.1162 - val_accuracy: 0.9743\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9801 - val_loss: 0.1076 - val_accuracy: 0.9743\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0933 - accuracy: 0.9801 - val_loss: 0.1054 - val_accuracy: 0.9743\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0920 - accuracy: 0.9801 - val_loss: 0.1201 - val_accuracy: 0.9743\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9801 - val_loss: 0.1057 - val_accuracy: 0.9743\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9801 - val_loss: 0.1067 - val_accuracy: 0.9743\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.1116 - val_accuracy: 0.9743\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9801 - val_loss: 0.1046 - val_accuracy: 0.9743\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9801 - val_loss: 0.1035 - val_accuracy: 0.9743\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9801 - val_loss: 0.1098 - val_accuracy: 0.9743\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9801 - val_loss: 0.1077 - val_accuracy: 0.9743\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9801 - val_loss: 0.1082 - val_accuracy: 0.9743\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9801 - val_loss: 0.1059 - val_accuracy: 0.9743\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9801 - val_loss: 0.1043 - val_accuracy: 0.9743\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9801 - val_loss: 0.1040 - val_accuracy: 0.9743\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9801 - val_loss: 0.1075 - val_accuracy: 0.9743\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9801 - val_loss: 0.1049 - val_accuracy: 0.9743\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9801 - val_loss: 0.1194 - val_accuracy: 0.9743\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9801 - val_loss: 0.1033 - val_accuracy: 0.9743\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9801 - val_loss: 0.1097 - val_accuracy: 0.9743\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0894 - accuracy: 0.9801 - val_loss: 0.1072 - val_accuracy: 0.9743\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9801 - val_loss: 0.1049 - val_accuracy: 0.9743\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0912 - accuracy: 0.9801 - val_loss: 0.1035 - val_accuracy: 0.9743\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.1106 - val_accuracy: 0.9743\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9801 - val_loss: 0.1016 - val_accuracy: 0.9743\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9801 - val_loss: 0.1120 - val_accuracy: 0.9743\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9801 - val_loss: 0.1077 - val_accuracy: 0.9743\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9801 - val_loss: 0.1069 - val_accuracy: 0.9743\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9801 - val_loss: 0.1062 - val_accuracy: 0.9743\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9801 - val_loss: 0.1107 - val_accuracy: 0.9743\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9801 - val_loss: 0.1033 - val_accuracy: 0.9743\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9801 - val_loss: 0.1050 - val_accuracy: 0.9743\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9801 - val_loss: 0.1062 - val_accuracy: 0.9743\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9801 - val_loss: 0.1078 - val_accuracy: 0.9743\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9801 - val_loss: 0.1024 - val_accuracy: 0.9743\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 24 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.9168 - accuracy: 0.9058 - val_loss: 0.2400 - val_accuracy: 0.9758\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1350 - accuracy: 0.9811 - val_loss: 0.1122 - val_accuracy: 0.9758\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0906 - accuracy: 0.9811 - val_loss: 0.1101 - val_accuracy: 0.9758\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9811 - val_loss: 0.1118 - val_accuracy: 0.9758\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9811 - val_loss: 0.1195 - val_accuracy: 0.9758\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9811 - val_loss: 0.1122 - val_accuracy: 0.9758\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9811 - val_loss: 0.1138 - val_accuracy: 0.9758\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9811 - val_loss: 0.1125 - val_accuracy: 0.9758\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9811 - val_loss: 0.1126 - val_accuracy: 0.9758\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9811 - val_loss: 0.1112 - val_accuracy: 0.9758\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0896 - accuracy: 0.9811 - val_loss: 0.1123 - val_accuracy: 0.9758\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0893 - accuracy: 0.9811 - val_loss: 0.1124 - val_accuracy: 0.9758\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9811 - val_loss: 0.1134 - val_accuracy: 0.9758\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 25 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6336 - accuracy: 0.9368 - val_loss: 0.2325 - val_accuracy: 0.9788\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1415 - accuracy: 0.9786 - val_loss: 0.1010 - val_accuracy: 0.9788\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9786 - val_loss: 0.0979 - val_accuracy: 0.9788\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9786 - val_loss: 0.0989 - val_accuracy: 0.9788\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9786 - val_loss: 0.0986 - val_accuracy: 0.9788\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9786 - val_loss: 0.0974 - val_accuracy: 0.9788\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9785 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9786 - val_loss: 0.0996 - val_accuracy: 0.9788\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9786 - val_loss: 0.0977 - val_accuracy: 0.9788\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9786 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9786 - val_loss: 0.0972 - val_accuracy: 0.9788\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9786 - val_loss: 0.0978 - val_accuracy: 0.9788\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9786 - val_loss: 0.0966 - val_accuracy: 0.9788\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9786 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9786 - val_loss: 0.0972 - val_accuracy: 0.9788\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9786 - val_loss: 0.0979 - val_accuracy: 0.9788\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9786 - val_loss: 0.0956 - val_accuracy: 0.9788\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9786 - val_loss: 0.0961 - val_accuracy: 0.9788\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9786 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9786 - val_loss: 0.0960 - val_accuracy: 0.9788\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9786 - val_loss: 0.0954 - val_accuracy: 0.9788\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9786 - val_loss: 0.0950 - val_accuracy: 0.9788\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9786 - val_loss: 0.0960 - val_accuracy: 0.9788\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9786 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9786 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9786 - val_loss: 0.0960 - val_accuracy: 0.9788\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9786 - val_loss: 0.0954 - val_accuracy: 0.9788\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9786 - val_loss: 0.0964 - val_accuracy: 0.9788\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9786 - val_loss: 0.0948 - val_accuracy: 0.9788\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9785 - val_loss: 0.0949 - val_accuracy: 0.9788\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9786 - val_loss: 0.0970 - val_accuracy: 0.9788\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9786 - val_loss: 0.0969 - val_accuracy: 0.9788\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9786 - val_loss: 0.0942 - val_accuracy: 0.9788\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9786 - val_loss: 0.0950 - val_accuracy: 0.9788\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9786 - val_loss: 0.0947 - val_accuracy: 0.9788\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9786 - val_loss: 0.0948 - val_accuracy: 0.9788\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9786 - val_loss: 0.0937 - val_accuracy: 0.9788\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9786 - val_loss: 0.0940 - val_accuracy: 0.9788\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9786 - val_loss: 0.0949 - val_accuracy: 0.9788\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9786 - val_loss: 0.0959 - val_accuracy: 0.9788\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9786 - val_loss: 0.0942 - val_accuracy: 0.9788\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9786 - val_loss: 0.0936 - val_accuracy: 0.9788\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9786 - val_loss: 0.0937 - val_accuracy: 0.9788\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9786 - val_loss: 0.0929 - val_accuracy: 0.9788\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9786 - val_loss: 0.0958 - val_accuracy: 0.9788\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9786 - val_loss: 0.0947 - val_accuracy: 0.9788\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9786 - val_loss: 0.0948 - val_accuracy: 0.9788\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9786 - val_loss: 0.0933 - val_accuracy: 0.9788\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9786 - val_loss: 0.0931 - val_accuracy: 0.9788\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9786 - val_loss: 0.0938 - val_accuracy: 0.9788\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9786 - val_loss: 0.0989 - val_accuracy: 0.9788\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9786 - val_loss: 0.0947 - val_accuracy: 0.9788\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9786 - val_loss: 0.0965 - val_accuracy: 0.9788\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9786 - val_loss: 0.0944 - val_accuracy: 0.9788\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 26 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.8472 - accuracy: 0.8954 - val_loss: 0.2713 - val_accuracy: 0.9818\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9805 - val_loss: 0.0969 - val_accuracy: 0.9818\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9805 - val_loss: 0.0904 - val_accuracy: 0.9818\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9805 - val_loss: 0.0903 - val_accuracy: 0.9818\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9805 - val_loss: 0.0896 - val_accuracy: 0.9818\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9805 - val_loss: 0.0898 - val_accuracy: 0.9818\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9805 - val_loss: 0.0887 - val_accuracy: 0.9818\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9805 - val_loss: 0.0889 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9805 - val_loss: 0.0896 - val_accuracy: 0.9818\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.0890 - val_accuracy: 0.9818\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9805 - val_loss: 0.0908 - val_accuracy: 0.9818\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9805 - val_loss: 0.0915 - val_accuracy: 0.9818\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9805 - val_loss: 0.0893 - val_accuracy: 0.9818\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9805 - val_loss: 0.0898 - val_accuracy: 0.9818\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9805 - val_loss: 0.0912 - val_accuracy: 0.9818\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.0885 - val_accuracy: 0.9818\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.0883 - val_accuracy: 0.9818\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0913 - accuracy: 0.9805 - val_loss: 0.0907 - val_accuracy: 0.9818\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9805 - val_loss: 0.0893 - val_accuracy: 0.9818\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.0894 - val_accuracy: 0.9818\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9805 - val_loss: 0.0887 - val_accuracy: 0.9818\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9805 - val_loss: 0.0913 - val_accuracy: 0.9818\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.0933 - val_accuracy: 0.9818\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9805 - val_loss: 0.0893 - val_accuracy: 0.9818\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0905 - accuracy: 0.9805 - val_loss: 0.0889 - val_accuracy: 0.9818\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9805 - val_loss: 0.0887 - val_accuracy: 0.9818\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.0881 - val_accuracy: 0.9818\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9805 - val_loss: 0.0895 - val_accuracy: 0.9818\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.0888 - val_accuracy: 0.9818\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9805 - val_loss: 0.0887 - val_accuracy: 0.9818\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9805 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9805 - val_loss: 0.0890 - val_accuracy: 0.9818\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9805 - val_loss: 0.0898 - val_accuracy: 0.9818\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.0871 - val_accuracy: 0.9818\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0891 - accuracy: 0.9805 - val_loss: 0.0890 - val_accuracy: 0.9818\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.0896 - val_accuracy: 0.9818\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0902 - accuracy: 0.9805 - val_loss: 0.0883 - val_accuracy: 0.9818\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9805 - val_loss: 0.0879 - val_accuracy: 0.9818\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9805 - val_loss: 0.0872 - val_accuracy: 0.9818\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9805 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9805 - val_loss: 0.0866 - val_accuracy: 0.9818\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.0874 - val_accuracy: 0.9818\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.9805 - val_loss: 0.0880 - val_accuracy: 0.9818\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0886 - accuracy: 0.9805 - val_loss: 0.0877 - val_accuracy: 0.9818\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9805 - val_loss: 0.0871 - val_accuracy: 0.9818\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9805 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9805 - val_loss: 0.0872 - val_accuracy: 0.9818\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9805 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9805 - val_loss: 0.0874 - val_accuracy: 0.9818\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0889 - accuracy: 0.9805 - val_loss: 0.0872 - val_accuracy: 0.9818\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0878 - accuracy: 0.9805 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0876 - accuracy: 0.9805 - val_loss: 0.0851 - val_accuracy: 0.9818\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0899 - accuracy: 0.9805 - val_loss: 0.0864 - val_accuracy: 0.9818\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0887 - accuracy: 0.9805 - val_loss: 0.0858 - val_accuracy: 0.9818\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0888 - accuracy: 0.9805 - val_loss: 0.0883 - val_accuracy: 0.9818\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0866 - accuracy: 0.9805 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9805 - val_loss: 0.0869 - val_accuracy: 0.9818\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9805 - val_loss: 0.0888 - val_accuracy: 0.9818\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.0867 - val_accuracy: 0.9818\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0880 - accuracy: 0.9805 - val_loss: 0.0863 - val_accuracy: 0.9818\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0887 - accuracy: 0.9805 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0898 - accuracy: 0.9805 - val_loss: 0.0869 - val_accuracy: 0.9818\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 27 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6845 - accuracy: 0.9748 - val_loss: 0.1668 - val_accuracy: 0.9777\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1123 - accuracy: 0.9790 - val_loss: 0.1024 - val_accuracy: 0.9777\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9790 - val_loss: 0.1018 - val_accuracy: 0.9777\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9790 - val_loss: 0.1042 - val_accuracy: 0.9777\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9790 - val_loss: 0.1029 - val_accuracy: 0.9777\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9790 - val_loss: 0.1035 - val_accuracy: 0.9777\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9790 - val_loss: 0.1020 - val_accuracy: 0.9777\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9790 - val_loss: 0.1039 - val_accuracy: 0.9777\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9790 - val_loss: 0.1035 - val_accuracy: 0.9777\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9790 - val_loss: 0.1018 - val_accuracy: 0.9777\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9790 - val_loss: 0.1075 - val_accuracy: 0.9777\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9790 - val_loss: 0.1020 - val_accuracy: 0.9777\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9790 - val_loss: 0.1025 - val_accuracy: 0.9777\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9790 - val_loss: 0.1014 - val_accuracy: 0.9777\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9790 - val_loss: 0.1020 - val_accuracy: 0.9777\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9790 - val_loss: 0.1060 - val_accuracy: 0.9777\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9790 - val_loss: 0.1031 - val_accuracy: 0.9777\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.1014 - val_accuracy: 0.9777\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.1007 - val_accuracy: 0.9777\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9790 - val_loss: 0.1000 - val_accuracy: 0.9777\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9790 - val_loss: 0.1027 - val_accuracy: 0.9777\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9790 - val_loss: 0.1016 - val_accuracy: 0.9777\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9790 - val_loss: 0.1024 - val_accuracy: 0.9777\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9790 - val_loss: 0.1022 - val_accuracy: 0.9777\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9790 - val_loss: 0.1001 - val_accuracy: 0.9777\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9790 - val_loss: 0.1003 - val_accuracy: 0.9777\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9790 - val_loss: 0.0988 - val_accuracy: 0.9777\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.1003 - val_accuracy: 0.9777\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9790 - val_loss: 0.1011 - val_accuracy: 0.9777\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9790 - val_loss: 0.1028 - val_accuracy: 0.9777\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0991 - val_accuracy: 0.9777\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9790 - val_loss: 0.0999 - val_accuracy: 0.9777\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9790 - val_loss: 0.1016 - val_accuracy: 0.9777\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9790 - val_loss: 0.1008 - val_accuracy: 0.9777\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9790 - val_loss: 0.1013 - val_accuracy: 0.9777\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0983 - val_accuracy: 0.9777\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9790 - val_loss: 0.0991 - val_accuracy: 0.9777\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9790 - val_loss: 0.1011 - val_accuracy: 0.9777\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9790 - val_loss: 0.0996 - val_accuracy: 0.9777\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0986 - val_accuracy: 0.9777\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9790 - val_loss: 0.0984 - val_accuracy: 0.9777\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.0982 - val_accuracy: 0.9777\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9790 - val_loss: 0.1001 - val_accuracy: 0.9777\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9790 - val_loss: 0.0987 - val_accuracy: 0.9777\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0984 - val_accuracy: 0.9777\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9790 - val_loss: 0.1002 - val_accuracy: 0.9777\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9790 - val_loss: 0.1007 - val_accuracy: 0.9777\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 0.0976 - val_accuracy: 0.9777\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9790 - val_loss: 0.0977 - val_accuracy: 0.9777\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9790 - val_loss: 0.0980 - val_accuracy: 0.9777\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9790 - val_loss: 0.0985 - val_accuracy: 0.9777\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0985 - val_accuracy: 0.9777\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9790 - val_loss: 0.0982 - val_accuracy: 0.9777\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.0976 - val_accuracy: 0.9777\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0972 - val_accuracy: 0.9777\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9790 - val_loss: 0.1052 - val_accuracy: 0.9777\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9790 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0935 - accuracy: 0.9790 - val_loss: 0.0966 - val_accuracy: 0.9777\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0989 - val_accuracy: 0.9777\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9790 - val_loss: 0.1052 - val_accuracy: 0.9777\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9790 - val_loss: 0.0994 - val_accuracy: 0.9777\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0968 - val_accuracy: 0.9777\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0962 - val_accuracy: 0.9777\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9790 - val_loss: 0.1011 - val_accuracy: 0.9777\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9790 - val_loss: 0.0992 - val_accuracy: 0.9777\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0997 - val_accuracy: 0.9777\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 0.0959 - val_accuracy: 0.9777\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9790 - val_loss: 0.0973 - val_accuracy: 0.9777\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9790 - val_loss: 0.0985 - val_accuracy: 0.9777\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9790 - val_loss: 0.0976 - val_accuracy: 0.9777\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9790 - val_loss: 0.1007 - val_accuracy: 0.9777\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9790 - val_loss: 0.0951 - val_accuracy: 0.9777\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0905 - accuracy: 0.9790 - val_loss: 0.0969 - val_accuracy: 0.9777\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9790 - val_loss: 0.0958 - val_accuracy: 0.9777\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.0988 - val_accuracy: 0.9777\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9790 - val_loss: 0.0976 - val_accuracy: 0.9777\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0948 - val_accuracy: 0.9777\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0959 - val_accuracy: 0.9777\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9790 - val_loss: 0.0950 - val_accuracy: 0.9777\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9790 - val_loss: 0.0939 - val_accuracy: 0.9777\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9790 - val_loss: 0.0945 - val_accuracy: 0.9777\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0947 - val_accuracy: 0.9777\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9790 - val_loss: 0.0927 - val_accuracy: 0.9777\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0945 - val_accuracy: 0.9777\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9790 - val_loss: 0.0985 - val_accuracy: 0.9777\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9790 - val_loss: 0.1028 - val_accuracy: 0.9777\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9790 - val_loss: 0.0919 - val_accuracy: 0.9777\n",
            "Epoch 90/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.0960 - val_accuracy: 0.9777\n",
            "Epoch 91/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0915 - accuracy: 0.9790 - val_loss: 0.0943 - val_accuracy: 0.9777\n",
            "Epoch 92/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0954 - val_accuracy: 0.9777\n",
            "Epoch 93/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0941 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "Epoch 94/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0945 - val_accuracy: 0.9777\n",
            "Epoch 95/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9790 - val_loss: 0.0945 - val_accuracy: 0.9777\n",
            "Epoch 96/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9790 - val_loss: 0.0929 - val_accuracy: 0.9777\n",
            "Epoch 97/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9790 - val_loss: 0.0937 - val_accuracy: 0.9777\n",
            "Epoch 98/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9790 - val_loss: 0.1015 - val_accuracy: 0.9777\n",
            "Epoch 99/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9790 - val_loss: 0.0975 - val_accuracy: 0.9777\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 28 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.9083 - accuracy: 0.8093 - val_loss: 0.3579 - val_accuracy: 0.9788\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.2299 - accuracy: 0.9785 - val_loss: 0.1369 - val_accuracy: 0.9788\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1106 - accuracy: 0.9785 - val_loss: 0.0997 - val_accuracy: 0.9788\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9785 - val_loss: 0.1002 - val_accuracy: 0.9788\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1011 - accuracy: 0.9785 - val_loss: 0.1005 - val_accuracy: 0.9788\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9785 - val_loss: 0.0989 - val_accuracy: 0.9788\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9785 - val_loss: 0.1000 - val_accuracy: 0.9788\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9785 - val_loss: 0.0991 - val_accuracy: 0.9788\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9785 - val_loss: 0.1000 - val_accuracy: 0.9788\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9785 - val_loss: 0.0996 - val_accuracy: 0.9788\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9785 - val_loss: 0.1012 - val_accuracy: 0.9788\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9785 - val_loss: 0.0993 - val_accuracy: 0.9788\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9785 - val_loss: 0.0989 - val_accuracy: 0.9788\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9785 - val_loss: 0.1001 - val_accuracy: 0.9788\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9785 - val_loss: 0.0992 - val_accuracy: 0.9788\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9785 - val_loss: 0.0983 - val_accuracy: 0.9788\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9785 - val_loss: 0.0987 - val_accuracy: 0.9788\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1000 - accuracy: 0.9785 - val_loss: 0.1015 - val_accuracy: 0.9788\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9785 - val_loss: 0.0996 - val_accuracy: 0.9788\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9785 - val_loss: 0.0987 - val_accuracy: 0.9788\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0988 - val_accuracy: 0.9788\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9785 - val_loss: 0.0982 - val_accuracy: 0.9788\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0976 - val_accuracy: 0.9788\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9785 - val_loss: 0.0985 - val_accuracy: 0.9788\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0987 - accuracy: 0.9785 - val_loss: 0.0974 - val_accuracy: 0.9788\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9785 - val_loss: 0.0983 - val_accuracy: 0.9788\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9785 - val_loss: 0.0981 - val_accuracy: 0.9788\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9785 - val_loss: 0.0995 - val_accuracy: 0.9788\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9785 - val_loss: 0.0982 - val_accuracy: 0.9788\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9785 - val_loss: 0.0985 - val_accuracy: 0.9788\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0993 - val_accuracy: 0.9788\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9785 - val_loss: 0.0975 - val_accuracy: 0.9788\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9785 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9785 - val_loss: 0.0983 - val_accuracy: 0.9788\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9785 - val_loss: 0.0975 - val_accuracy: 0.9788\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0966 - val_accuracy: 0.9788\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9785 - val_loss: 0.0993 - val_accuracy: 0.9788\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9785 - val_loss: 0.0972 - val_accuracy: 0.9788\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9785 - val_loss: 0.0983 - val_accuracy: 0.9788\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0974 - val_accuracy: 0.9788\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0973 - val_accuracy: 0.9788\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0970 - val_accuracy: 0.9788\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9785 - val_loss: 0.0968 - val_accuracy: 0.9788\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9785 - val_loss: 0.0966 - val_accuracy: 0.9788\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0971 - val_accuracy: 0.9788\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0974 - val_accuracy: 0.9788\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9785 - val_loss: 0.0989 - val_accuracy: 0.9788\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9785 - val_loss: 0.0961 - val_accuracy: 0.9788\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9785 - val_loss: 0.0958 - val_accuracy: 0.9788\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9788\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9788\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9785 - val_loss: 0.0960 - val_accuracy: 0.9788\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9785 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0968 - val_accuracy: 0.9788\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0952 - val_accuracy: 0.9788\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0951 - val_accuracy: 0.9788\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.0994 - val_accuracy: 0.9788\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9785 - val_loss: 0.0969 - val_accuracy: 0.9788\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 0.0958 - val_accuracy: 0.9788\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9785 - val_loss: 0.0950 - val_accuracy: 0.9788\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9785 - val_loss: 0.0956 - val_accuracy: 0.9788\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9785 - val_loss: 0.0965 - val_accuracy: 0.9788\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9785 - val_loss: 0.0951 - val_accuracy: 0.9788\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9785 - val_loss: 0.0953 - val_accuracy: 0.9788\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9785 - val_loss: 0.0971 - val_accuracy: 0.9788\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9785 - val_loss: 0.0959 - val_accuracy: 0.9788\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9785 - val_loss: 0.0949 - val_accuracy: 0.9788\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9785 - val_loss: 0.0978 - val_accuracy: 0.9788\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0949 - val_accuracy: 0.9788\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9788\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.0986 - val_accuracy: 0.9788\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9785 - val_loss: 0.0961 - val_accuracy: 0.9788\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9785 - val_loss: 0.0962 - val_accuracy: 0.9788\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9785 - val_loss: 0.0965 - val_accuracy: 0.9788\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.0957 - val_accuracy: 0.9788\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9785 - val_loss: 0.0999 - val_accuracy: 0.9788\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0958 - val_accuracy: 0.9788\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 0.0936 - val_accuracy: 0.9788\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9785 - val_loss: 0.0956 - val_accuracy: 0.9788\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9785 - val_loss: 0.0949 - val_accuracy: 0.9788\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9785 - val_loss: 0.0950 - val_accuracy: 0.9788\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9785 - val_loss: 0.0950 - val_accuracy: 0.9788\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9785 - val_loss: 0.0940 - val_accuracy: 0.9788\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0965 - val_accuracy: 0.9788\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9785 - val_loss: 0.1013 - val_accuracy: 0.9788\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0952 - val_accuracy: 0.9788\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0938 - val_accuracy: 0.9788\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9785 - val_loss: 0.0940 - val_accuracy: 0.9788\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 29 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.7532 - accuracy: 0.9583 - val_loss: 0.1613 - val_accuracy: 0.9792\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1134 - accuracy: 0.9787 - val_loss: 0.0948 - val_accuracy: 0.9792\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9787 - val_loss: 0.0942 - val_accuracy: 0.9792\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9787 - val_loss: 0.0914 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9787 - val_loss: 0.0913 - val_accuracy: 0.9792\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9787 - val_loss: 0.0925 - val_accuracy: 0.9792\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9787 - val_loss: 0.0946 - val_accuracy: 0.9792\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9787 - val_loss: 0.0914 - val_accuracy: 0.9792\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9787 - val_loss: 0.0931 - val_accuracy: 0.9792\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9787 - val_loss: 0.0962 - val_accuracy: 0.9792\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9787 - val_loss: 0.0958 - val_accuracy: 0.9792\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9787 - val_loss: 0.0923 - val_accuracy: 0.9792\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9787 - val_loss: 0.0896 - val_accuracy: 0.9792\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9787 - val_loss: 0.0913 - val_accuracy: 0.9792\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9787 - val_loss: 0.0905 - val_accuracy: 0.9792\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9787 - val_loss: 0.0918 - val_accuracy: 0.9792\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9787 - val_loss: 0.0915 - val_accuracy: 0.9792\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9787 - val_loss: 0.0930 - val_accuracy: 0.9792\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9787 - val_loss: 0.0901 - val_accuracy: 0.9792\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.0896 - val_accuracy: 0.9792\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0897 - val_accuracy: 0.9792\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.0895 - val_accuracy: 0.9792\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9787 - val_loss: 0.0882 - val_accuracy: 0.9792\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0892 - val_accuracy: 0.9792\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9787 - val_loss: 0.0890 - val_accuracy: 0.9792\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0918 - val_accuracy: 0.9792\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.0882 - val_accuracy: 0.9792\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9787 - val_loss: 0.0927 - val_accuracy: 0.9792\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9787 - val_loss: 0.0869 - val_accuracy: 0.9792\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9787 - val_loss: 0.0864 - val_accuracy: 0.9792\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0874 - val_accuracy: 0.9792\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0884 - val_accuracy: 0.9792\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9787 - val_loss: 0.0895 - val_accuracy: 0.9792\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9787 - val_loss: 0.0873 - val_accuracy: 0.9792\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 0.0905 - val_accuracy: 0.9792\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9787 - val_loss: 0.0875 - val_accuracy: 0.9792\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9787 - val_loss: 0.0860 - val_accuracy: 0.9792\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9787 - val_loss: 0.0873 - val_accuracy: 0.9792\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0910 - val_accuracy: 0.9792\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9787 - val_loss: 0.0881 - val_accuracy: 0.9792\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0870 - val_accuracy: 0.9792\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9787 - val_loss: 0.0876 - val_accuracy: 0.9792\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9787 - val_loss: 0.0933 - val_accuracy: 0.9792\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9787 - val_loss: 0.0848 - val_accuracy: 0.9792\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0958 - accuracy: 0.9787 - val_loss: 0.0849 - val_accuracy: 0.9792\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9787 - val_loss: 0.0858 - val_accuracy: 0.9792\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9787 - val_loss: 0.0845 - val_accuracy: 0.9792\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9787 - val_loss: 0.0843 - val_accuracy: 0.9792\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9787 - val_loss: 0.0860 - val_accuracy: 0.9792\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9787 - val_loss: 0.0845 - val_accuracy: 0.9792\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9787 - val_loss: 0.0866 - val_accuracy: 0.9792\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9787 - val_loss: 0.0851 - val_accuracy: 0.9792\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9787 - val_loss: 0.0855 - val_accuracy: 0.9792\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9787 - val_loss: 0.0872 - val_accuracy: 0.9792\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.0853 - val_accuracy: 0.9792\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9787 - val_loss: 0.0844 - val_accuracy: 0.9792\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9787 - val_loss: 0.0860 - val_accuracy: 0.9792\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 0.0830 - val_accuracy: 0.9792\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9787 - val_loss: 0.0840 - val_accuracy: 0.9792\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9787 - val_loss: 0.0878 - val_accuracy: 0.9792\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0957 - accuracy: 0.9787 - val_loss: 0.0901 - val_accuracy: 0.9792\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0873 - val_accuracy: 0.9792\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9787 - val_loss: 0.0883 - val_accuracy: 0.9792\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9787 - val_loss: 0.0848 - val_accuracy: 0.9792\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9787 - val_loss: 0.0848 - val_accuracy: 0.9792\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9787 - val_loss: 0.0864 - val_accuracy: 0.9792\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9787 - val_loss: 0.0824 - val_accuracy: 0.9792\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9787 - val_loss: 0.0836 - val_accuracy: 0.9792\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9787 - val_loss: 0.0849 - val_accuracy: 0.9792\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9787 - val_loss: 0.0855 - val_accuracy: 0.9792\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9787 - val_loss: 0.0830 - val_accuracy: 0.9792\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9787 - val_loss: 0.0838 - val_accuracy: 0.9792\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9787 - val_loss: 0.0855 - val_accuracy: 0.9792\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9787 - val_loss: 0.0852 - val_accuracy: 0.9792\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9787 - val_loss: 0.0836 - val_accuracy: 0.9792\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9787 - val_loss: 0.0867 - val_accuracy: 0.9792\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9787 - val_loss: 0.0844 - val_accuracy: 0.9792\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 30 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8838 - accuracy: 0.8628 - val_loss: 0.2878 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9781 - val_loss: 0.1057 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1025 - accuracy: 0.9781 - val_loss: 0.0954 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9781 - val_loss: 0.0946 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9781 - val_loss: 0.0942 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9781 - val_loss: 0.0940 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9781 - val_loss: 0.0961 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9781 - val_loss: 0.0946 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9781 - val_loss: 0.0943 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9781 - val_loss: 0.0957 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0993 - accuracy: 0.9781 - val_loss: 0.0944 - val_accuracy: 0.9803\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9781 - val_loss: 0.0966 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9781 - val_loss: 0.0937 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0999 - accuracy: 0.9781 - val_loss: 0.0939 - val_accuracy: 0.9803\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9781 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9781 - val_loss: 0.0957 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9781 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9781 - val_loss: 0.0941 - val_accuracy: 0.9803\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9781 - val_loss: 0.0946 - val_accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9781 - val_loss: 0.0937 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9781 - val_loss: 0.0935 - val_accuracy: 0.9803\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9781 - val_loss: 0.0937 - val_accuracy: 0.9803\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9781 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9781 - val_loss: 0.0929 - val_accuracy: 0.9803\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9781 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9781 - val_loss: 0.0929 - val_accuracy: 0.9803\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9781 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9781 - val_loss: 0.0922 - val_accuracy: 0.9803\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9781 - val_loss: 0.0926 - val_accuracy: 0.9803\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9781 - val_loss: 0.0927 - val_accuracy: 0.9803\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9781 - val_loss: 0.0940 - val_accuracy: 0.9803\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9781 - val_loss: 0.0926 - val_accuracy: 0.9803\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9781 - val_loss: 0.0945 - val_accuracy: 0.9803\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9781 - val_loss: 0.0922 - val_accuracy: 0.9803\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9781 - val_loss: 0.0924 - val_accuracy: 0.9803\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9781 - val_loss: 0.0923 - val_accuracy: 0.9803\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9781 - val_loss: 0.0936 - val_accuracy: 0.9803\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9781 - val_loss: 0.0922 - val_accuracy: 0.9803\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 31 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6367 - accuracy: 0.9663 - val_loss: 0.1760 - val_accuracy: 0.9807\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1162 - accuracy: 0.9793 - val_loss: 0.0923 - val_accuracy: 0.9807\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0926 - val_accuracy: 0.9807\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9793 - val_loss: 0.0915 - val_accuracy: 0.9807\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9793 - val_loss: 0.0912 - val_accuracy: 0.9807\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9793 - val_loss: 0.0924 - val_accuracy: 0.9807\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.0900 - val_accuracy: 0.9807\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9793 - val_loss: 0.0934 - val_accuracy: 0.9807\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9793 - val_loss: 0.0932 - val_accuracy: 0.9807\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9793 - val_loss: 0.0914 - val_accuracy: 0.9807\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9793 - val_loss: 0.0905 - val_accuracy: 0.9807\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9793 - val_loss: 0.0903 - val_accuracy: 0.9807\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9793 - val_loss: 0.0988 - val_accuracy: 0.9807\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9793 - val_loss: 0.0894 - val_accuracy: 0.9807\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9793 - val_loss: 0.0905 - val_accuracy: 0.9807\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9793 - val_loss: 0.0886 - val_accuracy: 0.9807\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9793 - val_loss: 0.0887 - val_accuracy: 0.9807\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9793 - val_loss: 0.0932 - val_accuracy: 0.9807\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9793 - val_loss: 0.0887 - val_accuracy: 0.9807\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9793 - val_loss: 0.0905 - val_accuracy: 0.9807\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9793 - val_loss: 0.0887 - val_accuracy: 0.9807\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9793 - val_loss: 0.0896 - val_accuracy: 0.9807\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 0.0907 - val_accuracy: 0.9807\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 0.0884 - val_accuracy: 0.9807\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 0.0885 - val_accuracy: 0.9807\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9793 - val_loss: 0.0884 - val_accuracy: 0.9807\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9793 - val_loss: 0.0925 - val_accuracy: 0.9807\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 0.0871 - val_accuracy: 0.9807\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9793 - val_loss: 0.0917 - val_accuracy: 0.9807\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9793 - val_loss: 0.0881 - val_accuracy: 0.9807\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9793 - val_loss: 0.0881 - val_accuracy: 0.9807\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9793 - val_loss: 0.0872 - val_accuracy: 0.9807\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9793 - val_loss: 0.0863 - val_accuracy: 0.9807\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9793 - val_loss: 0.0905 - val_accuracy: 0.9807\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9793 - val_loss: 0.0871 - val_accuracy: 0.9807\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9793 - val_loss: 0.0900 - val_accuracy: 0.9807\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9793 - val_loss: 0.0866 - val_accuracy: 0.9807\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9793 - val_loss: 0.0901 - val_accuracy: 0.9807\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9793 - val_loss: 0.0877 - val_accuracy: 0.9807\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9793 - val_loss: 0.0886 - val_accuracy: 0.9807\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9793 - val_loss: 0.0863 - val_accuracy: 0.9807\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0917 - accuracy: 0.9793 - val_loss: 0.0891 - val_accuracy: 0.9807\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9793 - val_loss: 0.0884 - val_accuracy: 0.9807\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 32 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6882 - accuracy: 0.9386 - val_loss: 0.2131 - val_accuracy: 0.9811\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9796 - val_loss: 0.0923 - val_accuracy: 0.9811\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.0921 - val_accuracy: 0.9811\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.0891 - val_accuracy: 0.9811\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 0.0886 - val_accuracy: 0.9811\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9796 - val_loss: 0.0892 - val_accuracy: 0.9811\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9796 - val_loss: 0.0901 - val_accuracy: 0.9811\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9796 - val_loss: 0.0897 - val_accuracy: 0.9811\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.0897 - val_accuracy: 0.9811\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 0.0882 - val_accuracy: 0.9811\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0935 - val_accuracy: 0.9811\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9796 - val_loss: 0.0874 - val_accuracy: 0.9811\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0874 - val_accuracy: 0.9811\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9796 - val_loss: 0.0873 - val_accuracy: 0.9811\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0893 - val_accuracy: 0.9811\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9796 - val_loss: 0.0883 - val_accuracy: 0.9811\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.0870 - val_accuracy: 0.9811\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9796 - val_loss: 0.0868 - val_accuracy: 0.9811\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9796 - val_loss: 0.0894 - val_accuracy: 0.9811\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9796 - val_loss: 0.0874 - val_accuracy: 0.9811\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9796 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9796 - val_loss: 0.0862 - val_accuracy: 0.9811\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9796 - val_loss: 0.0858 - val_accuracy: 0.9811\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9796 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9796 - val_loss: 0.0854 - val_accuracy: 0.9811\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9796 - val_loss: 0.0868 - val_accuracy: 0.9811\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9796 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9796 - val_loss: 0.0864 - val_accuracy: 0.9811\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9796 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9796 - val_loss: 0.0888 - val_accuracy: 0.9811\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9796 - val_loss: 0.0872 - val_accuracy: 0.9811\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 0.0876 - val_accuracy: 0.9811\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0922 - accuracy: 0.9796 - val_loss: 0.0843 - val_accuracy: 0.9811\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 0.0891 - val_accuracy: 0.9811\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9796 - val_loss: 0.0849 - val_accuracy: 0.9811\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9796 - val_loss: 0.0857 - val_accuracy: 0.9811\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9796 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9796 - val_loss: 0.0851 - val_accuracy: 0.9811\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9796 - val_loss: 0.0867 - val_accuracy: 0.9811\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0900 - accuracy: 0.9796 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9796 - val_loss: 0.0864 - val_accuracy: 0.9811\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9796 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9796 - val_loss: 0.0904 - val_accuracy: 0.9811\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 33 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.7896 - accuracy: 0.9061 - val_loss: 0.2890 - val_accuracy: 0.9792\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1721 - accuracy: 0.9788 - val_loss: 0.1048 - val_accuracy: 0.9792\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9788 - val_loss: 0.0973 - val_accuracy: 0.9792\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9788 - val_loss: 0.0971 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9788 - val_loss: 0.0969 - val_accuracy: 0.9792\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9788 - val_loss: 0.0990 - val_accuracy: 0.9792\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9788 - val_loss: 0.0985 - val_accuracy: 0.9792\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9788 - val_loss: 0.0963 - val_accuracy: 0.9792\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9788 - val_loss: 0.0969 - val_accuracy: 0.9792\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9788 - val_loss: 0.0986 - val_accuracy: 0.9792\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9788 - val_loss: 0.0962 - val_accuracy: 0.9792\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1003 - accuracy: 0.9788 - val_loss: 0.0970 - val_accuracy: 0.9792\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9788 - val_loss: 0.0960 - val_accuracy: 0.9792\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9788 - val_loss: 0.0965 - val_accuracy: 0.9792\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9788 - val_loss: 0.0954 - val_accuracy: 0.9792\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9788 - val_loss: 0.0957 - val_accuracy: 0.9792\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1004 - accuracy: 0.9788 - val_loss: 0.0961 - val_accuracy: 0.9792\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0991 - accuracy: 0.9788 - val_loss: 0.0954 - val_accuracy: 0.9792\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9788 - val_loss: 0.0953 - val_accuracy: 0.9792\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9788 - val_loss: 0.0964 - val_accuracy: 0.9792\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9788 - val_loss: 0.0959 - val_accuracy: 0.9792\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9788 - val_loss: 0.0976 - val_accuracy: 0.9792\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9788 - val_loss: 0.0952 - val_accuracy: 0.9792\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9788 - val_loss: 0.0951 - val_accuracy: 0.9792\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9788 - val_loss: 0.0952 - val_accuracy: 0.9792\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9788 - val_loss: 0.0947 - val_accuracy: 0.9792\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9788 - val_loss: 0.0953 - val_accuracy: 0.9792\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9788 - val_loss: 0.0948 - val_accuracy: 0.9792\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9788 - val_loss: 0.0947 - val_accuracy: 0.9792\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9788 - val_loss: 0.0948 - val_accuracy: 0.9792\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9788 - val_loss: 0.0932 - val_accuracy: 0.9792\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9792\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9788 - val_loss: 0.0936 - val_accuracy: 0.9792\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9788 - val_loss: 0.0957 - val_accuracy: 0.9792\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9788 - val_loss: 0.0936 - val_accuracy: 0.9792\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9788 - val_loss: 0.0940 - val_accuracy: 0.9792\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9788 - val_loss: 0.0936 - val_accuracy: 0.9792\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9788 - val_loss: 0.0939 - val_accuracy: 0.9792\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9788 - val_loss: 0.0937 - val_accuracy: 0.9792\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9788 - val_loss: 0.0925 - val_accuracy: 0.9792\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9792\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9788 - val_loss: 0.0974 - val_accuracy: 0.9792\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9788 - val_loss: 0.0934 - val_accuracy: 0.9792\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9788 - val_loss: 0.0916 - val_accuracy: 0.9792\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0927 - val_accuracy: 0.9792\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9788 - val_loss: 0.0929 - val_accuracy: 0.9792\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9788 - val_loss: 0.0921 - val_accuracy: 0.9792\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.0929 - val_accuracy: 0.9792\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0930 - val_accuracy: 0.9792\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.0915 - val_accuracy: 0.9792\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9788 - val_loss: 0.0916 - val_accuracy: 0.9792\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9788 - val_loss: 0.0916 - val_accuracy: 0.9792\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0933 - val_accuracy: 0.9792\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9788 - val_loss: 0.0938 - val_accuracy: 0.9792\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 0.0927 - val_accuracy: 0.9792\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0958 - val_accuracy: 0.9792\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0919 - val_accuracy: 0.9792\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9788 - val_loss: 0.0923 - val_accuracy: 0.9792\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9788 - val_loss: 0.0937 - val_accuracy: 0.9792\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9788 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 34 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7535 - accuracy: 0.9063 - val_loss: 0.2366 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1410 - accuracy: 0.9788 - val_loss: 0.1014 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1000 - accuracy: 0.9788 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.1004 - accuracy: 0.9788 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9788 - val_loss: 0.0987 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9788 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9788 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9788 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9788 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9788 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9788 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9788 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9788 - val_loss: 0.1016 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9788 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9788 - val_loss: 0.0977 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9788 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9788 - val_loss: 0.0991 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9788 - val_loss: 0.0962 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0984 - accuracy: 0.9788 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9788 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9788 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9788 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9788 - val_loss: 0.0985 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9788 - val_loss: 0.0989 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9788 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9788 - val_loss: 0.0971 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9788 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9788 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9788 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9788 - val_loss: 0.0955 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9788 - val_loss: 0.0949 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9788 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9788 - val_loss: 0.0960 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9788 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9788 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9788 - val_loss: 0.0942 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9788 - val_loss: 0.0924 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9788 - val_loss: 0.0929 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9788 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9788 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9788 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9788 - val_loss: 0.0990 - val_accuracy: 0.9784\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0926 - val_accuracy: 0.9784\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9788 - val_loss: 0.0934 - val_accuracy: 0.9784\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9788 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0927 - val_accuracy: 0.9784\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9788 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9788 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9788 - val_loss: 0.0922 - val_accuracy: 0.9784\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9788 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0921 - val_accuracy: 0.9784\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9788 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9788 - val_loss: 0.0899 - val_accuracy: 0.9784\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9788 - val_loss: 0.0925 - val_accuracy: 0.9784\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9788 - val_loss: 0.0915 - val_accuracy: 0.9784\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0932 - accuracy: 0.9788 - val_loss: 0.0916 - val_accuracy: 0.9784\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9788 - val_loss: 0.0912 - val_accuracy: 0.9784\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0919 - accuracy: 0.9788 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0923 - accuracy: 0.9788 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9788 - val_loss: 0.0903 - val_accuracy: 0.9784\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9788 - val_loss: 0.0900 - val_accuracy: 0.9784\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9788 - val_loss: 0.0908 - val_accuracy: 0.9784\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9788 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 35 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8874 - accuracy: 0.9225 - val_loss: 0.2309 - val_accuracy: 0.9799\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9795 - val_loss: 0.0954 - val_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9795 - val_loss: 0.0932 - val_accuracy: 0.9799\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0913 - val_accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0917 - val_accuracy: 0.9799\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9795 - val_loss: 0.0910 - val_accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9795 - val_loss: 0.0921 - val_accuracy: 0.9799\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9795 - val_loss: 0.0915 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.0947 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9795 - val_loss: 0.0917 - val_accuracy: 0.9799\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.0928 - val_accuracy: 0.9799\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.0903 - val_accuracy: 0.9799\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9795 - val_loss: 0.0932 - val_accuracy: 0.9799\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9795 - val_loss: 0.0921 - val_accuracy: 0.9799\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9795 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.0913 - val_accuracy: 0.9799\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.0919 - val_accuracy: 0.9799\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9795 - val_loss: 0.0897 - val_accuracy: 0.9799\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9795 - val_loss: 0.0888 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9795 - val_loss: 0.0889 - val_accuracy: 0.9799\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9795 - val_loss: 0.0905 - val_accuracy: 0.9799\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0921 - val_accuracy: 0.9799\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9795 - val_loss: 0.0886 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 0.0910 - val_accuracy: 0.9799\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 0.0897 - val_accuracy: 0.9799\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0887 - val_accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.0909 - val_accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9795 - val_loss: 0.0878 - val_accuracy: 0.9799\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.0889 - val_accuracy: 0.9799\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9795 - val_loss: 0.0916 - val_accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9795 - val_loss: 0.0898 - val_accuracy: 0.9799\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9795 - val_loss: 0.0887 - val_accuracy: 0.9799\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.0868 - val_accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9795 - val_loss: 0.0880 - val_accuracy: 0.9799\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9795 - val_loss: 0.0873 - val_accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9795 - val_loss: 0.0880 - val_accuracy: 0.9799\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9795 - val_loss: 0.0936 - val_accuracy: 0.9799\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9795 - val_loss: 0.0889 - val_accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9795 - val_loss: 0.0885 - val_accuracy: 0.9799\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9795 - val_loss: 0.0878 - val_accuracy: 0.9799\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9795 - val_loss: 0.0864 - val_accuracy: 0.9799\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9795 - val_loss: 0.0871 - val_accuracy: 0.9799\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9795 - val_loss: 0.0860 - val_accuracy: 0.9799\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9795 - val_loss: 0.0869 - val_accuracy: 0.9799\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9795 - val_loss: 0.0875 - val_accuracy: 0.9799\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9795 - val_loss: 0.0871 - val_accuracy: 0.9799\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9795 - val_loss: 0.0865 - val_accuracy: 0.9799\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9795 - val_loss: 0.0903 - val_accuracy: 0.9799\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9795 - val_loss: 0.0860 - val_accuracy: 0.9799\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9795 - val_loss: 0.0859 - val_accuracy: 0.9799\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9795 - val_loss: 0.0866 - val_accuracy: 0.9799\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9795 - val_loss: 0.0872 - val_accuracy: 0.9799\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9795 - val_loss: 0.0859 - val_accuracy: 0.9799\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0922 - accuracy: 0.9795 - val_loss: 0.0889 - val_accuracy: 0.9799\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0913 - accuracy: 0.9795 - val_loss: 0.0864 - val_accuracy: 0.9799\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0915 - accuracy: 0.9795 - val_loss: 0.0865 - val_accuracy: 0.9799\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9795 - val_loss: 0.0945 - val_accuracy: 0.9799\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9795 - val_loss: 0.0865 - val_accuracy: 0.9799\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0911 - accuracy: 0.9795 - val_loss: 0.0961 - val_accuracy: 0.9799\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0917 - accuracy: 0.9795 - val_loss: 0.0873 - val_accuracy: 0.9799\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.9795 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0910 - accuracy: 0.9795 - val_loss: 0.0858 - val_accuracy: 0.9799\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9795 - val_loss: 0.0855 - val_accuracy: 0.9799\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9795 - val_loss: 0.0874 - val_accuracy: 0.9799\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9795 - val_loss: 0.0913 - val_accuracy: 0.9799\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0907 - accuracy: 0.9795 - val_loss: 0.0883 - val_accuracy: 0.9799\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0908 - accuracy: 0.9795 - val_loss: 0.0861 - val_accuracy: 0.9799\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0904 - accuracy: 0.9795 - val_loss: 0.0848 - val_accuracy: 0.9799\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9795 - val_loss: 0.0862 - val_accuracy: 0.9799\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9795 - val_loss: 0.0857 - val_accuracy: 0.9799\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0899 - accuracy: 0.9795 - val_loss: 0.0852 - val_accuracy: 0.9799\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0901 - accuracy: 0.9795 - val_loss: 0.0864 - val_accuracy: 0.9799\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0896 - accuracy: 0.9795 - val_loss: 0.0884 - val_accuracy: 0.9799\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0901 - accuracy: 0.9795 - val_loss: 0.0832 - val_accuracy: 0.9799\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0904 - accuracy: 0.9795 - val_loss: 0.0854 - val_accuracy: 0.9799\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0894 - accuracy: 0.9795 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0898 - accuracy: 0.9795 - val_loss: 0.0853 - val_accuracy: 0.9799\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0895 - accuracy: 0.9795 - val_loss: 0.0848 - val_accuracy: 0.9799\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9795 - val_loss: 0.0836 - val_accuracy: 0.9799\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0894 - accuracy: 0.9795 - val_loss: 0.0852 - val_accuracy: 0.9799\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9795 - val_loss: 0.0829 - val_accuracy: 0.9799\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9795 - val_loss: 0.0863 - val_accuracy: 0.9799\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0893 - accuracy: 0.9795 - val_loss: 0.0830 - val_accuracy: 0.9799\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9795 - val_loss: 0.0841 - val_accuracy: 0.9799\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0892 - accuracy: 0.9795 - val_loss: 0.0838 - val_accuracy: 0.9799\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0897 - accuracy: 0.9795 - val_loss: 0.0868 - val_accuracy: 0.9799\n",
            "Epoch 90/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9795 - val_loss: 0.0907 - val_accuracy: 0.9799\n",
            "Epoch 91/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0891 - accuracy: 0.9795 - val_loss: 0.0836 - val_accuracy: 0.9799\n",
            "Epoch 92/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0882 - accuracy: 0.9795 - val_loss: 0.0850 - val_accuracy: 0.9799\n",
            "Epoch 93/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0885 - accuracy: 0.9795 - val_loss: 0.0822 - val_accuracy: 0.9799\n",
            "Epoch 94/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9795 - val_loss: 0.0833 - val_accuracy: 0.9799\n",
            "Epoch 95/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0885 - accuracy: 0.9795 - val_loss: 0.0832 - val_accuracy: 0.9799\n",
            "Epoch 96/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0879 - accuracy: 0.9795 - val_loss: 0.0843 - val_accuracy: 0.9799\n",
            "Epoch 97/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0883 - accuracy: 0.9795 - val_loss: 0.0885 - val_accuracy: 0.9799\n",
            "Epoch 98/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0881 - accuracy: 0.9795 - val_loss: 0.0854 - val_accuracy: 0.9799\n",
            "Epoch 99/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0874 - accuracy: 0.9795 - val_loss: 0.0873 - val_accuracy: 0.9799\n",
            "Epoch 100/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0883 - accuracy: 0.9795 - val_loss: 0.0853 - val_accuracy: 0.9799\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 36 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7288 - accuracy: 0.9364 - val_loss: 0.1747 - val_accuracy: 0.9826\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9782 - val_loss: 0.0902 - val_accuracy: 0.9826\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9782 - val_loss: 0.0864 - val_accuracy: 0.9826\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9826\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9826\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9782 - val_loss: 0.0849 - val_accuracy: 0.9826\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9782 - val_loss: 0.0860 - val_accuracy: 0.9826\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9782 - val_loss: 0.0856 - val_accuracy: 0.9826\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9782 - val_loss: 0.0856 - val_accuracy: 0.9826\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9782 - val_loss: 0.0858 - val_accuracy: 0.9826\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9782 - val_loss: 0.0876 - val_accuracy: 0.9826\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9782 - val_loss: 0.0852 - val_accuracy: 0.9826\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9782 - val_loss: 0.0838 - val_accuracy: 0.9826\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9782 - val_loss: 0.0846 - val_accuracy: 0.9826\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9826\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9782 - val_loss: 0.0843 - val_accuracy: 0.9826\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9782 - val_loss: 0.0895 - val_accuracy: 0.9826\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9782 - val_loss: 0.0957 - val_accuracy: 0.9826\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9782 - val_loss: 0.0850 - val_accuracy: 0.9826\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9782 - val_loss: 0.0878 - val_accuracy: 0.9826\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 0.0852 - val_accuracy: 0.9826\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9782 - val_loss: 0.0861 - val_accuracy: 0.9826\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.0955 - val_accuracy: 0.9826\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 37 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6023 - accuracy: 0.9581 - val_loss: 0.1615 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1128 - accuracy: 0.9790 - val_loss: 0.0899 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9790 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9790 - val_loss: 0.0885 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9790 - val_loss: 0.0908 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9790 - val_loss: 0.0900 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9790 - val_loss: 0.0882 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9790 - val_loss: 0.0912 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9790 - val_loss: 0.0930 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9790 - val_loss: 0.0909 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9790 - val_loss: 0.0891 - val_accuracy: 0.9803\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9790 - val_loss: 0.0913 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.0876 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9790 - val_loss: 0.0867 - val_accuracy: 0.9803\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9790 - val_loss: 0.0869 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9790 - val_loss: 0.0892 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9790 - val_loss: 0.0878 - val_accuracy: 0.9803\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9790 - val_loss: 0.0872 - val_accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9790 - val_loss: 0.0860 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9790 - val_loss: 0.0872 - val_accuracy: 0.9803\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.0870 - val_accuracy: 0.9803\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.0884 - val_accuracy: 0.9803\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9790 - val_loss: 0.0867 - val_accuracy: 0.9803\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9790 - val_loss: 0.0892 - val_accuracy: 0.9803\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9790 - val_loss: 0.0880 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9790 - val_loss: 0.0859 - val_accuracy: 0.9803\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9790 - val_loss: 0.0905 - val_accuracy: 0.9803\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0949 - accuracy: 0.9790 - val_loss: 0.0862 - val_accuracy: 0.9803\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9803\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9790 - val_loss: 0.0879 - val_accuracy: 0.9803\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9803\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0883 - val_accuracy: 0.9803\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0856 - val_accuracy: 0.9803\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9790 - val_loss: 0.0916 - val_accuracy: 0.9803\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9790 - val_loss: 0.0833 - val_accuracy: 0.9803\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9803\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9803\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9790 - val_loss: 0.0884 - val_accuracy: 0.9803\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9790 - val_loss: 0.0893 - val_accuracy: 0.9803\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9790 - val_loss: 0.0848 - val_accuracy: 0.9803\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9790 - val_loss: 0.0874 - val_accuracy: 0.9803\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0959 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9790 - val_loss: 0.0852 - val_accuracy: 0.9803\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9790 - val_loss: 0.0840 - val_accuracy: 0.9803\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9803\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0861 - val_accuracy: 0.9803\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0875 - val_accuracy: 0.9803\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9803\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9790 - val_loss: 0.0867 - val_accuracy: 0.9803\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9803\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9790 - val_loss: 0.0866 - val_accuracy: 0.9803\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9803\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9803\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9803\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9803\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9790 - val_loss: 0.0830 - val_accuracy: 0.9803\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.0818 - val_accuracy: 0.9803\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9790 - val_loss: 0.0829 - val_accuracy: 0.9803\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0936 - accuracy: 0.9790 - val_loss: 0.0828 - val_accuracy: 0.9803\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9790 - val_loss: 0.0885 - val_accuracy: 0.9803\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9803\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9790 - val_loss: 0.0817 - val_accuracy: 0.9803\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9790 - val_loss: 0.0812 - val_accuracy: 0.9803\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0855 - val_accuracy: 0.9803\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9790 - val_loss: 0.0834 - val_accuracy: 0.9803\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0909 - accuracy: 0.9790 - val_loss: 0.0884 - val_accuracy: 0.9803\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9790 - val_loss: 0.0842 - val_accuracy: 0.9803\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9790 - val_loss: 0.0841 - val_accuracy: 0.9803\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0916 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9803\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.0806 - val_accuracy: 0.9803\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0923 - accuracy: 0.9790 - val_loss: 0.0797 - val_accuracy: 0.9803\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9790 - val_loss: 0.0831 - val_accuracy: 0.9803\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9790 - val_loss: 0.0808 - val_accuracy: 0.9803\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9790 - val_loss: 0.0798 - val_accuracy: 0.9803\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0924 - accuracy: 0.9790 - val_loss: 0.0794 - val_accuracy: 0.9803\n",
            "Epoch 80/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9790 - val_loss: 0.0838 - val_accuracy: 0.9803\n",
            "Epoch 81/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9790 - val_loss: 0.0804 - val_accuracy: 0.9803\n",
            "Epoch 82/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9790 - val_loss: 0.0827 - val_accuracy: 0.9803\n",
            "Epoch 83/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9790 - val_loss: 0.0822 - val_accuracy: 0.9803\n",
            "Epoch 84/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0928 - accuracy: 0.9790 - val_loss: 0.0808 - val_accuracy: 0.9803\n",
            "Epoch 85/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9790 - val_loss: 0.0795 - val_accuracy: 0.9803\n",
            "Epoch 86/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0902 - accuracy: 0.9790 - val_loss: 0.0798 - val_accuracy: 0.9803\n",
            "Epoch 87/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.0823 - val_accuracy: 0.9803\n",
            "Epoch 88/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9790 - val_loss: 0.0801 - val_accuracy: 0.9803\n",
            "Epoch 89/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9790 - val_loss: 0.0853 - val_accuracy: 0.9803\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 38 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8636 - accuracy: 0.8960 - val_loss: 0.2994 - val_accuracy: 0.9852\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1797 - accuracy: 0.9787 - val_loss: 0.0895 - val_accuracy: 0.9852\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9787 - val_loss: 0.0759 - val_accuracy: 0.9852\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9787 - val_loss: 0.0753 - val_accuracy: 0.9852\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9787 - val_loss: 0.0752 - val_accuracy: 0.9852\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.1002 - accuracy: 0.9787 - val_loss: 0.0763 - val_accuracy: 0.9852\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9787 - val_loss: 0.0750 - val_accuracy: 0.9852\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9787 - val_loss: 0.0756 - val_accuracy: 0.9852\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9787 - val_loss: 0.0760 - val_accuracy: 0.9852\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9787 - val_loss: 0.0758 - val_accuracy: 0.9852\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9787 - val_loss: 0.0758 - val_accuracy: 0.9852\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9787 - val_loss: 0.0748 - val_accuracy: 0.9852\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9787 - val_loss: 0.0751 - val_accuracy: 0.9852\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9787 - val_loss: 0.0749 - val_accuracy: 0.9852\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9787 - val_loss: 0.0751 - val_accuracy: 0.9852\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0988 - accuracy: 0.9787 - val_loss: 0.0759 - val_accuracy: 0.9852\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9787 - val_loss: 0.0760 - val_accuracy: 0.9852\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9787 - val_loss: 0.0749 - val_accuracy: 0.9852\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9787 - val_loss: 0.0747 - val_accuracy: 0.9852\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0749 - val_accuracy: 0.9852\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0749 - val_accuracy: 0.9852\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0980 - accuracy: 0.9787 - val_loss: 0.0741 - val_accuracy: 0.9852\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9787 - val_loss: 0.0748 - val_accuracy: 0.9852\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9787 - val_loss: 0.0751 - val_accuracy: 0.9852\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0745 - val_accuracy: 0.9852\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0747 - val_accuracy: 0.9852\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9787 - val_loss: 0.0748 - val_accuracy: 0.9852\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9787 - val_loss: 0.0736 - val_accuracy: 0.9852\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0748 - val_accuracy: 0.9852\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9787 - val_loss: 0.0740 - val_accuracy: 0.9852\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9787 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9787 - val_loss: 0.0791 - val_accuracy: 0.9852\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9787 - val_loss: 0.0733 - val_accuracy: 0.9852\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9787 - val_loss: 0.0740 - val_accuracy: 0.9852\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9787 - val_loss: 0.0740 - val_accuracy: 0.9852\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9787 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0968 - accuracy: 0.9787 - val_loss: 0.0731 - val_accuracy: 0.9852\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9787 - val_loss: 0.0743 - val_accuracy: 0.9852\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9787 - val_loss: 0.0734 - val_accuracy: 0.9852\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9787 - val_loss: 0.0731 - val_accuracy: 0.9852\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9787 - val_loss: 0.0734 - val_accuracy: 0.9852\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9787 - val_loss: 0.0727 - val_accuracy: 0.9852\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9787 - val_loss: 0.0732 - val_accuracy: 0.9852\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0753 - val_accuracy: 0.9852\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9787 - val_loss: 0.0744 - val_accuracy: 0.9852\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9787 - val_loss: 0.0739 - val_accuracy: 0.9852\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9787 - val_loss: 0.0745 - val_accuracy: 0.9852\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 0.0728 - val_accuracy: 0.9852\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9787 - val_loss: 0.0751 - val_accuracy: 0.9852\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9787 - val_loss: 0.0728 - val_accuracy: 0.9852\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0721 - val_accuracy: 0.9852\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9787 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0962 - accuracy: 0.9787 - val_loss: 0.0721 - val_accuracy: 0.9852\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9787 - val_loss: 0.0735 - val_accuracy: 0.9852\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0952 - accuracy: 0.9787 - val_loss: 0.0739 - val_accuracy: 0.9852\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9787 - val_loss: 0.0753 - val_accuracy: 0.9852\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9787 - val_loss: 0.0719 - val_accuracy: 0.9852\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0967 - accuracy: 0.9787 - val_loss: 0.0715 - val_accuracy: 0.9852\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9787 - val_loss: 0.0724 - val_accuracy: 0.9852\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9787 - val_loss: 0.0715 - val_accuracy: 0.9852\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9787 - val_loss: 0.0710 - val_accuracy: 0.9852\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9787 - val_loss: 0.0721 - val_accuracy: 0.9852\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9787 - val_loss: 0.0715 - val_accuracy: 0.9852\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9787 - val_loss: 0.0771 - val_accuracy: 0.9852\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9787 - val_loss: 0.0724 - val_accuracy: 0.9852\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 0.0713 - val_accuracy: 0.9852\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9787 - val_loss: 0.0700 - val_accuracy: 0.9852\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0944 - accuracy: 0.9787 - val_loss: 0.0700 - val_accuracy: 0.9852\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9787 - val_loss: 0.0743 - val_accuracy: 0.9852\n",
            "Epoch 71/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0723 - val_accuracy: 0.9852\n",
            "Epoch 72/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9787 - val_loss: 0.0736 - val_accuracy: 0.9852\n",
            "Epoch 73/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9787 - val_loss: 0.0751 - val_accuracy: 0.9852\n",
            "Epoch 74/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9787 - val_loss: 0.0702 - val_accuracy: 0.9852\n",
            "Epoch 75/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9787 - val_loss: 0.0702 - val_accuracy: 0.9852\n",
            "Epoch 76/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9787 - val_loss: 0.0737 - val_accuracy: 0.9852\n",
            "Epoch 77/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9787 - val_loss: 0.0717 - val_accuracy: 0.9852\n",
            "Epoch 78/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9787 - val_loss: 0.0712 - val_accuracy: 0.9852\n",
            "Epoch 79/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9787 - val_loss: 0.0700 - val_accuracy: 0.9852\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 39 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.8572 - accuracy: 0.9199 - val_loss: 0.2084 - val_accuracy: 0.9811\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1330 - accuracy: 0.9784 - val_loss: 0.0927 - val_accuracy: 0.9811\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0897 - val_accuracy: 0.9811\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9784 - val_loss: 0.0900 - val_accuracy: 0.9811\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0873 - val_accuracy: 0.9811\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9784 - val_loss: 0.0903 - val_accuracy: 0.9811\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9784 - val_loss: 0.0872 - val_accuracy: 0.9811\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9784 - val_loss: 0.0906 - val_accuracy: 0.9811\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9784 - val_loss: 0.0880 - val_accuracy: 0.9811\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9784 - val_loss: 0.0866 - val_accuracy: 0.9811\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9784 - val_loss: 0.0869 - val_accuracy: 0.9811\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9784 - val_loss: 0.0860 - val_accuracy: 0.9811\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9784 - val_loss: 0.0878 - val_accuracy: 0.9811\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9784 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9784 - val_loss: 0.0907 - val_accuracy: 0.9811\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9784 - val_loss: 0.0868 - val_accuracy: 0.9811\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9784 - val_loss: 0.0923 - val_accuracy: 0.9811\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0998 - accuracy: 0.9784 - val_loss: 0.0907 - val_accuracy: 0.9811\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9784 - val_loss: 0.0844 - val_accuracy: 0.9811\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9784 - val_loss: 0.0851 - val_accuracy: 0.9811\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0987 - accuracy: 0.9784 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9784 - val_loss: 0.0855 - val_accuracy: 0.9811\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9784 - val_loss: 0.0848 - val_accuracy: 0.9811\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9784 - val_loss: 0.0842 - val_accuracy: 0.9811\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9784 - val_loss: 0.0850 - val_accuracy: 0.9811\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.0844 - val_accuracy: 0.9811\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9784 - val_loss: 0.0838 - val_accuracy: 0.9811\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9784 - val_loss: 0.0829 - val_accuracy: 0.9811\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9784 - val_loss: 0.0852 - val_accuracy: 0.9811\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9784 - val_loss: 0.0870 - val_accuracy: 0.9811\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9784 - val_loss: 0.0830 - val_accuracy: 0.9811\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9784 - val_loss: 0.0872 - val_accuracy: 0.9811\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.0867 - val_accuracy: 0.9811\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9784 - val_loss: 0.0831 - val_accuracy: 0.9811\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0967 - accuracy: 0.9784 - val_loss: 0.0838 - val_accuracy: 0.9811\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9811\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9784 - val_loss: 0.0814 - val_accuracy: 0.9811\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9784 - val_loss: 0.0811 - val_accuracy: 0.9811\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9784 - val_loss: 0.0844 - val_accuracy: 0.9811\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9784 - val_loss: 0.0850 - val_accuracy: 0.9811\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9811\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9784 - val_loss: 0.0814 - val_accuracy: 0.9811\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9784 - val_loss: 0.0863 - val_accuracy: 0.9811\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9784 - val_loss: 0.0840 - val_accuracy: 0.9811\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9784 - val_loss: 0.0812 - val_accuracy: 0.9811\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9784 - val_loss: 0.0830 - val_accuracy: 0.9811\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9784 - val_loss: 0.0875 - val_accuracy: 0.9811\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9784 - val_loss: 0.0816 - val_accuracy: 0.9811\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 40 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 3ms/step - loss: 2.9042 - accuracy: 0.8614 - val_loss: 0.3217 - val_accuracy: 0.9814\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.2019 - accuracy: 0.9785 - val_loss: 0.1178 - val_accuracy: 0.9814\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1051 - accuracy: 0.9785 - val_loss: 0.0908 - val_accuracy: 0.9814\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0993 - accuracy: 0.9785 - val_loss: 0.0910 - val_accuracy: 0.9814\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9785 - val_loss: 0.0898 - val_accuracy: 0.9814\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9785 - val_loss: 0.0903 - val_accuracy: 0.9814\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9785 - val_loss: 0.0901 - val_accuracy: 0.9814\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9785 - val_loss: 0.0902 - val_accuracy: 0.9814\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9785 - val_loss: 0.0899 - val_accuracy: 0.9814\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9785 - val_loss: 0.0899 - val_accuracy: 0.9814\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9785 - val_loss: 0.0895 - val_accuracy: 0.9814\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0979 - accuracy: 0.9785 - val_loss: 0.0900 - val_accuracy: 0.9814\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9785 - val_loss: 0.0895 - val_accuracy: 0.9814\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0885 - val_accuracy: 0.9814\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0975 - accuracy: 0.9785 - val_loss: 0.0889 - val_accuracy: 0.9814\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0905 - val_accuracy: 0.9814\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0892 - val_accuracy: 0.9814\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9785 - val_loss: 0.0888 - val_accuracy: 0.9814\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9785 - val_loss: 0.0890 - val_accuracy: 0.9814\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0897 - val_accuracy: 0.9814\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9785 - val_loss: 0.0911 - val_accuracy: 0.9814\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9785 - val_loss: 0.0893 - val_accuracy: 0.9814\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.0888 - val_accuracy: 0.9814\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9785 - val_loss: 0.0891 - val_accuracy: 0.9814\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 41 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8973 - accuracy: 0.9343 - val_loss: 0.2117 - val_accuracy: 0.9822\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9795 - val_loss: 0.0867 - val_accuracy: 0.9826\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9795 - val_loss: 0.0842 - val_accuracy: 0.9822\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9794 - val_loss: 0.0838 - val_accuracy: 0.9826\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9795 - val_loss: 0.0857 - val_accuracy: 0.9826\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9795 - val_loss: 0.0836 - val_accuracy: 0.9826\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9795 - val_loss: 0.0851 - val_accuracy: 0.9826\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9795 - val_loss: 0.0854 - val_accuracy: 0.9826\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9795 - val_loss: 0.0826 - val_accuracy: 0.9826\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9795 - val_loss: 0.0827 - val_accuracy: 0.9826\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9795 - val_loss: 0.0837 - val_accuracy: 0.9826\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9795 - val_loss: 0.0826 - val_accuracy: 0.9826\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0833 - val_accuracy: 0.9822\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9795 - val_loss: 0.0819 - val_accuracy: 0.9826\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9795 - val_loss: 0.0837 - val_accuracy: 0.9826\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9795 - val_loss: 0.0858 - val_accuracy: 0.9826\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9795 - val_loss: 0.0818 - val_accuracy: 0.9826\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9795 - val_loss: 0.0825 - val_accuracy: 0.9826\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9795 - val_loss: 0.0843 - val_accuracy: 0.9826\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0909 - val_accuracy: 0.9826\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9795 - val_loss: 0.0823 - val_accuracy: 0.9826\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.0817 - val_accuracy: 0.9826\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9795 - val_loss: 0.0842 - val_accuracy: 0.9826\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.0815 - val_accuracy: 0.9826\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.0816 - val_accuracy: 0.9826\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9795 - val_loss: 0.0817 - val_accuracy: 0.9826\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9795 - val_loss: 0.0858 - val_accuracy: 0.9826\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9795 - val_loss: 0.0814 - val_accuracy: 0.9826\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9795 - val_loss: 0.0810 - val_accuracy: 0.9826\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9795 - val_loss: 0.0816 - val_accuracy: 0.9826\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.0808 - val_accuracy: 0.9826\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9795 - val_loss: 0.0854 - val_accuracy: 0.9826\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9795 - val_loss: 0.0814 - val_accuracy: 0.9826\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9795 - val_loss: 0.0806 - val_accuracy: 0.9826\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0964 - accuracy: 0.9795 - val_loss: 0.0810 - val_accuracy: 0.9826\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9795 - val_loss: 0.0805 - val_accuracy: 0.9826\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9795 - val_loss: 0.0836 - val_accuracy: 0.9826\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9795 - val_loss: 0.0801 - val_accuracy: 0.9826\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9795 - val_loss: 0.0801 - val_accuracy: 0.9826\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9795 - val_loss: 0.0818 - val_accuracy: 0.9826\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9795 - val_loss: 0.0811 - val_accuracy: 0.9826\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9826\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9795 - val_loss: 0.0796 - val_accuracy: 0.9826\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0932 - accuracy: 0.9795 - val_loss: 0.0802 - val_accuracy: 0.9826\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9795 - val_loss: 0.0879 - val_accuracy: 0.9826\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9795 - val_loss: 0.0796 - val_accuracy: 0.9826\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0807 - val_accuracy: 0.9826\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0789 - val_accuracy: 0.9826\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9795 - val_loss: 0.0805 - val_accuracy: 0.9826\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9795 - val_loss: 0.0786 - val_accuracy: 0.9826\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9826\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 0.0802 - val_accuracy: 0.9826\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9795 - val_loss: 0.0781 - val_accuracy: 0.9826\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9795 - val_loss: 0.0784 - val_accuracy: 0.9826\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0933 - accuracy: 0.9795 - val_loss: 0.0788 - val_accuracy: 0.9826\n",
            "Epoch 58/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9795 - val_loss: 0.0789 - val_accuracy: 0.9826\n",
            "Epoch 59/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9795 - val_loss: 0.0800 - val_accuracy: 0.9826\n",
            "Epoch 60/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9795 - val_loss: 0.0781 - val_accuracy: 0.9826\n",
            "Epoch 61/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9795 - val_loss: 0.0783 - val_accuracy: 0.9826\n",
            "Epoch 62/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9795 - val_loss: 0.0798 - val_accuracy: 0.9826\n",
            "Epoch 63/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
            "Epoch 64/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9795 - val_loss: 0.0794 - val_accuracy: 0.9826\n",
            "Epoch 65/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9795 - val_loss: 0.0789 - val_accuracy: 0.9826\n",
            "Epoch 66/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9795 - val_loss: 0.0809 - val_accuracy: 0.9826\n",
            "Epoch 67/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9795 - val_loss: 0.0784 - val_accuracy: 0.9826\n",
            "Epoch 68/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9795 - val_loss: 0.0792 - val_accuracy: 0.9826\n",
            "Epoch 69/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9795 - val_loss: 0.0820 - val_accuracy: 0.9826\n",
            "Epoch 70/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0960 - accuracy: 0.9795 - val_loss: 0.0811 - val_accuracy: 0.9826\n",
            "149/149 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 42 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7265 - accuracy: 0.9581 - val_loss: 0.2053 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1238 - accuracy: 0.9803 - val_loss: 0.1020 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9803 - val_loss: 0.1000 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9803 - val_loss: 0.1024 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9803 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9803 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9803 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9803 - val_loss: 0.1022 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9803 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9803 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9803 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9803 - val_loss: 0.0988 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0943 - accuracy: 0.9803 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9803 - val_loss: 0.0992 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0940 - accuracy: 0.9803 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9803 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9803 - val_loss: 0.0975 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9803 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9803 - val_loss: 0.0980 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9803 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9803 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9803 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9803 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9803 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0930 - accuracy: 0.9803 - val_loss: 0.0970 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0929 - accuracy: 0.9803 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0929 - accuracy: 0.9803 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9803 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9803 - val_loss: 0.0944 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0927 - accuracy: 0.9803 - val_loss: 0.0973 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0930 - accuracy: 0.9803 - val_loss: 0.0984 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 2ms/step\n",
            "Iteration 43 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.6957 - accuracy: 0.9635 - val_loss: 0.1930 - val_accuracy: 0.9803\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1205 - accuracy: 0.9796 - val_loss: 0.0963 - val_accuracy: 0.9803\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9796 - val_loss: 0.0949 - val_accuracy: 0.9803\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9796 - val_loss: 0.0946 - val_accuracy: 0.9803\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.0932 - val_accuracy: 0.9803\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0956 - accuracy: 0.9796 - val_loss: 0.0937 - val_accuracy: 0.9803\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9796 - val_loss: 0.0942 - val_accuracy: 0.9803\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9796 - val_loss: 0.0943 - val_accuracy: 0.9803\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9796 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0947 - accuracy: 0.9796 - val_loss: 0.0933 - val_accuracy: 0.9803\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9796 - val_loss: 0.0931 - val_accuracy: 0.9803\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9796 - val_loss: 0.0923 - val_accuracy: 0.9803\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0942 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0939 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.0938 - val_accuracy: 0.9803\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9796 - val_loss: 0.0922 - val_accuracy: 0.9803\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9796 - val_loss: 0.0928 - val_accuracy: 0.9803\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9796 - val_loss: 0.0935 - val_accuracy: 0.9803\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0927 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9803\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 0.0929 - val_accuracy: 0.9803\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0940 - accuracy: 0.9796 - val_loss: 0.0946 - val_accuracy: 0.9803\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0918 - accuracy: 0.9796 - val_loss: 0.0969 - val_accuracy: 0.9803\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0921 - accuracy: 0.9796 - val_loss: 0.0972 - val_accuracy: 0.9803\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0938 - accuracy: 0.9796 - val_loss: 0.0950 - val_accuracy: 0.9803\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9796 - val_loss: 0.0958 - val_accuracy: 0.9803\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0920 - accuracy: 0.9796 - val_loss: 0.0940 - val_accuracy: 0.9803\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 44 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 2s 4ms/step - loss: 2.4882 - accuracy: 0.9756 - val_loss: 0.1586 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1067 - accuracy: 0.9794 - val_loss: 0.0993 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0957 - accuracy: 0.9794 - val_loss: 0.1009 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9794 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9794 - val_loss: 0.1015 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9794 - val_loss: 0.1004 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9794 - val_loss: 0.1007 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9794 - val_loss: 0.0994 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0948 - accuracy: 0.9794 - val_loss: 0.0996 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0949 - accuracy: 0.9794 - val_loss: 0.1029 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9794 - val_loss: 0.1013 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0946 - accuracy: 0.9794 - val_loss: 0.0995 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 45 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8241 - accuracy: 0.9231 - val_loss: 0.2461 - val_accuracy: 0.9799\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1468 - accuracy: 0.9785 - val_loss: 0.1015 - val_accuracy: 0.9799\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1008 - accuracy: 0.9785 - val_loss: 0.0946 - val_accuracy: 0.9799\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.1001 - accuracy: 0.9785 - val_loss: 0.0956 - val_accuracy: 0.9799\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1003 - accuracy: 0.9785 - val_loss: 0.0950 - val_accuracy: 0.9799\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9785 - val_loss: 0.0958 - val_accuracy: 0.9799\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9785 - val_loss: 0.0950 - val_accuracy: 0.9799\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0995 - accuracy: 0.9785 - val_loss: 0.0939 - val_accuracy: 0.9799\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1005 - accuracy: 0.9785 - val_loss: 0.0945 - val_accuracy: 0.9799\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9785 - val_loss: 0.0939 - val_accuracy: 0.9799\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9785 - val_loss: 0.0939 - val_accuracy: 0.9799\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9785 - val_loss: 0.0940 - val_accuracy: 0.9799\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9785 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9785 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9785 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9785 - val_loss: 0.0931 - val_accuracy: 0.9799\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0933 - val_accuracy: 0.9799\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0987 - accuracy: 0.9785 - val_loss: 0.0924 - val_accuracy: 0.9799\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0994 - accuracy: 0.9785 - val_loss: 0.0919 - val_accuracy: 0.9799\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0985 - accuracy: 0.9785 - val_loss: 0.0927 - val_accuracy: 0.9799\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0994 - accuracy: 0.9785 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9785 - val_loss: 0.0924 - val_accuracy: 0.9799\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9785 - val_loss: 0.0927 - val_accuracy: 0.9799\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9785 - val_loss: 0.0928 - val_accuracy: 0.9799\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0938 - val_accuracy: 0.9799\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9785 - val_loss: 0.0952 - val_accuracy: 0.9799\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9785 - val_loss: 0.0921 - val_accuracy: 0.9799\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0913 - val_accuracy: 0.9799\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9785 - val_loss: 0.0940 - val_accuracy: 0.9799\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9785 - val_loss: 0.0911 - val_accuracy: 0.9799\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9785 - val_loss: 0.0928 - val_accuracy: 0.9799\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0914 - val_accuracy: 0.9799\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0906 - val_accuracy: 0.9799\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0979 - accuracy: 0.9785 - val_loss: 0.0934 - val_accuracy: 0.9799\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0962 - val_accuracy: 0.9799\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9785 - val_loss: 0.0907 - val_accuracy: 0.9799\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0991 - accuracy: 0.9785 - val_loss: 0.0911 - val_accuracy: 0.9799\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9785 - val_loss: 0.0903 - val_accuracy: 0.9799\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0899 - val_accuracy: 0.9799\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.0904 - val_accuracy: 0.9799\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9785 - val_loss: 0.0903 - val_accuracy: 0.9799\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9785 - val_loss: 0.0894 - val_accuracy: 0.9799\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0888 - val_accuracy: 0.9799\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9785 - val_loss: 0.0939 - val_accuracy: 0.9799\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0899 - val_accuracy: 0.9799\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0879 - val_accuracy: 0.9799\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9785 - val_loss: 0.0941 - val_accuracy: 0.9799\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.0931 - val_accuracy: 0.9799\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9785 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0962 - accuracy: 0.9785 - val_loss: 0.0885 - val_accuracy: 0.9799\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0959 - accuracy: 0.9785 - val_loss: 0.0900 - val_accuracy: 0.9799\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 54/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0884 - val_accuracy: 0.9799\n",
            "Epoch 55/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9785 - val_loss: 0.0954 - val_accuracy: 0.9799\n",
            "Epoch 56/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9785 - val_loss: 0.0895 - val_accuracy: 0.9799\n",
            "Epoch 57/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9785 - val_loss: 0.0881 - val_accuracy: 0.9799\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 46 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7733 - accuracy: 0.9650 - val_loss: 0.1740 - val_accuracy: 0.9780\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1147 - accuracy: 0.9790 - val_loss: 0.1009 - val_accuracy: 0.9780\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0986 - accuracy: 0.9790 - val_loss: 0.0971 - val_accuracy: 0.9780\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9790 - val_loss: 0.1003 - val_accuracy: 0.9780\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9790 - val_loss: 0.0976 - val_accuracy: 0.9780\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.0972 - val_accuracy: 0.9780\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.0972 - val_accuracy: 0.9780\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.1001 - val_accuracy: 0.9780\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.1022 - val_accuracy: 0.9780\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0976 - accuracy: 0.9790 - val_loss: 0.0990 - val_accuracy: 0.9780\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9790 - val_loss: 0.0974 - val_accuracy: 0.9780\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9790 - val_loss: 0.0996 - val_accuracy: 0.9780\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9790 - val_loss: 0.0980 - val_accuracy: 0.9780\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 47 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.9757 - accuracy: 0.8152 - val_loss: 0.3686 - val_accuracy: 0.9818\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.2409 - accuracy: 0.9782 - val_loss: 0.1368 - val_accuracy: 0.9818\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1143 - accuracy: 0.9782 - val_loss: 0.0911 - val_accuracy: 0.9818\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1017 - accuracy: 0.9782 - val_loss: 0.0884 - val_accuracy: 0.9818\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1013 - accuracy: 0.9782 - val_loss: 0.0906 - val_accuracy: 0.9818\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1019 - accuracy: 0.9782 - val_loss: 0.0879 - val_accuracy: 0.9818\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1015 - accuracy: 0.9782 - val_loss: 0.0886 - val_accuracy: 0.9818\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1012 - accuracy: 0.9782 - val_loss: 0.0880 - val_accuracy: 0.9818\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1014 - accuracy: 0.9782 - val_loss: 0.0885 - val_accuracy: 0.9818\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1010 - accuracy: 0.9782 - val_loss: 0.0878 - val_accuracy: 0.9818\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1007 - accuracy: 0.9782 - val_loss: 0.0876 - val_accuracy: 0.9818\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9782 - val_loss: 0.0875 - val_accuracy: 0.9818\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9782 - val_loss: 0.0890 - val_accuracy: 0.9818\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9782 - val_loss: 0.0870 - val_accuracy: 0.9818\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1005 - accuracy: 0.9782 - val_loss: 0.0871 - val_accuracy: 0.9818\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1006 - accuracy: 0.9782 - val_loss: 0.0868 - val_accuracy: 0.9818\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1008 - accuracy: 0.9782 - val_loss: 0.0873 - val_accuracy: 0.9818\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1007 - accuracy: 0.9782 - val_loss: 0.0879 - val_accuracy: 0.9818\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0897 - val_accuracy: 0.9818\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.0871 - val_accuracy: 0.9818\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0997 - accuracy: 0.9782 - val_loss: 0.0869 - val_accuracy: 0.9818\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0866 - val_accuracy: 0.9818\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0999 - accuracy: 0.9782 - val_loss: 0.0868 - val_accuracy: 0.9818\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.0865 - val_accuracy: 0.9818\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1004 - accuracy: 0.9782 - val_loss: 0.0859 - val_accuracy: 0.9818\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9782 - val_loss: 0.0867 - val_accuracy: 0.9818\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9782 - val_loss: 0.0867 - val_accuracy: 0.9818\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0996 - accuracy: 0.9782 - val_loss: 0.0865 - val_accuracy: 0.9818\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9782 - val_loss: 0.0864 - val_accuracy: 0.9818\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0868 - val_accuracy: 0.9818\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0989 - accuracy: 0.9782 - val_loss: 0.0861 - val_accuracy: 0.9818\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.0859 - val_accuracy: 0.9818\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9782 - val_loss: 0.0865 - val_accuracy: 0.9818\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9782 - val_loss: 0.0860 - val_accuracy: 0.9818\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0998 - accuracy: 0.9782 - val_loss: 0.0859 - val_accuracy: 0.9818\n",
            "149/149 [==============================] - 0s 1ms/step\n",
            "Iteration 48 of 50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.9084 - accuracy: 0.9355 - val_loss: 0.2028 - val_accuracy: 0.9792\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1281 - accuracy: 0.9785 - val_loss: 0.0976 - val_accuracy: 0.9792\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0994 - accuracy: 0.9785 - val_loss: 0.0948 - val_accuracy: 0.9792\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0995 - accuracy: 0.9785 - val_loss: 0.0938 - val_accuracy: 0.9792\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9785 - val_loss: 0.0985 - val_accuracy: 0.9792\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0988 - accuracy: 0.9785 - val_loss: 0.0949 - val_accuracy: 0.9792\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0945 - val_accuracy: 0.9792\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0992 - accuracy: 0.9785 - val_loss: 0.0938 - val_accuracy: 0.9792\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9785 - val_loss: 0.0922 - val_accuracy: 0.9792\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9785 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0973 - val_accuracy: 0.9792\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9785 - val_loss: 0.0932 - val_accuracy: 0.9792\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0984 - accuracy: 0.9785 - val_loss: 0.0956 - val_accuracy: 0.9792\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0926 - val_accuracy: 0.9792\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9784 - val_loss: 0.0940 - val_accuracy: 0.9792\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0930 - val_accuracy: 0.9792\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0942 - val_accuracy: 0.9792\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9785 - val_loss: 0.0914 - val_accuracy: 0.9792\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9785 - val_loss: 0.0941 - val_accuracy: 0.9792\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0932 - val_accuracy: 0.9792\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9785 - val_loss: 0.0935 - val_accuracy: 0.9792\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0917 - val_accuracy: 0.9792\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9785 - val_loss: 0.0934 - val_accuracy: 0.9792\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9785 - val_loss: 0.0908 - val_accuracy: 0.9792\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0927 - val_accuracy: 0.9792\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0961 - accuracy: 0.9785 - val_loss: 0.0922 - val_accuracy: 0.9792\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9785 - val_loss: 0.0906 - val_accuracy: 0.9792\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.0919 - val_accuracy: 0.9792\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9785 - val_loss: 0.0916 - val_accuracy: 0.9792\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9785 - val_loss: 0.0905 - val_accuracy: 0.9792\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9785 - val_loss: 0.0898 - val_accuracy: 0.9792\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0889 - val_accuracy: 0.9792\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9785 - val_loss: 0.0898 - val_accuracy: 0.9792\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0969 - accuracy: 0.9785 - val_loss: 0.0907 - val_accuracy: 0.9792\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0950 - accuracy: 0.9785 - val_loss: 0.0899 - val_accuracy: 0.9792\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9785 - val_loss: 0.0936 - val_accuracy: 0.9792\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9785 - val_loss: 0.0893 - val_accuracy: 0.9792\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9785 - val_loss: 0.0903 - val_accuracy: 0.9792\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 0.0904 - val_accuracy: 0.9792\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9785 - val_loss: 0.0930 - val_accuracy: 0.9792\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0955 - accuracy: 0.9785 - val_loss: 0.0896 - val_accuracy: 0.9792\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9785 - val_loss: 0.0910 - val_accuracy: 0.9792\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 49 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.8816 - accuracy: 0.9051 - val_loss: 0.2507 - val_accuracy: 0.9758\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1442 - accuracy: 0.9791 - val_loss: 0.1118 - val_accuracy: 0.9758\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9791 - val_loss: 0.1093 - val_accuracy: 0.9758\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9791 - val_loss: 0.1113 - val_accuracy: 0.9758\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0979 - accuracy: 0.9791 - val_loss: 0.1093 - val_accuracy: 0.9758\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9791 - val_loss: 0.1092 - val_accuracy: 0.9758\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9791 - val_loss: 0.1091 - val_accuracy: 0.9758\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9791 - val_loss: 0.1088 - val_accuracy: 0.9758\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9791 - val_loss: 0.1105 - val_accuracy: 0.9758\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9791 - val_loss: 0.1124 - val_accuracy: 0.9758\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9791 - val_loss: 0.1078 - val_accuracy: 0.9758\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0972 - accuracy: 0.9791 - val_loss: 0.1128 - val_accuracy: 0.9758\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0965 - accuracy: 0.9791 - val_loss: 0.1082 - val_accuracy: 0.9758\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0966 - accuracy: 0.9791 - val_loss: 0.1084 - val_accuracy: 0.9758\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9791 - val_loss: 0.1119 - val_accuracy: 0.9758\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9791 - val_loss: 0.1075 - val_accuracy: 0.9758\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9791 - val_loss: 0.1082 - val_accuracy: 0.9758\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9791 - val_loss: 0.1078 - val_accuracy: 0.9758\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9791 - val_loss: 0.1071 - val_accuracy: 0.9758\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9791 - val_loss: 0.1074 - val_accuracy: 0.9758\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9791 - val_loss: 0.1117 - val_accuracy: 0.9758\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9791 - val_loss: 0.1094 - val_accuracy: 0.9758\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9758\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9791 - val_loss: 0.1060 - val_accuracy: 0.9758\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9791 - val_loss: 0.1058 - val_accuracy: 0.9758\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0953 - accuracy: 0.9791 - val_loss: 0.1063 - val_accuracy: 0.9758\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0954 - accuracy: 0.9791 - val_loss: 0.1059 - val_accuracy: 0.9758\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9791 - val_loss: 0.1056 - val_accuracy: 0.9758\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9791 - val_loss: 0.1054 - val_accuracy: 0.9758\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0945 - accuracy: 0.9791 - val_loss: 0.1065 - val_accuracy: 0.9758\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0946 - accuracy: 0.9791 - val_loss: 0.1063 - val_accuracy: 0.9758\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0945 - accuracy: 0.9791 - val_loss: 0.1066 - val_accuracy: 0.9758\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0939 - accuracy: 0.9791 - val_loss: 0.1073 - val_accuracy: 0.9758\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0936 - accuracy: 0.9791 - val_loss: 0.1054 - val_accuracy: 0.9758\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0941 - accuracy: 0.9791 - val_loss: 0.1057 - val_accuracy: 0.9758\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0935 - accuracy: 0.9791 - val_loss: 0.1046 - val_accuracy: 0.9758\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0937 - accuracy: 0.9791 - val_loss: 0.1064 - val_accuracy: 0.9758\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0926 - accuracy: 0.9791 - val_loss: 0.1041 - val_accuracy: 0.9758\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0934 - accuracy: 0.9791 - val_loss: 0.1046 - val_accuracy: 0.9758\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9791 - val_loss: 0.1076 - val_accuracy: 0.9758\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9791 - val_loss: 0.1053 - val_accuracy: 0.9758\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0931 - accuracy: 0.9791 - val_loss: 0.1046 - val_accuracy: 0.9758\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0928 - accuracy: 0.9791 - val_loss: 0.1029 - val_accuracy: 0.9758\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0918 - accuracy: 0.9791 - val_loss: 0.1052 - val_accuracy: 0.9758\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 4ms/step - loss: 0.0929 - accuracy: 0.9791 - val_loss: 0.1061 - val_accuracy: 0.9758\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9791 - val_loss: 0.1067 - val_accuracy: 0.9758\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0925 - accuracy: 0.9791 - val_loss: 0.1075 - val_accuracy: 0.9758\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9791 - val_loss: 0.1085 - val_accuracy: 0.9758\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0924 - accuracy: 0.9791 - val_loss: 0.1041 - val_accuracy: 0.9758\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0925 - accuracy: 0.9791 - val_loss: 0.1047 - val_accuracy: 0.9758\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0921 - accuracy: 0.9791 - val_loss: 0.1048 - val_accuracy: 0.9758\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0919 - accuracy: 0.9791 - val_loss: 0.1052 - val_accuracy: 0.9758\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0911 - accuracy: 0.9791 - val_loss: 0.1124 - val_accuracy: 0.9758\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 50 of 50\n",
            "Epoch 1/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 2.7972 - accuracy: 0.9079 - val_loss: 0.2885 - val_accuracy: 0.9784\n",
            "Epoch 2/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1743 - accuracy: 0.9793 - val_loss: 0.1073 - val_accuracy: 0.9784\n",
            "Epoch 3/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.1009 - accuracy: 0.9793 - val_loss: 0.0981 - val_accuracy: 0.9784\n",
            "Epoch 4/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9792 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
            "Epoch 5/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9793 - val_loss: 0.1019 - val_accuracy: 0.9784\n",
            "Epoch 6/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9793 - val_loss: 0.0966 - val_accuracy: 0.9784\n",
            "Epoch 7/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0983 - accuracy: 0.9793 - val_loss: 0.0976 - val_accuracy: 0.9784\n",
            "Epoch 8/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0982 - accuracy: 0.9793 - val_loss: 0.0982 - val_accuracy: 0.9784\n",
            "Epoch 9/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9793 - val_loss: 0.0983 - val_accuracy: 0.9784\n",
            "Epoch 10/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0985 - accuracy: 0.9793 - val_loss: 0.0987 - val_accuracy: 0.9784\n",
            "Epoch 11/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0977 - accuracy: 0.9793 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 12/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0980 - accuracy: 0.9793 - val_loss: 0.0974 - val_accuracy: 0.9784\n",
            "Epoch 13/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0983 - accuracy: 0.9793 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
            "Epoch 14/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0978 - accuracy: 0.9793 - val_loss: 0.0979 - val_accuracy: 0.9784\n",
            "Epoch 15/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0975 - accuracy: 0.9793 - val_loss: 0.0959 - val_accuracy: 0.9784\n",
            "Epoch 16/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0981 - accuracy: 0.9793 - val_loss: 0.0967 - val_accuracy: 0.9784\n",
            "Epoch 17/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0992 - accuracy: 0.9793 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "Epoch 18/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9793 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
            "Epoch 19/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0982 - accuracy: 0.9793 - val_loss: 0.1011 - val_accuracy: 0.9784\n",
            "Epoch 20/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0974 - accuracy: 0.9793 - val_loss: 0.0965 - val_accuracy: 0.9784\n",
            "Epoch 21/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0976 - accuracy: 0.9793 - val_loss: 0.0961 - val_accuracy: 0.9784\n",
            "Epoch 22/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9793 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 23/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0973 - accuracy: 0.9793 - val_loss: 0.0963 - val_accuracy: 0.9784\n",
            "Epoch 24/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0978 - accuracy: 0.9793 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 25/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.0946 - val_accuracy: 0.9784\n",
            "Epoch 26/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0966 - accuracy: 0.9793 - val_loss: 0.0954 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9793 - val_loss: 0.0951 - val_accuracy: 0.9784\n",
            "Epoch 28/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0965 - accuracy: 0.9793 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
            "Epoch 29/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0961 - accuracy: 0.9793 - val_loss: 0.0947 - val_accuracy: 0.9784\n",
            "Epoch 30/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9793 - val_loss: 0.0978 - val_accuracy: 0.9784\n",
            "Epoch 31/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
            "Epoch 32/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9793 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
            "Epoch 33/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.0956 - val_accuracy: 0.9784\n",
            "Epoch 34/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9793 - val_loss: 0.1007 - val_accuracy: 0.9784\n",
            "Epoch 35/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0972 - accuracy: 0.9793 - val_loss: 0.0950 - val_accuracy: 0.9784\n",
            "Epoch 36/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0962 - accuracy: 0.9793 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
            "Epoch 37/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0973 - accuracy: 0.9793 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 38/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0968 - accuracy: 0.9793 - val_loss: 0.0935 - val_accuracy: 0.9784\n",
            "Epoch 39/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0977 - accuracy: 0.9793 - val_loss: 0.0936 - val_accuracy: 0.9784\n",
            "Epoch 40/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0956 - accuracy: 0.9793 - val_loss: 0.0930 - val_accuracy: 0.9784\n",
            "Epoch 41/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.0957 - val_accuracy: 0.9784\n",
            "Epoch 42/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9793 - val_loss: 0.0986 - val_accuracy: 0.9784\n",
            "Epoch 43/100\n",
            "331/331 [==============================] - 1s 3ms/step - loss: 0.0969 - accuracy: 0.9793 - val_loss: 0.0914 - val_accuracy: 0.9784\n",
            "Epoch 44/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0951 - accuracy: 0.9793 - val_loss: 0.0933 - val_accuracy: 0.9784\n",
            "Epoch 45/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9793 - val_loss: 0.0958 - val_accuracy: 0.9784\n",
            "Epoch 46/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9793 - val_loss: 0.0945 - val_accuracy: 0.9784\n",
            "Epoch 47/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0964 - accuracy: 0.9793 - val_loss: 0.0920 - val_accuracy: 0.9784\n",
            "Epoch 48/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0942 - accuracy: 0.9793 - val_loss: 0.0939 - val_accuracy: 0.9784\n",
            "Epoch 49/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0944 - accuracy: 0.9793 - val_loss: 0.0928 - val_accuracy: 0.9784\n",
            "Epoch 50/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0957 - accuracy: 0.9793 - val_loss: 0.0923 - val_accuracy: 0.9784\n",
            "Epoch 51/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0952 - accuracy: 0.9793 - val_loss: 0.0918 - val_accuracy: 0.9784\n",
            "Epoch 52/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0959 - accuracy: 0.9793 - val_loss: 0.0919 - val_accuracy: 0.9784\n",
            "Epoch 53/100\n",
            "331/331 [==============================] - 1s 2ms/step - loss: 0.0958 - accuracy: 0.9793 - val_loss: 0.0937 - val_accuracy: 0.9784\n",
            "149/149 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pre = pd.read_csv(\"predictions.csv\")"
      ],
      "metadata": {
        "id": "uvIWDGsQHeB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df[predictions_df['prediction'] == 1].to_csv('predictions.csv', index=False)\n",
        "pre['index'].value_counts().head(200).to_csv('predictions.csv')"
      ],
      "metadata": {
        "id": "sZ4MQy30He1u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_count = pd.DataFrame(pre['index'].value_counts().head(200))"
      ],
      "metadata": {
        "id": "QCfOsiWUJqHK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 779
        },
        "id": "Gl7O9cLeOdaK",
        "outputId": "86e76b31-29b9-41ab-8f1f-1ac95ac03baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                         index\n",
              "INDEPENDENCE BANK           51\n",
              "GENESIS BANK                50\n",
              "EVERMORE BANK               50\n",
              "GAINEY BUSINESS BANK        50\n",
              "LEGACY BANK                 50\n",
              "...                        ...\n",
              "NATIONWIDE TRUST CO FSB     13\n",
              "PIERMONT BANK               13\n",
              "GULF CAPITAL BANK           13\n",
              "MIZUHO BANK USA             13\n",
              "GOLDWATER BANK N A          13\n",
              "\n",
              "[200 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c875bf8-9685-4ae1-be83-8691287e7332\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>INDEPENDENCE BANK</th>\n",
              "      <td>51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GENESIS BANK</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>EVERMORE BANK</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GAINEY BUSINESS BANK</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LEGACY BANK</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NATIONWIDE TRUST CO FSB</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PIERMONT BANK</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GULF CAPITAL BANK</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>MIZUHO BANK USA</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>GOLDWATER BANK N A</th>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c875bf8-9685-4ae1-be83-8691287e7332')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c875bf8-9685-4ae1-be83-8691287e7332 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c875bf8-9685-4ae1-be83-8691287e7332');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contains_bank_names = output_count.index.str.contains('|'.join(bank_names), case=False)\n",
        "\n",
        "# Count the occurrences of True\n",
        "count_true = contains_bank_names.sum()\n",
        "\n",
        "print(count_true)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRgD4-wMNS_6",
        "outputId": "9361a0b0-6a0a-42a2-a681-cd91949b314f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "contains_bank_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69Nn1JgjdJht",
        "outputId": "790f24a4-afb2-4f42-dcf3-3497d471c097"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False,  True, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False,  True,\n",
              "        True, False, False, False, False, False, False,  True, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdc8evJZqSceBxLfF41Q7J",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}